{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ time_bin_Converted already exists\n"
     ]
    }
   ],
   "source": [
    "import arcpy, os, re, datetime as dt\n",
    "from arcpy.sa import *\n",
    "import time\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "current_file = \"cities_cum_helene\"\n",
    "pop_boo = False\n",
    "if pop_boo:\n",
    "    pop_str = \"pop\"\n",
    "    pop_var = \"population\"\n",
    "else:\n",
    "    pop_str = \"\"\n",
    "    pop_var = None\n",
    "\n",
    "GDB         = r\"C:\\Users\\colto\\Documents\\tw_project\\tw_project\\tw_project.gdb\"\n",
    "POINTS_FC   = r\"C:\\Users\\colto\\Documents\\tw_project\\tw_project\\tw_project.gdb\\cities_cum_helene\"\n",
    "BIN_HOURS   = 4\n",
    "\n",
    "CELL_SIZE_M = 1000\n",
    "RADIUS_M    = 18000\n",
    "MD_NAME     = f\"\"\"KD_Time_{current_file}_{pop_str}_\"\"\"\n",
    "PREFIX      = f\"\"\"kd_{current_file}_{pop_str}_\"\"\"\n",
    "\n",
    "# H3 Configuration\n",
    "H3_RESOLUTION = 7  # Resolution 7: ~5.16 km² average hexagon area\n",
    "H3_PREFIX = f\"h3_{current_file}_{pop_str}_\"\n",
    "H3_MD_NAME = f\"H3_Time_{current_file}_{pop_str}_\"\n",
    "\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "arcpy.env.overwriteOutput  = True\n",
    "arcpy.env.workspace        = GDB\n",
    "arcpy.env.scratchWorkspace = GDB\n",
    "\n",
    "# --- 1) Convert string field -> Date field (official ArcGIS tool) ---\n",
    "SRC_FC   = POINTS_FC\n",
    "SRC_TEXT = \"time_bin\"                 # your text time field\n",
    "DST_DATE = \"time_bin_Converted\"       # name of new Date field\n",
    "FORMAT   = \"yyyy-MM-dd HH:mm:ss\"      # adjust if yours differs\n",
    "\n",
    "# Only run conversion if needed\n",
    "if DST_DATE not in [f.name for f in arcpy.ListFields(SRC_FC)]:\n",
    "    arcpy.management.ConvertTimeField(\n",
    "        in_table=SRC_FC,\n",
    "        input_time_field=SRC_TEXT,\n",
    "        input_time_format=FORMAT,\n",
    "        output_time_field=DST_DATE,\n",
    "        output_time_type=\"DATE\"\n",
    "    )\n",
    "    print(f\"✅ Created {DST_DATE} from {SRC_TEXT}\")\n",
    "else:\n",
    "    print(f\"✅ {DST_DATE} already exists\")\n",
    "\n",
    "TIME_FIELD = DST_DATE\n",
    "\n",
    "# 0) Project points to a meters-based CRS (EPSG:5070) for true meter units\n",
    "sr_in = arcpy.Describe(POINTS_FC).spatialReference\n",
    "PTS_METERS = os.path.join(GDB, f\"\"\"{current_file}_{pop_str}_5070\"\"\")\n",
    "if not arcpy.Exists(PTS_METERS):\n",
    "    if sr_in.type == \"Geographic\" or sr_in.linearUnitName.lower() in (\"\", \"degree\", \"degrees\"):\n",
    "        arcpy.management.Project(POINTS_FC, PTS_METERS, arcpy.SpatialReference(5070))  # NAD83 / Conus Albers\n",
    "    else:\n",
    "        # Already projected — make a clean copy with a known name\n",
    "        arcpy.management.CopyFeatures(POINTS_FC, PTS_METERS)\n",
    "\n",
    "# Set processing envs to projected space\n",
    "sr = arcpy.Describe(PTS_METERS).spatialReference\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "arcpy.env.cellSize = CELL_SIZE_M\n",
    "# if AOI:\n",
    "#     arcpy.env.mask = AOI\n",
    "#     arcpy.env.extent = arcpy.Describe(AOI).extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<da.SearchCursor object at 0x00000268BE5BA790>\n",
      "Time range: 2024-09-26 00:00:00 to 2024-09-27 16:00:00\n",
      "Starting from: 2024-09-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 1) Determine time range\n",
    "def iter_times(fc, fld):\n",
    "    with arcpy.da.SearchCursor(fc, [fld]) as rows:\n",
    "        print(rows)\n",
    "        for (t,) in rows:\n",
    "            if t:\n",
    "                yield t\n",
    "\n",
    "times = list(iter_times(PTS_METERS, TIME_FIELD))\n",
    "\n",
    "if not times:\n",
    "    raise RuntimeError(f\"No valid times in field '{TIME_FIELD}'.\")\n",
    "\n",
    "tmin, tmax = min(times), max(times)\n",
    "start = dt.datetime(tmin.year, tmin.month, tmin.day, (tmin.hour // BIN_HOURS) * BIN_HOURS)\n",
    "print(f\"Time range: {tmin} to {tmax}\")\n",
    "print(f\"Starting from: {start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extent: -6127658, 414147, 1777573, 2750738\n",
      "Buffered extent (100km): -6227658, 314147, 1877573, 2850738\n",
      "✅ H3 grid already exists: C:\\Users\\colto\\Documents\\tw_project\\tw_project\\tw_project.gdb\\h3_grid_cities_cum_helene_res7\n"
     ]
    },
    {
     "ename": "<class 'arcgisscripting.ExecuteError'>",
     "evalue": "ERROR 000210: Cannot create output C:\\Users\\colto\\Documents\\tw_project\\tw_project\\tw_project.gdb\\h3_cities_cum_helene__20240926_0000\nFailed to execute (SpatialJoin).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 69\u001b[0m\n\u001b[0;32m     58\u001b[0m     arcpy\u001b[38;5;241m.\u001b[39manalysis\u001b[38;5;241m.\u001b[39mSpatialJoin(\n\u001b[0;32m     59\u001b[0m         target_features\u001b[38;5;241m=\u001b[39mh3_grid_base,\n\u001b[0;32m     60\u001b[0m         join_features\u001b[38;5;241m=\u001b[39mlyr_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m         match_option\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONTAINS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m     )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Count tweets per hexagon (Join_Count field)\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     arcpy\u001b[38;5;241m.\u001b[39manalysis\u001b[38;5;241m.\u001b[39mSpatialJoin(\n\u001b[0;32m     70\u001b[0m         target_features\u001b[38;5;241m=\u001b[39mh3_grid_base,\n\u001b[0;32m     71\u001b[0m         join_features\u001b[38;5;241m=\u001b[39mlyr_name,\n\u001b[0;32m     72\u001b[0m         out_feature_class\u001b[38;5;241m=\u001b[39mh3_with_counts,\n\u001b[0;32m     73\u001b[0m         join_operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJOIN_ONE_TO_ONE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     74\u001b[0m         join_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKEEP_COMMON\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m         match_option\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONTAINS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     78\u001b[0m h3_created\u001b[38;5;241m.\u001b[39mappend(h3_with_counts)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcur\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m%Y-%m-%d %H:%M\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh3_with_counts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py:1079\u001b[0m, in \u001b[0;36mSpatialJoin\u001b[1;34m(target_features, join_features, out_feature_class, join_operation, join_type, field_mapping, match_option, search_radius, distance_field_name, match_fields)\u001b[0m\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1079\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py:1059\u001b[0m, in \u001b[0;36mSpatialJoin\u001b[1;34m(target_features, join_features, out_feature_class, join_operation, join_type, field_mapping, match_option, search_radius, distance_field_name, match_fields)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marcpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marcobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marcobjectconversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convertArcObjectToPythonObject\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1058\u001b[0m     retval \u001b[38;5;241m=\u001b[39m convertArcObjectToPythonObject(\n\u001b[1;32m-> 1059\u001b[0m         gp\u001b[38;5;241m.\u001b[39mSpatialJoin_analysis(\n\u001b[0;32m   1060\u001b[0m             \u001b[38;5;241m*\u001b[39mgp_fixargs(\n\u001b[0;32m   1061\u001b[0m                 (\n\u001b[0;32m   1062\u001b[0m                     target_features,\n\u001b[0;32m   1063\u001b[0m                     join_features,\n\u001b[0;32m   1064\u001b[0m                     out_feature_class,\n\u001b[0;32m   1065\u001b[0m                     join_operation,\n\u001b[0;32m   1066\u001b[0m                     join_type,\n\u001b[0;32m   1067\u001b[0m                     field_mapping,\n\u001b[0;32m   1068\u001b[0m                     match_option,\n\u001b[0;32m   1069\u001b[0m                     search_radius,\n\u001b[0;32m   1070\u001b[0m                     distance_field_name,\n\u001b[0;32m   1071\u001b[0m                     match_fields,\n\u001b[0;32m   1072\u001b[0m                 ),\n\u001b[0;32m   1073\u001b[0m                 \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1074\u001b[0m             )\n\u001b[0;32m   1075\u001b[0m         )\n\u001b[0;32m   1076\u001b[0m     )\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py:533\u001b[0m, in \u001b[0;36mGeoprocessor.__getattr__.<locals>.<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    531\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp, attr)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(val):\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: val(\u001b[38;5;241m*\u001b[39mgp_fixargs(args, \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convertArcObjectToPythonObject(val)\n",
      "\u001b[1;31mExecuteError\u001b[0m: ERROR 000210: Cannot create output C:\\Users\\colto\\Documents\\tw_project\\tw_project\\tw_project.gdb\\h3_cities_cum_helene__20240926_0000\nFailed to execute (SpatialJoin).\n"
     ]
    }
   ],
   "source": [
    "# === H3 HEXAGONAL AGGREGATION PER TIME BIN (Using ArcGIS Pro's Built-in H3) ===\n",
    "# Tessellated cells kept as feature classes (NO rasterization)\n",
    "\n",
    "# Get the extent of the tweet data and buffer it to cover entire states\n",
    "data_extent = arcpy.Describe(PTS_METERS).extent\n",
    "\n",
    "# Buffer the extent by 100km (100000 meters) to ensure we capture entire states\n",
    "buffer_distance = 100000  # 100 km in meters\n",
    "\n",
    "buffered_extent = arcpy.Extent(\n",
    "    XMin=data_extent.XMin - buffer_distance,\n",
    "    YMin=data_extent.YMin - buffer_distance,\n",
    "    XMax=data_extent.XMax + buffer_distance,\n",
    "    YMax=data_extent.YMax + buffer_distance\n",
    ")\n",
    "\n",
    "print(f\"Data extent: {data_extent.XMin:.0f}, {data_extent.YMin:.0f}, {data_extent.XMax:.0f}, {data_extent.YMax:.0f}\")\n",
    "print(f\"Buffered extent (100km): {buffered_extent.XMin:.0f}, {buffered_extent.YMin:.0f}, {buffered_extent.XMax:.0f}, {buffered_extent.YMax:.0f}\")\n",
    "\n",
    "# Create the H3 hexagon grid that covers the buffered extent (only once)\n",
    "h3_grid_base = os.path.join(GDB, f\"h3_grid_{current_file}_res{H3_RESOLUTION}\")\n",
    "if not arcpy.Exists(h3_grid_base):\n",
    "    print(f\"Creating H3 resolution {H3_RESOLUTION} grid covering tweet extent + 100km buffer...\")\n",
    "    arcpy.management.GenerateTessellation(\n",
    "        Output_Feature_Class=h3_grid_base,\n",
    "        Extent=buffered_extent,\n",
    "        Shape_Type=\"H3_HEXAGON\",\n",
    "        H3_Resolution=H3_RESOLUTION\n",
    "    )\n",
    "    print(f\"✅ Created H3 grid: {h3_grid_base}\")\n",
    "else:\n",
    "    print(f\"✅ H3 grid already exists: {h3_grid_base}\")\n",
    "\n",
    "h3_created = []  # Store feature class names (NOT rasters)\n",
    "cur = start\n",
    "\n",
    "while cur <= tmax:\n",
    "    nxt = cur + dt.timedelta(hours=BIN_HOURS)\n",
    "    where = (f\"{arcpy.AddFieldDelimiters(PTS_METERS, TIME_FIELD)} >= TIMESTAMP '{cur:%Y-%m-%d %H:%M:%S}' \"\n",
    "             f\"AND {arcpy.AddFieldDelimiters(PTS_METERS, TIME_FIELD)} < TIMESTAMP '{nxt:%Y-%m-%d %H:%M:%S}'\")\n",
    "    \n",
    "    # Create temporary layer for this time bin\n",
    "    lyr_name = os.path.join(\"memory\", f\"h3_bin_{cur:%Y%m%d_%H%M}\")\n",
    "    arcpy.conversion.ExportFeatures(\n",
    "        in_features=PTS_METERS,\n",
    "        out_features=lyr_name,\n",
    "        where_clause=where\n",
    "    )\n",
    "    \n",
    "    # Check if we have points in this time bin\n",
    "    if int(arcpy.management.GetCount(lyr_name).getOutput(0)) > 0:\n",
    "        # Spatial join: aggregate tweets into H3 hexagons\n",
    "        h3_with_counts = os.path.join(GDB, f\"{H3_PREFIX}{cur:%Y%m%d_%H%M}\")\n",
    "        \n",
    "        if pop_boo:\n",
    "            # Sum population field\n",
    "            field_mapping = f'population \"population\" true true false 8 Double 0 0,Sum,#,{lyr_name},population,-1,-1'\n",
    "            arcpy.analysis.SpatialJoin(\n",
    "                target_features=h3_grid_base,\n",
    "                join_features=lyr_name,\n",
    "                out_feature_class=h3_with_counts,\n",
    "                join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "                join_type=\"KEEP_COMMON\",\n",
    "                field_mapping=field_mapping,\n",
    "                match_option=\"CONTAINS\"\n",
    "            )\n",
    "        else:\n",
    "            # Count tweets per hexagon (Join_Count field)\n",
    "            arcpy.analysis.SpatialJoin(\n",
    "                target_features=h3_grid_base,\n",
    "                join_features=lyr_name,\n",
    "                out_feature_class=h3_with_counts,\n",
    "                join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "                join_type=\"KEEP_COMMON\",\n",
    "                match_option=\"CONTAINS\"\n",
    "            )\n",
    "        \n",
    "        h3_created.append(h3_with_counts)\n",
    "        print(f\"✅ {cur:%Y-%m-%d %H:%M} → {h3_with_counts}\")\n",
    "    else:\n",
    "        print(f\"⚠️ {cur:%Y-%m-%d %H:%M}: No tweets in this bin\")\n",
    "    \n",
    "    cur = nxt\n",
    "\n",
    "if not h3_created:\n",
    "    raise RuntimeError(\"No H3 hexagons created. Check data and time field.\")\n",
    "\n",
    "print(f\"\\n✅ Created {len(h3_created)} time-binned H3 feature classes (NO rasterization)\")\n",
    "print(f\"Feature classes: {h3_created}\")\n",
    "\n",
    "# OPTIONAL: Compile all time bins into a single feature class with a timestamp field\n",
    "if h3_created:\n",
    "    h3_compiled = os.path.join(GDB, f\"H3_compiled_{current_file}_{int(time.time())}\")\n",
    "    \n",
    "    # Create template from first feature class\n",
    "    arcpy.management.CopyFeatures(h3_created[0], h3_compiled)\n",
    "    \n",
    "    # Add StartTime field if not present\n",
    "    if \"StartTime\" not in [f.name for f in arcpy.ListFields(h3_compiled)]:\n",
    "        arcpy.management.AddField(h3_compiled, \"StartTime\", \"DATE\")\n",
    "    \n",
    "    # Append remaining and populate timestamp\n",
    "    for idx, h3_fc in enumerate(h3_created[1:], start=1):\n",
    "        # Extract timestamp from feature class name (e.g., \"h3_cities_cum_helene__20240926_0000\")\n",
    "        time_str = h3_fc.split(\"_\")[-2:]  # Get last 2 parts: YYYYMMDD_HHMM\n",
    "        time_str = f\"{time_str[0]}_{time_str[1]}\"\n",
    "        \n",
    "        # Add StartTime field to this fc if not present\n",
    "        if \"StartTime\" not in [f.name for f in arcpy.ListFields(h3_fc)]:\n",
    "            arcpy.management.AddField(h3_fc, \"StartTime\", \"DATE\")\n",
    "        \n",
    "        # Calculate the date\n",
    "        ts_date = dt.datetime.strptime(time_str, \"%Y%m%d_%H%M\")\n",
    "        \n",
    "        # Append\n",
    "        arcpy.management.Append(h3_fc, h3_compiled, \"NO_TEST\")\n",
    "    \n",
    "    # Populate StartTime field on all records\n",
    "    code_block = \"\"\"import datetime\n",
    "def parse_name(fc_name):\n",
    "    try:\n",
    "        time_str = fc_name.split(\"_\")[-2:]\n",
    "        time_str = f\"{time_str[0]}_{time_str[1]}\"\n",
    "        return datetime.datetime.strptime(time_str, \"%Y%m%d_%H%M\")\n",
    "    except:\n",
    "        return None\n",
    "\"\"\"\n",
    "    \n",
    "    # Manual approach: iterate and update\n",
    "    with arcpy.da.UpdateCursor(h3_compiled, [\"StartTime\"]) as cursor:\n",
    "        for idx, row in enumerate(cursor):\n",
    "            if idx < len(h3_created):\n",
    "                h3_fc_name = h3_created[idx].split(\"\\\\\")[-1]\n",
    "                time_str = h3_fc_name.split(\"_\")[-2:]\n",
    "                time_str = f\"{time_str[0]}_{time_str[1]}\"\n",
    "                ts_date = dt.datetime.strptime(time_str, \"%Y%m%d_%H%M\")\n",
    "                row[0] = ts_date\n",
    "                cursor.updateRow(row)\n",
    "    \n",
    "    print(f\"✅ Compiled all time bins into: {h3_compiled}\")\n",
    "    print(f\"   Use 'StartTime' field for temporal filtering in ArcPro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CREATE TIME-AWARE MOSAIC DATASET FOR H3 ===\n",
    "if h3_created:\n",
    "    timestamp = time.time()\n",
    "    H3_MD_NAME = f\"H3_{current_file}_{pop_str}_{int(timestamp)}\"\n",
    "    \n",
    "    # Create mosaic dataset for H3 rasters\n",
    "    H3_MD = arcpy.management.CreateMosaicDataset(\n",
    "        in_workspace=GDB,\n",
    "        in_mosaicdataset_name=H3_MD_NAME,\n",
    "        coordinate_system=sr,\n",
    "        pixel_type=\"32_BIT_FLOAT\"\n",
    "    ).getOutput(0)\n",
    "    \n",
    "    # Add each H3 raster slice\n",
    "    for nm in h3_created:\n",
    "        print(f\"Adding {nm} to H3 mosaic dataset...\")\n",
    "        arcpy.management.AddRastersToMosaicDataset(\n",
    "            in_mosaic_dataset=H3_MD,\n",
    "            raster_type=\"Raster Dataset\",\n",
    "            input_path=os.path.join(GDB, nm),\n",
    "            update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "            update_boundary=\"UPDATE_BOUNDARY\",\n",
    "            update_overviews=\"NO_OVERVIEWS\"\n",
    "        )\n",
    "    \n",
    "    # Add StartTime field and populate from item Name\n",
    "    if \"StartTime\" not in [f.name for f in arcpy.ListFields(H3_MD)]:\n",
    "        arcpy.management.AddField(H3_MD, \"StartTime\", \"DATE\")\n",
    "    \n",
    "    code_block = \"\"\"import datetime\n",
    "def parse_name(nm):\n",
    "    # expects 'h3_YYYYMMDD_HHMM' \n",
    "    return datetime.datetime.strptime(nm[-13:], '%Y%m%d_%H%M')\n",
    "\"\"\"\n",
    "    arcpy.management.CalculateField(H3_MD, \"StartTime\", \"parse_name(!Name!)\", \"PYTHON3\", code_block)\n",
    "    \n",
    "    # Build pyramids & stats\n",
    "    arcpy.management.BuildPyramidsandStatistics(H3_MD, skip_existing=\"OVERWRITE\")\n",
    "    print(f\"✅ H3 Resolution 7: {len(h3_created)} time slices → {H3_MD}\")\n",
    "else:\n",
    "    print(\"⚠️ No H3 mosaic dataset created (no H3 rasters generated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Per-bin Kernel Density (1 km cell, 18 km radius) saved to the GDB\n",
    "created = []\n",
    "cur = start\n",
    "print(PTS_METERS)\n",
    "# create local geojson/gdb\n",
    "while cur <= tmax:\n",
    "    print(cur)\n",
    "    nxt = cur + dt.timedelta(hours=BIN_HOURS)\n",
    "    where = (f\"{arcpy.AddFieldDelimiters(PTS_METERS, TIME_FIELD)} >= TIMESTAMP '{cur:%Y-%m-%d %H:%M:%S}' \"\n",
    "             f\"AND {arcpy.AddFieldDelimiters(PTS_METERS, TIME_FIELD)} < TIMESTAMP '{nxt:%Y-%m-%d %H:%M:%S}'\")\n",
    "\n",
    "    lyr_name = os.path.join(\"memory\\\\\", f\"bin_{cur:%Y%m%d_%H%M}\")\n",
    "    arcpy.conversion.ExportFeatures(\n",
    "        in_features=PTS_METERS,\n",
    "        out_features=lyr_name,\n",
    "        where_clause=where,\n",
    "        #use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "        #field_mapping='city_name \"city_name\" true true false 80 Text 0 0,First,#,cities_CUMULATIVE_ALL,city_name,0,79;city_id \"city_id\" true true false 18 Double 0 18,First,#,cities_CUMULATIVE_ALL,city_id,-1,-1;population \"population\" true true false 18 Double 0 18,First,#,cities_CUMULATIVE_ALL,population,-1,-1;cumul_cnt \"cumul_cnt\" true true false 18 Double 0 18,First,#,cities_CUMULATIVE_ALL,cumul_cnt,-1,-1;time_bin \"time_bin\" true true false 80 Text 0 0,First,#,cities_CUMULATIVE_ALL,time_bin,0,79',\n",
    "        #sort_field=None\n",
    "    )\n",
    "    try:\n",
    "        if int(arcpy.management.GetCount(lyr_name).getOutput(0)) > 0:\n",
    "            out_name = f\"{PREFIX}{cur:%Y%m%d_%H%M}\"\n",
    "            out_path = os.path.join(GDB, out_name)\n",
    "            if arcpy.Exists(out_path):\n",
    "                arcpy.management.Delete(out_path)\n",
    "\n",
    "            kd = KernelDensity(\n",
    "                in_features=lyr_name,\n",
    "                population_field=pop_var,\n",
    "                cell_size=CELL_SIZE_M,\n",
    "                search_radius=RADIUS_M,\n",
    "                out_cell_values=\"DENSITIES\",\n",
    "                method=\"PLANAR\"\n",
    "            )\n",
    "            \n",
    "            kd.save(out_path)\n",
    "            created.append(out_name)\n",
    "            \n",
    "    except Exception:\n",
    "        raise RuntimeError(\"KernelDensity failed:\\n\" + arcpy.GetMessages(2))   \n",
    "    # arcpy.management.Delete(lyr_name)\n",
    "    \n",
    "    cur = nxt\n",
    "\n",
    "if not created:\n",
    "    raise RuntimeError(\"No rasters created. Check time field values and bin size.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Create a time-aware Mosaic Dataset and add the rasters we just made\n",
    "print(GDB, MD_NAME)\n",
    "if arcpy.Exists(os.path.join(GDB, MD_NAME)):\n",
    "    arcpy.management.Delete(os.path.join(GDB, MD_NAME))\n",
    "timestamp = time.time()\n",
    "MD_NAME = f\"KD_{current_file}_{pop_str}_{int(timestamp)}\"\n",
    "\n",
    "# Just create it. Don't check, don't delete, don't reuse.\n",
    "MD = arcpy.management.CreateMosaicDataset(\n",
    "    in_workspace=GDB,\n",
    "    in_mosaicdataset_name=MD_NAME,\n",
    "    coordinate_system=sr,\n",
    "    pixel_type=\"32_BIT_FLOAT\"\n",
    ").getOutput(0)\n",
    "\n",
    "# Add each slice explicitly (robust for FGDB rasters)\n",
    "for nm in created:\n",
    "    print(nm)\n",
    "    arcpy.management.AddRastersToMosaicDataset(\n",
    "        in_mosaic_dataset=MD,\n",
    "        raster_type=\"Raster Dataset\",\n",
    "        input_path=os.path.join(GDB, nm),\n",
    "        update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "        update_boundary=\"UPDATE_BOUNDARY\",\n",
    "        update_overviews=\"NO_OVERVIEWS\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Add StartTime on the mosaic items and populate from item Name (kd_YYYYMMDD_HHMM)\n",
    "if \"StartTime\" not in [f.name for f in arcpy.ListFields(MD)]:\n",
    "    arcpy.management.AddField(MD, \"StartTime\", \"DATE\")\n",
    "\n",
    "code_block = \"\"\"import datetime\n",
    "def parse_name(nm):\n",
    "    # expects 'kd_YYYYMMDD_HHMM' \n",
    "    return datetime.datetime.strptime(nm[-13:], '%Y%m%d_%H%M')\n",
    "\"\"\"\n",
    "arcpy.management.CalculateField(MD, \"StartTime\", \"parse_name(!Name!)\", \"PYTHON3\", code_block)\n",
    "# arcpy.management.EnableTime(MD, \"StartTime\", \"Single\", timeStepInterval=str(BIN_HOURS), timeStepUnits=\"HOURS\")\n",
    "\n",
    "# Build pyramids & stats (correct function name/case)\n",
    "arcpy.management.BuildPyramidsandStatistics(MD, skip_existing=\"OVERWRITE\")\n",
    "print(f\"OK: {len(created)} KDE slices → {MD}\")\n",
    "# arcpy.management.Delete(kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
