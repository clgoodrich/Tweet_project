{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-19T20:48:36.753731Z",
     "start_time": "2025-09-19T20:48:36.630791Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Load GeoJSON files\n",
    "francine_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\geojson\\francine.geojson\"\n",
    "helene_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\geojson\\helene.geojson\"\n",
    "\n",
    "# Load into GeoDataFrames\n",
    "francine_gdf = gpd.read_file(francine_path)\n",
    "helene_gdf = gpd.read_file(helene_path)\n",
    "\n",
    "# Standardize timestamps to UTC\n",
    "francine_gdf['timestamp'] = pd.to_datetime(francine_gdf['time'], utc=True)\n",
    "# print(francine_gdf['time'])\n",
    "helene_gdf['timestamp'] = pd.to_datetime(helene_gdf['time'], utc=True)\n",
    "\n",
    "\n",
    "# Floor to 4-hour bins\n",
    "francine_gdf['time_bin'] = francine_gdf['timestamp'].dt.floor('4h')\n",
    "helene_gdf['time_bin'] = helene_gdf['timestamp'].dt.floor('4h')\n",
    "all_data = francine_gdf['time_bin'].unique()\n",
    "francine_gdf['unix_timestamp'] = francine_gdf['time_bin'].astype('int64') // 1000\n",
    "helene_gdf['unix_timestamp'] = helene_gdf['time_bin'].astype('int64') // 1000\n",
    "# Create readable bin labels for file naming\n",
    "francine_gdf['bin_label'] = francine_gdf['time_bin'].dt.strftime('%Y%m%d_%H%M')\n",
    "helene_gdf['bin_label'] = helene_gdf['time_bin'].dt.strftime('%Y%m%d_%H%M')\n",
    "# Display summary\n",
    "print(\"FRANCINE Dataset:\")\n",
    "print(f\"  Total tweets: {len(francine_gdf)}\")\n",
    "print(f\"  Time range: {francine_gdf['time_bin'].min()} to {francine_gdf['time_bin'].max()}\")\n",
    "print(f\"  Number of 4-hour bins: {francine_gdf['time_bin'].nunique()}\")\n",
    "print(f\"\\nHELENE Dataset:\")\n",
    "print(f\"  Total tweets: {len(helene_gdf)}\")\n",
    "print(f\"  Time range: {helene_gdf['time_bin'].min()} to {helene_gdf['time_bin'].max()}\")\n",
    "print(f\"  Number of 4-hour bins: {helene_gdf['time_bin'].nunique()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRANCINE Dataset:\n",
      "  Total tweets: 2303\n",
      "  Time range: 2024-09-09 08:00:00+00:00 to 2024-09-16 12:00:00+00:00\n",
      "  Number of 4-hour bins: 42\n",
      "\n",
      "HELENE Dataset:\n",
      "  Total tweets: 3007\n",
      "  Time range: 2024-09-26 00:00:00+00:00 to 2024-09-27 16:00:00+00:00\n",
      "  Number of 4-hour bins: 11\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T20:48:37.650823Z",
     "start_time": "2025-09-19T20:48:36.759578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load reference shapefiles\n",
    "states_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\shape_files\\cb_2023_us_state_20m.shp\"\n",
    "counties_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\shape_files\\cb_2023_us_county_20m.shp\"\n",
    "cities_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\tables\\cities1000.csv\"\n",
    "\n",
    "# Load spatial reference data\n",
    "states_gdf = gpd.read_file(states_path)\n",
    "counties_gdf = gpd.read_file(counties_path)\n",
    "cities_df = pd.read_csv(cities_path)\n",
    "\n",
    "# Create lookup dictionaries for matching\n",
    "# States: NAME field maps to geometry\n",
    "state_lookup = dict(zip(states_gdf['NAME'].str.upper(), states_gdf.geometry))\n",
    "\n",
    "# Counties: NAME field maps to geometry\n",
    "county_lookup = dict(zip(counties_gdf['NAME'].str.upper(), counties_gdf.geometry))\n",
    "\n",
    "# Cities: name field with coordinates for point creation\n",
    "cities_lookup = dict(zip(cities_df['name'].str.upper(),\n",
    "                        gpd.points_from_xy(cities_df['longitude'], cities_df['latitude'])))\n",
    "\n",
    "# Function to assign scale level and matched geometry\n",
    "def assign_scale_level(row):\n",
    "    \"\"\"Determine geographic scale and match to geometry\"\"\"\n",
    "    gpe = str(row.get('GPE', '')).upper().strip()\n",
    "    fac = str(row.get('FAC', '')).upper().strip()\n",
    "\n",
    "    # Priority: State > County > City > Facility\n",
    "    if gpe in state_lookup:\n",
    "        return 'STATE', gpe, state_lookup[gpe]\n",
    "    elif gpe in county_lookup:\n",
    "        return 'COUNTY', gpe, county_lookup[gpe]\n",
    "    elif gpe in cities_lookup:\n",
    "        return 'CITY', gpe, cities_lookup[gpe]\n",
    "    elif fac and fac != 'NAN':\n",
    "        return 'FACILITY', fac, row.geometry  # Use tweet's geocoded point\n",
    "    else:\n",
    "        return 'UNMATCHED', None, row.geometry\n",
    "\n",
    "# Apply to both datasets\n",
    "francine_gdf[['scale_level', 'matched_name', 'matched_geom']] = francine_gdf.apply(\n",
    "    assign_scale_level, axis=1, result_type='expand')\n",
    "\n",
    "helene_gdf[['scale_level', 'matched_name', 'matched_geom']] = helene_gdf.apply(\n",
    "    assign_scale_level, axis=1, result_type='expand')\n",
    "\n",
    "# Display scale distribution\n",
    "print(\"FRANCINE Scale Distribution:\")\n",
    "print(francine_gdf['scale_level'].value_counts())\n",
    "print(f\"\\nHELENE Scale Distribution:\")\n",
    "print(helene_gdf['scale_level'].value_counts())"
   ],
   "id": "102cf233829866a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colto\\AppData\\Local\\Temp\\ipykernel_54096\\3948738291.py:9: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cities_df = pd.read_csv(cities_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRANCINE Scale Distribution:\n",
      "scale_level\n",
      "STATE        1270\n",
      "UNMATCHED     698\n",
      "CITY          276\n",
      "COUNTY         32\n",
      "FACILITY       27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HELENE Scale Distribution:\n",
      "scale_level\n",
      "STATE        1673\n",
      "UNMATCHED     962\n",
      "CITY          248\n",
      "FACILITY       76\n",
      "COUNTY         48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T20:48:37.724659Z",
     "start_time": "2025-09-19T20:48:37.709218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group tweets by 4-hour intervals and scale level\n",
    "# Using unix_timestamp for unambiguous temporal grouping\n",
    "\n",
    "# Alternative approach:\n",
    "francine_interval_counts = francine_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).agg({\n",
    "    'matched_geom': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Add count column separately\n",
    "count_series = francine_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).size()\n",
    "francine_interval_counts['count'] = count_series.values\n",
    "\n",
    "# Same for Helene\n",
    "helene_interval_counts = helene_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).agg({\n",
    "    'matched_geom': 'first'\n",
    "}).reset_index()\n",
    "count_series = helene_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).size()\n",
    "helene_interval_counts['count'] = count_series.values\n",
    "\n",
    "# Sort by timestamp to ensure chronological order\n",
    "francine_interval_counts = francine_interval_counts.sort_values('unix_timestamp')\n",
    "helene_interval_counts = helene_interval_counts.sort_values('unix_timestamp')\n",
    "\n",
    "# Calculate cumulative counts\n",
    "francine_interval_counts['cumulative_count'] = francine_interval_counts.groupby(['scale_level', 'matched_name'])['count'].cumsum()\n",
    "helene_interval_counts['cumulative_count'] = helene_interval_counts.groupby(['scale_level', 'matched_name'])['count'].cumsum()\n",
    "\n",
    "# Get unique time bins for iteration\n",
    "francine_time_bins = sorted(francine_gdf['unix_timestamp'].unique())\n",
    "helene_time_bins = sorted(helene_gdf['unix_timestamp'].unique())\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"FRANCINE Time Binning Summary:\")\n",
    "print(f\"  Total time bins: {len(francine_time_bins)}\")\n",
    "print(f\"  Total location-time combinations: {len(francine_interval_counts)}\")\n",
    "print(f\"\\nSample interval counts:\")\n",
    "print(francine_interval_counts.head(10))\n",
    "\n",
    "print(f\"\\nHELENE Time Binning Summary:\")\n",
    "print(f\"  Total time bins: {len(helene_time_bins)}\")\n",
    "print(f\"  Total location-time combinations: {len(helene_interval_counts)}\")\n",
    "print(f\"\\nSample interval counts:\")\n",
    "print(helene_interval_counts.head(10))"
   ],
   "id": "95d5ae7c58fc2af4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRANCINE Time Binning Summary:\n",
      "  Total time bins: 42\n",
      "  Total location-time combinations: 250\n",
      "\n",
      "Sample interval counts:\n",
      "   unix_timestamp scale_level matched_name  \\\n",
      "0      1725868800       STATE    LOUISIANA   \n",
      "1      1725868800       STATE        TEXAS   \n",
      "2      1725883200      COUNTY       DALLAS   \n",
      "3      1725883200       STATE     ARKANSAS   \n",
      "4      1725883200       STATE    LOUISIANA   \n",
      "5      1725883200       STATE        TEXAS   \n",
      "6      1725897600    FACILITY         I-10   \n",
      "7      1725897600       STATE    LOUISIANA   \n",
      "8      1725897600       STATE  MISSISSIPPI   \n",
      "9      1725912000      COUNTY    LAFAYETTE   \n",
      "\n",
      "                                        matched_geom  count  cumulative_count  \n",
      "0  POLYGON ((-94.0430515276176 32.6930299766656, ...      1                 1  \n",
      "1  POLYGON ((-106.623445 31.914034, -106.630114 3...      1                 1  \n",
      "2  POLYGON ((-97.036295 32.693227, -97.035996 32....      1                 1  \n",
      "3  POLYGON ((-94.617919 36.499414, -94.361203 36....      1                 1  \n",
      "4  POLYGON ((-94.0430515276176 32.6930299766656, ...      9                10  \n",
      "5  POLYGON ((-106.623445 31.914034, -106.630114 3...      1                 2  \n",
      "6                    POINT (-89.6379454 30.30428515)      2                 2  \n",
      "7  POLYGON ((-94.0430515276176 32.6930299766656, ...     24                34  \n",
      "8  POLYGON ((-91.621358 31.267811, -91.564192 31....      3                 3  \n",
      "9  POLYGON ((-94.106764 39.091703, -94.104823 39....      2                 2  \n",
      "\n",
      "HELENE Time Binning Summary:\n",
      "  Total time bins: 11\n",
      "  Total location-time combinations: 252\n",
      "\n",
      "Sample interval counts:\n",
      "   unix_timestamp scale_level                    matched_name  \\\n",
      "0      1727308800        CITY                    BLOWING ROCK   \n",
      "1      1727308800        CITY                   LAWRENCEVILLE   \n",
      "2      1727308800        CITY                           OCALA   \n",
      "3      1727308800        CITY                         ORLANDO   \n",
      "4      1727308800        CITY                     TALLAHASSEE   \n",
      "5      1727308800      COUNTY                       CHARLOTTE   \n",
      "6      1727308800      COUNTY                         RALEIGH   \n",
      "7      1727308800    FACILITY  PORT CANAVERAL, PORT CANAVERAL   \n",
      "8      1727308800    FACILITY          RIVER CITY MARKETPLACE   \n",
      "9      1727308800       STATE                         FLORIDA   \n",
      "\n",
      "                                        matched_geom  count  cumulative_count  \n",
      "0                         POINT (-81.67761 36.13513)      1                 1  \n",
      "1                          POINT (-74.7296 40.29733)      1                 1  \n",
      "2                          POINT (-82.14009 29.1872)      1                 1  \n",
      "3                         POINT (-81.37924 28.53834)      1                 1  \n",
      "4                         POINT (-84.28073 30.43826)      1                 1  \n",
      "5  POLYGON ((-78.904587 37.022288, -78.824209 37....      1                 1  \n",
      "6  POLYGON ((-81.571534 37.927707, -81.456632 37....      1                 1  \n",
      "7                      POINT (-80.629588 28.4071344)      2                 2  \n",
      "8              POINT (-81.64087344210384 30.4769187)      1                 1  \n",
      "9  MULTIPOLYGON (((-81.811693 24.568745, -81.7512...     44                44  \n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T20:48:37.759624Z",
     "start_time": "2025-09-19T20:48:37.730033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 1: DEFINE MASTER GRID CANVAS\n",
    "# ==============================================================================\n",
    "\n",
    "# Configuration\n",
    "TARGET_CRS = 'EPSG:3857'  # Web Mercator\n",
    "CELL_SIZE_M = 5000  # 5 km in meters\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: CREATING MASTER GRID CANVAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Project both datasets to target CRS\n",
    "print(f\"\\nProjecting datasets to {TARGET_CRS}...\")\n",
    "francine_proj = francine_gdf.to_crs(TARGET_CRS)\n",
    "helene_proj = helene_gdf.to_crs(TARGET_CRS)\n",
    "\n",
    "# Also project reference geometries\n",
    "print(\"Projecting reference geometries...\")\n",
    "states_proj = states_gdf.to_crs(TARGET_CRS)\n",
    "counties_proj = counties_gdf.to_crs(TARGET_CRS)\n",
    "\n",
    "# Calculate combined extent from both hurricanes\n",
    "print(\"\\nCalculating master extent...\")\n",
    "francine_bounds = francine_proj.total_bounds\n",
    "helene_bounds = helene_proj.total_bounds\n",
    "\n",
    "# Get union of both bounding boxes\n",
    "minx = min(francine_bounds[0], helene_bounds[0])\n",
    "miny = min(francine_bounds[1], helene_bounds[1])\n",
    "maxx = max(francine_bounds[2], helene_bounds[2])\n",
    "maxy = max(francine_bounds[3], helene_bounds[3])\n",
    "\n",
    "print(f\"  Master bounds (EPSG:3857):\")\n",
    "print(f\"    minx: {minx:,.2f}\")\n",
    "print(f\"    miny: {miny:,.2f}\")\n",
    "print(f\"    maxx: {maxx:,.2f}\")\n",
    "print(f\"    maxy: {maxy:,.2f}\")\n",
    "\n",
    "# Calculate grid dimensions\n",
    "width = int(np.ceil((maxx - minx) / CELL_SIZE_M))\n",
    "height = int(np.ceil((maxy - miny) / CELL_SIZE_M))\n",
    "\n",
    "print(f\"\\nGrid Configuration:\")\n",
    "print(f\"  Cell size: {CELL_SIZE_M:,} meters ({CELL_SIZE_M/1000} km)\")\n",
    "print(f\"  Grid dimensions: {width} x {height} cells\")\n",
    "print(f\"  Total cells: {width * height:,}\")\n",
    "\n",
    "# Create master transform\n",
    "master_transform = from_bounds(minx, miny, maxx, maxy, width, height)\n",
    "\n",
    "print(f\"\\nMaster Transform:\")\n",
    "print(f\"  {master_transform}\")\n",
    "\n",
    "# Calculate actual coverage area\n",
    "area_km2 = (width * height * CELL_SIZE_M * CELL_SIZE_M) / 1_000_000\n",
    "print(f\"\\nCoverage area: {area_km2:,.2f} km²\")\n",
    "\n",
    "# Store grid parameters for later use\n",
    "grid_params = {\n",
    "    'crs': TARGET_CRS,\n",
    "    'cell_size': CELL_SIZE_M,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'bounds': (minx, miny, maxx, maxy),\n",
    "    'transform': master_transform\n",
    "}\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"MASTER GRID CANVAS READY ✓\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Update lookup dictionaries with projected geometries\n",
    "print(\"\\nUpdating geometry lookups with projected coordinates...\")\n",
    "state_lookup_proj = dict(zip(states_proj['NAME'].str.upper(), states_proj.geometry))\n",
    "county_lookup_proj = dict(zip(counties_proj['NAME'].str.upper(), counties_proj.geometry))\n",
    "\n",
    "print(\"Lookup dictionaries updated with projected geometries ✓\")"
   ],
   "id": "5bd77653518eadb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: CREATING MASTER GRID CANVAS\n",
      "============================================================\n",
      "\n",
      "Projecting datasets to EPSG:3857...\n",
      "Projecting reference geometries...\n",
      "\n",
      "Calculating master extent...\n",
      "  Master bounds (EPSG:3857):\n",
      "    minx: -11,854,083.11\n",
      "    miny: 2,947,395.71\n",
      "    maxx: -8,490,833.94\n",
      "    maxy: 5,142,357.36\n",
      "\n",
      "Grid Configuration:\n",
      "  Cell size: 5,000 meters (5.0 km)\n",
      "  Grid dimensions: 673 x 439 cells\n",
      "  Total cells: 295,447\n",
      "\n",
      "Master Transform:\n",
      "  | 4997.40, 0.00,-11854083.11|\n",
      "| 0.00,-4999.91, 5142357.36|\n",
      "| 0.00, 0.00, 1.00|\n",
      "\n",
      "Coverage area: 7,386,175.00 km²\n",
      "\n",
      "============================================================\n",
      "MASTER GRID CANVAS READY ✓\n",
      "============================================================\n",
      "\n",
      "Updating geometry lookups with projected coordinates...\n",
      "Lookup dictionaries updated with projected geometries ✓\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T20:48:38.708586Z",
     "start_time": "2025-09-19T20:48:37.763939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.features import geometry_mask\n",
    "# ==============================================================================\n",
    "# STEP 2: MAIN RASTERIZATION LOOP - TIME ITERATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Create output directories\n",
    "output_dir = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def process_hurricane(hurricane_name, gdf_proj, interval_counts, time_bins):\n",
    "    \"\"\"\n",
    "    Process a single hurricane through all time bins\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"PROCESSING: {hurricane_name.upper()}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    # Create hurricane-specific output directory\n",
    "    hurricane_dir = os.path.join(output_dir, hurricane_name.lower())\n",
    "    os.makedirs(hurricane_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize cumulative grid (persists across time bins)\n",
    "    cumulative_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Loop through each time bin chronologically\n",
    "    for idx, time_bin in enumerate(time_bins):\n",
    "        print(f\"\\n--- Time Bin {idx+1}/{len(time_bins)}: {time_bin} ---\")\n",
    "\n",
    "        # Filter data for current time bin\n",
    "        current_data = interval_counts[interval_counts['unix_timestamp'] == time_bin]\n",
    "        tweet_count = len(current_data)\n",
    "        print(f\"  Tweets in this bin: {tweet_count}\")\n",
    "\n",
    "        # Initialize incremental grid for this time bin\n",
    "        incremental_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "        # === PLACEHOLDER FUNCTIONS ===\n",
    "\n",
    "        # 1. Create State Raster\n",
    "        state_raster = create_state_raster(current_data, grid_params)\n",
    "        incremental_grid += state_raster\n",
    "\n",
    "        # 2. Create County Raster\n",
    "        county_raster = create_county_raster(current_data, grid_params)\n",
    "        incremental_grid += county_raster\n",
    "\n",
    "        # 3. Create City/Point Raster\n",
    "        city_raster = create_city_raster(current_data, grid_params)\n",
    "        incremental_grid += city_raster\n",
    "\n",
    "        # 4. Create Facility/KDE Raster\n",
    "        facility_raster = create_facility_raster(current_data, grid_params)\n",
    "        incremental_grid += facility_raster\n",
    "\n",
    "        # === END PLACEHOLDERS ===\n",
    "\n",
    "        # Update cumulative grid\n",
    "        cumulative_grid += incremental_grid\n",
    "\n",
    "        # Save rasters\n",
    "        save_raster(incremental_grid, hurricane_dir, hurricane_name, time_bin, 'increment')\n",
    "        save_raster(cumulative_grid, hurricane_dir, hurricane_name, time_bin, 'cumulative')\n",
    "\n",
    "        print(f\"  Incremental max value: {np.max(incremental_grid):.2f}\")\n",
    "        print(f\"  Cumulative max value: {np.max(cumulative_grid):.2f}\")\n",
    "\n",
    "    print(f\"\\n{hurricane_name.upper()} processing complete!\")\n",
    "    print(f\"Output saved to: {hurricane_dir}\")\n",
    "    return\n",
    "\n",
    "# ==============================================================================\n",
    "# PLACEHOLDER FUNCTIONS (TO BE IMPLEMENTED)\n",
    "# ==============================================================================\n",
    "\n",
    "def create_state_raster(data, grid_params):\n",
    "    \"\"\"Rasterize state-level tweets\"\"\"\n",
    "    print(\"    [STATE] Creating state raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    state_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for STATE-level tweets only\n",
    "    state_data = data[data['scale_level'] == 'STATE']\n",
    "\n",
    "    if len(state_data) == 0:\n",
    "        print(\"      No state-level tweets in this time bin\")\n",
    "        return state_grid\n",
    "\n",
    "    # Group by state name and sum counts\n",
    "    state_counts = state_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(state_counts)} unique states\")\n",
    "\n",
    "    # Process each state\n",
    "    for state_name, tweet_count in state_counts.items():\n",
    "        if state_name in state_lookup_proj:\n",
    "            # Get the state geometry\n",
    "            state_geom = state_lookup_proj[state_name]\n",
    "\n",
    "            # Rasterize the polygon\n",
    "            # Create a list of (geometry, value) tuples\n",
    "            shapes = [(state_geom, 1)]\n",
    "\n",
    "            # Rasterize to temporary grid\n",
    "            temp_grid = rasterio.features.rasterize(\n",
    "                shapes=shapes,\n",
    "                out_shape=(grid_params['height'], grid_params['width']),\n",
    "                transform=grid_params['transform'],\n",
    "                fill=0,\n",
    "                dtype=np.float32,\n",
    "                all_touched=True  # Include all pixels touched by polygon\n",
    "            )\n",
    "\n",
    "            # Multiply by tweet count and add to state grid\n",
    "            state_grid += temp_grid * tweet_count\n",
    "\n",
    "            print(f\"      - {state_name}: {tweet_count} tweets, {np.sum(temp_grid)} pixels\")\n",
    "        else:\n",
    "            print(f\"      WARNING: State '{state_name}' not found in lookup\")\n",
    "\n",
    "    total_value = np.sum(state_grid)\n",
    "    max_value = np.max(state_grid)\n",
    "    print(f\"      Total state grid value: {total_value:.0f}, Max pixel: {max_value:.0f}\")\n",
    "\n",
    "    return state_grid\n",
    "\n",
    "def create_county_raster(data, grid_params):\n",
    "    \"\"\"Rasterize county-level tweets with hotspot multiplier\"\"\"\n",
    "    print(\"    [COUNTY] Creating county raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    county_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for COUNTY-level tweets only\n",
    "    county_data = data[data['scale_level'] == 'COUNTY']\n",
    "\n",
    "    if len(county_data) == 0:\n",
    "        print(\"      No county-level tweets in this time bin\")\n",
    "        return county_grid\n",
    "\n",
    "    # Group by county name and sum counts\n",
    "    county_counts = county_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(county_counts)} unique counties\")\n",
    "\n",
    "    # HOTSPOT MULTIPLIER for counties\n",
    "    county_multiplier = 3  # Make counties 3x more prominent\n",
    "\n",
    "    # Process each county\n",
    "    for county_name, tweet_count in county_counts.items():\n",
    "        if county_name in county_lookup_proj:\n",
    "            # Get the county geometry\n",
    "            county_geom = county_lookup_proj[county_name]\n",
    "\n",
    "            # Rasterize the polygon\n",
    "            shapes = [(county_geom, 1)]\n",
    "\n",
    "            # Rasterize to temporary grid\n",
    "            temp_grid = rasterize(\n",
    "                shapes=shapes,\n",
    "                out_shape=(grid_params['height'], grid_params['width']),\n",
    "                transform=grid_params['transform'],\n",
    "                fill=0,\n",
    "                dtype=np.float32,\n",
    "                all_touched=True  # Include all pixels touched by polygon\n",
    "            )\n",
    "\n",
    "            # Multiply by tweet count AND multiplier for hotspot effect\n",
    "            county_grid += temp_grid * tweet_count * county_multiplier\n",
    "\n",
    "            print(f\"      - {county_name}: {tweet_count} tweets × {county_multiplier} = {tweet_count * county_multiplier}, {np.sum(temp_grid)} pixels\")\n",
    "        else:\n",
    "            print(f\"      WARNING: County '{county_name}' not found in lookup\")\n",
    "\n",
    "    total_value = np.sum(county_grid)\n",
    "    max_value = np.max(county_grid)\n",
    "    print(f\"      Total county grid value: {total_value:.0f}, Max pixel: {max_value:.0f}\")\n",
    "\n",
    "    return county_grid\n",
    "\n",
    "def create_city_raster(data, grid_params):\n",
    "    \"\"\"Rasterize city-level tweets with smaller buffer and hotspot multiplier\"\"\"\n",
    "    print(\"    [CITY] Creating city raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    city_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for CITY-level tweets only\n",
    "    city_data = data[data['scale_level'] == 'CITY']\n",
    "\n",
    "    if len(city_data) == 0:\n",
    "        print(\"      No city-level tweets in this time bin\")\n",
    "        return city_grid\n",
    "\n",
    "    # Group by city name and sum counts\n",
    "    city_counts = city_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(city_counts)} unique cities\")\n",
    "\n",
    "    # HOTSPOT PARAMETERS for cities\n",
    "    buffer_distance = 2500  # Reduced from 5000m to 2.5km for tighter hotspots\n",
    "    city_multiplier = 5     # Make cities 5x more prominent\n",
    "\n",
    "    # Process each city\n",
    "    for city_name, tweet_count in city_counts.items():\n",
    "        if city_name in cities_lookup:\n",
    "            # Get the city point geometry\n",
    "            city_point = cities_lookup[city_name]\n",
    "\n",
    "            # Need to project the point to match our grid CRS\n",
    "            # Create a temporary GeoSeries to handle projection\n",
    "            city_geoseries = gpd.GeoSeries([city_point], crs='EPSG:4326')\n",
    "            city_point_proj = city_geoseries.to_crs(grid_params['crs']).iloc[0]\n",
    "\n",
    "            # Create buffer around the point (2.5km)\n",
    "            city_buffer = city_point_proj.buffer(buffer_distance)\n",
    "\n",
    "            # Rasterize the buffered polygon\n",
    "            shapes = [(city_buffer, 1)]\n",
    "\n",
    "            # Rasterize to temporary grid\n",
    "            temp_grid = rasterize(\n",
    "                shapes=shapes,\n",
    "                out_shape=(grid_params['height'], grid_params['width']),\n",
    "                transform=grid_params['transform'],\n",
    "                fill=0,\n",
    "                dtype=np.float32,\n",
    "                all_touched=True  # Include all pixels touched by buffer\n",
    "            )\n",
    "\n",
    "            # Multiply by tweet count AND multiplier for hotspot effect\n",
    "            city_grid += temp_grid * tweet_count * city_multiplier\n",
    "\n",
    "            print(f\"      - {city_name}: {tweet_count} tweets × {city_multiplier} = {tweet_count * city_multiplier}, {np.sum(temp_grid)} pixels\")\n",
    "        else:\n",
    "            print(f\"      WARNING: City '{city_name}' not found in lookup\")\n",
    "\n",
    "    total_value = np.sum(city_grid)\n",
    "    max_value = np.max(city_grid)\n",
    "    print(f\"      Total city grid value: {total_value:.0f}, Max pixel: {max_value:.0f}\")\n",
    "\n",
    "    return city_grid\n",
    "\n",
    "def create_facility_raster(data, grid_params):\n",
    "    \"\"\"Create KDE raster for facility points with strong hotspot multiplier\"\"\"\n",
    "    print(\"    [FACILITY] Creating facility raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    facility_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for FACILITY-level tweets only\n",
    "    facility_data = data[data['scale_level'] == 'FACILITY']\n",
    "\n",
    "    if len(facility_data) == 0:\n",
    "        print(\"      No facility-level tweets in this time bin\")\n",
    "        return facility_grid\n",
    "\n",
    "    # Group by facility coordinates (using matched_name as proxy) and sum counts\n",
    "    facility_counts = facility_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(facility_counts)} unique facilities\")\n",
    "\n",
    "    # HOTSPOT PARAMETERS for facilities\n",
    "    sigma_meters = 2 * grid_params['cell_size']  # 10 km for 5km cells\n",
    "    sigma_pixels = sigma_meters / grid_params['cell_size']  # Convert to pixel units\n",
    "    facility_multiplier = 10  # Make facilities 10x more prominent (strongest hotspots)\n",
    "\n",
    "    # Process each facility\n",
    "    facilities_processed = 0\n",
    "    for facility_name, tweet_count in facility_counts.items():\n",
    "        # Get facility data to extract geometry\n",
    "        facility_rows = facility_data[facility_data['matched_name'] == facility_name]\n",
    "\n",
    "        if len(facility_rows) > 0:\n",
    "            # Get the point geometry (should be from the tweet's geocoded location)\n",
    "            facility_point = facility_rows.iloc[0]['matched_geom']\n",
    "\n",
    "            # Project point to grid CRS if needed\n",
    "            if hasattr(facility_point, 'x') and hasattr(facility_point, 'y'):\n",
    "                # Create GeoSeries to handle projection\n",
    "                point_geoseries = gpd.GeoSeries([facility_point], crs='EPSG:4326')\n",
    "                point_proj = point_geoseries.to_crs(grid_params['crs']).iloc[0]\n",
    "\n",
    "                # Convert point coordinates to pixel indices\n",
    "                px = (point_proj.x - grid_params['bounds'][0]) / grid_params['cell_size']\n",
    "                py = (grid_params['bounds'][3] - point_proj.y) / grid_params['cell_size']\n",
    "\n",
    "                # Check if point is within grid bounds\n",
    "                if 0 <= px < grid_params['width'] and 0 <= py < grid_params['height']:\n",
    "                    # Create point raster with tweet count at location\n",
    "                    point_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "                    point_grid[int(py), int(px)] = tweet_count\n",
    "\n",
    "                    # Apply Gaussian filter to create kernel density\n",
    "                    kernel_grid = gaussian_filter(point_grid, sigma=sigma_pixels, mode='constant', cval=0)\n",
    "\n",
    "                    # FIXED: Only add once with proper multiplier\n",
    "                    facility_grid += kernel_grid * facility_multiplier\n",
    "\n",
    "                    facilities_processed += 1\n",
    "                    effective_value = tweet_count * facility_multiplier\n",
    "                    print(f\"      - {facility_name}: {tweet_count} tweets × {facility_multiplier} = {effective_value}, KDE at ({point_proj.x:.0f}, {point_proj.y:.0f})\")\n",
    "                else:\n",
    "                    print(f\"      WARNING: Facility '{facility_name}' outside grid bounds\")\n",
    "            else:\n",
    "                print(f\"      WARNING: Invalid geometry for facility '{facility_name}'\")\n",
    "\n",
    "    print(f\"      Processed {facilities_processed} facilities with sigma={sigma_pixels:.2f} pixels\")\n",
    "\n",
    "    total_value = np.sum(facility_grid)\n",
    "    max_value = np.max(facility_grid)\n",
    "    print(f\"      Total facility grid value: {total_value:.2f}, Max pixel: {max_value:.2f}\")\n",
    "\n",
    "    return facility_grid\n",
    "\n",
    "def save_raster(grid, output_dir, hurricane_name, time_bin, raster_type):\n",
    "    \"\"\"Save raster as GeoTIFF\"\"\"\n",
    "    # Convert unix timestamp to readable format for filename\n",
    "    print('binny', time_bin)\n",
    "    # time_str = pd.Timestamp(time_bin, unit='ns').strftime('%Y%m%d_%H%M')\n",
    "    filename = f\"{hurricane_name}_{raster_type}_{time_bin}.tif\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    with rasterio.open(\n",
    "        filepath, 'w',\n",
    "        driver='GTiff',\n",
    "        height=grid_params['height'],\n",
    "        width=grid_params['width'],\n",
    "        count=1,\n",
    "        dtype=grid.dtype,\n",
    "        crs=grid_params['crs'],\n",
    "        transform=grid_params['transform'],\n",
    "        compress='lzw'\n",
    "    ) as dst:\n",
    "        dst.write(grid, 1)\n",
    "\n",
    "    print(f\"    Saved: {filename}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECUTE PROCESSING FOR BOTH HURRICANES\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STARTING RASTERIZATION PROCESS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process Francine\n",
    "# process_hurricane('francine', francine_proj, francine_interval_counts, francine_time_bins)\n",
    "\n",
    "# Process Helene\n",
    "process_hurricane('helene', helene_proj, helene_interval_counts, helene_time_bins)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL PROCESSING COMPLETE! ✓\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "2e1bc16e47f51e00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING RASTERIZATION PROCESS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING: HELENE\n",
      "============================================================\n",
      "\n",
      "--- Time Bin 1/11: 1727308800 ---\n",
      "  Tweets in this bin: 11\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 2 unique states\n",
      "      - FLORIDA: 44 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 1 tweets, 8879.0 pixels\n",
      "      Total state grid value: 365895, Max pixel: 45\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 2 unique counties\n",
      "      - CHARLOTTE: 1 tweets × 3 = 3, 110.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 130.0 pixels\n",
      "      Total county grid value: 720, Max pixel: 3\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 5 unique cities\n",
      "      - BLOWING ROCK: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - LAWRENCEVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - OCALA: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - ORLANDO: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - TALLAHASSEE: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      Total city grid value: 65, Max pixel: 5\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      - PORT CANAVERAL, PORT CANAVERAL: 2 tweets × 10 = 20, KDE at (-8975645, 3300402)\n",
      "      - RIVER CITY MARKETPLACE: 1 tweets × 10 = 10, KDE at (-9088220, 3565002)\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 30.00, Max pixel: 0.80\n",
      "binny 1727308800\n",
      "    Saved: helene_increment_1727308800.tif\n",
      "binny 1727308800\n",
      "    Saved: helene_cumulative_1727308800.tif\n",
      "  Incremental max value: 49.00\n",
      "  Cumulative max value: 49.00\n",
      "\n",
      "--- Time Bin 2/11: 1727323200 ---\n",
      "  Tweets in this bin: 16\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 6 unique states\n",
      "      - ALABAMA: 1 tweets, 7854.0 pixels\n",
      "      - FLORIDA: 77 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 2 tweets, 8879.0 pixels\n",
      "      - NORTH CAROLINA: 1 tweets, 7921.0 pixels\n",
      "      - OHIO: 1 tweets, 7589.0 pixels\n",
      "      - VIRGINIA: 2 tweets, 6782.0 pixels\n",
      "      Total state grid value: 679464, Max pixel: 80\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 2 unique counties\n",
      "      - BREVARD: 1 tweets × 3 = 3, 221.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 130.0 pixels\n",
      "      Total county grid value: 1053, Max pixel: 3\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 7 unique cities\n",
      "      - APALACHICOLA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ATLANTA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - CINCINNATI: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - DOTHAN: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ORLANDO: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - TALLAHASSEE: 4 tweets × 5 = 20, 3.0 pixels\n",
      "      - TAMPA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      Total city grid value: 155, Max pixel: 20\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 1 unique facilities\n",
      "      - BLUE RIDGE PARKWAY: 1 tweets × 10 = 10, KDE at (-9096483, 4320972)\n",
      "      Processed 1 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 10.00, Max pixel: 0.40\n",
      "binny 1727323200\n",
      "    Saved: helene_increment_1727323200.tif\n",
      "binny 1727323200\n",
      "    Saved: helene_cumulative_1727323200.tif\n",
      "  Incremental max value: 97.00\n",
      "  Cumulative max value: 146.00\n",
      "\n",
      "--- Time Bin 3/11: 1727337600 ---\n",
      "  Tweets in this bin: 14\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 6 unique states\n",
      "      - FLORIDA: 116 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 4 tweets, 8879.0 pixels\n",
      "      - NORTH CAROLINA: 1 tweets, 7921.0 pixels\n",
      "      - OHIO: 2 tweets, 7589.0 pixels\n",
      "      - TENNESSEE: 1 tweets, 6933.0 pixels\n",
      "      - VIRGINIA: 1 tweets, 6782.0 pixels\n",
      "      Total state grid value: 1013554, Max pixel: 120\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 3 unique counties\n",
      "      - BROWARD: 1 tweets × 3 = 3, 184.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 130.0 pixels\n",
      "      - SARASOTA: 1 tweets × 3 = 3, 98.0 pixels\n",
      "      Total county grid value: 1236, Max pixel: 3\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 5 unique cities\n",
      "      - ATLANTA: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - MYRTLE BEACH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - NASHVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - TALLAHASSEE: 2 tweets × 5 = 10, 3.0 pixels\n",
      "      - TAMPA: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      Total city grid value: 90, Max pixel: 10\n",
      "    [FACILITY] Creating facility raster...\n",
      "      No facility-level tweets in this time bin\n",
      "binny 1727337600\n",
      "    Saved: helene_increment_1727337600.tif\n",
      "binny 1727337600\n",
      "    Saved: helene_cumulative_1727337600.tif\n",
      "  Incremental max value: 126.00\n",
      "  Cumulative max value: 272.00\n",
      "\n",
      "--- Time Bin 4/11: 1727352000 ---\n",
      "  Tweets in this bin: 19\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 5 unique states\n",
      "      - ALABAMA: 1 tweets, 7854.0 pixels\n",
      "      - FLORIDA: 78 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 5 tweets, 8879.0 pixels\n",
      "      - OHIO: 1 tweets, 7589.0 pixels\n",
      "      - VIRGINIA: 4 tweets, 6782.0 pixels\n",
      "      Total state grid value: 719858, Max pixel: 84\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 3 unique counties\n",
      "      - CHARLESTON: 1 tweets × 3 = 3, 215.0 pixels\n",
      "      - MACON: 1 tweets × 3 = 3, 171.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 130.0 pixels\n",
      "      Total county grid value: 1548, Max pixel: 3\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 8 unique cities\n",
      "      - APALACHICOLA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ATLANTA: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - HARTSELLE: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - MEMPHIS: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ORLANDO: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - PENSACOLA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - TALLAHASSEE: 11 tweets × 5 = 55, 3.0 pixels\n",
      "      - TAMPA: 4 tweets × 5 = 20, 4.0 pixels\n",
      "      Total city grid value: 340, Max pixel: 55\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 3 unique facilities\n",
      "      - DISNEY WORLD: 1 tweets × 10 = 10, KDE at (-9068478, 3315080)\n",
      "      - DOLLYWOOD THEME PARK: 1 tweets × 10 = 10, KDE at (-9298731, 4272492)\n",
      "      - HAMPTON SPRINGS RD: 1 tweets × 10 = 10, KDE at (-9302606, 3517358)\n",
      "      Processed 3 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 30.00, Max pixel: 0.40\n",
      "binny 1727352000\n",
      "    Saved: helene_increment_1727352000.tif\n",
      "binny 1727352000\n",
      "    Saved: helene_cumulative_1727352000.tif\n",
      "  Incremental max value: 133.00\n",
      "  Cumulative max value: 405.00\n",
      "\n",
      "--- Time Bin 5/11: 1727366400 ---\n",
      "  Tweets in this bin: 23\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 6 unique states\n",
      "      - FLORIDA: 134 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 7 tweets, 8879.0 pixels\n",
      "      - NORTH CAROLINA: 2 tweets, 7921.0 pixels\n",
      "      - SOUTH CAROLINA: 1 tweets, 4909.0 pixels\n",
      "      - VIRGINIA: 1 tweets, 6782.0 pixels\n",
      "      - WEST VIRGINIA: 2 tweets, 4395.0 pixels\n",
      "      Total state grid value: 1185752, Max pixel: 141\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 4 unique counties\n",
      "      - CHARLOTTE: 1 tweets × 3 = 3, 110.0 pixels\n",
      "      - MACON: 1 tweets × 3 = 3, 171.0 pixels\n",
      "      - MIAMI: 1 tweets × 3 = 3, 91.0 pixels\n",
      "      - SARASOTA: 1 tweets × 3 = 3, 98.0 pixels\n",
      "      Total county grid value: 1410, Max pixel: 3\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 10 unique cities\n",
      "      - ASHEVILLE: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ATLANTA: 3 tweets × 5 = 15, 0.0 pixels\n",
      "      - MEMPHIS: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - MULBERRY: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - NORTH SARASOTA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - PEACHTREE CITY: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - PORT RICHEY: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - SAVANNAH: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - TALLAHASSEE: 12 tweets × 5 = 60, 3.0 pixels\n",
      "      - TAMPA: 5 tweets × 5 = 25, 4.0 pixels\n",
      "      Total city grid value: 410, Max pixel: 60\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 3 unique facilities\n",
      "      - BAYSHORE BOULEVARD: 2 tweets × 10 = 20, KDE at (-9180541, 3240507)\n",
      "      - THE DON CESAR: 1 tweets × 10 = 10, KDE at (-9210272, 3212369)\n",
      "      - VOLUSIA MALL: 1 tweets × 10 = 10, KDE at (-9023994, 3400729)\n",
      "      Processed 3 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 40.00, Max pixel: 0.80\n",
      "binny 1727366400\n",
      "    Saved: helene_increment_1727366400.tif\n",
      "binny 1727366400\n",
      "    Saved: helene_cumulative_1727366400.tif\n",
      "  Incremental max value: 194.00\n",
      "  Cumulative max value: 599.00\n",
      "\n",
      "--- Time Bin 6/11: 1727380800 ---\n",
      "  Tweets in this bin: 33\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 4 unique states\n",
      "      - ALABAMA: 7 tweets, 7854.0 pixels\n",
      "      - FLORIDA: 192 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 8 tweets, 8879.0 pixels\n",
      "      - NORTH CAROLINA: 1 tweets, 7921.0 pixels\n",
      "      Total state grid value: 1691819, Max pixel: 207\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 8 unique counties\n",
      "      - CHARLOTTE: 2 tweets × 3 = 6, 110.0 pixels\n",
      "      - CLEARWATER: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - LEXINGTON: 1 tweets × 3 = 3, 146.0 pixels\n",
      "      - MIAMI: 1 tweets × 3 = 3, 91.0 pixels\n",
      "      - RALEIGH: 2 tweets × 3 = 6, 130.0 pixels\n",
      "      - SARASOTA: 1 tweets × 3 = 3, 98.0 pixels\n",
      "      - SPARTANBURG: 2 tweets × 3 = 6, 157.0 pixels\n",
      "      - WAKULLA: 1 tweets × 3 = 3, 116.0 pixels\n",
      "      Total county grid value: 3735, Max pixel: 6\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 11 unique cities\n",
      "      - ALPHARETTA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ATLANTA: 5 tweets × 5 = 25, 0.0 pixels\n",
      "      - FORT MYERS BEACH: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - GREENSBORO: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - JACKSONVILLE: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - JENSEN BEACH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - OCALA: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - PORT RICHEY: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - SANDY SPRINGS: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - TALLAHASSEE: 14 tweets × 5 = 70, 3.0 pixels\n",
      "      - TAMPA: 18 tweets × 5 = 90, 4.0 pixels\n",
      "      Total city grid value: 735, Max pixel: 90\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 10 unique facilities\n",
      "      - BAYSHORE BOULEVARD: 1 tweets × 10 = 10, KDE at (-9180541, 3240507)\n",
      "      - BRONSON HIGH SCHOOL: 1 tweets × 10 = 10, KDE at (-9198240, 3435062)\n",
      "      - BUOY 42036: 2 tweets × 10 = 20, KDE at (-9804933, 4361859)\n",
      "      - DUPONT STATE RECREATIONAL FOREST: 1 tweets × 10 = 10, KDE at (-9195700, 4190827)\n",
      "      - JACKSONVILLE INTERNATIONAL AIRPORT: 1 tweets × 10 = 10, KDE at (-9094027, 3567176)\n",
      "      - LIDO KEY: 1 tweets × 10 = 10, KDE at (-9192929, 3163132)\n",
      "      - MATLACHA BRIDGE: 1 tweets × 10 = 10, KDE at (-9135754, 3077645)\n",
      "      - NAPLES BOTANICAL GARDEN: 1 tweets × 10 = 10, KDE at (-9102767, 3012202)\n",
      "      - PORT CANAVERAL: 1 tweets × 10 = 10, KDE at (-8973278, 3300894)\n",
      "      - YANKEE CLIPPERS: 1 tweets × 10 = 10, KDE at (-9132236, 3957949)\n",
      "      Processed 10 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 110.00, Max pixel: 0.80\n",
      "binny 1727380800\n",
      "    Saved: helene_increment_1727380800.tif\n",
      "binny 1727380800\n",
      "    Saved: helene_cumulative_1727380800.tif\n",
      "  Incremental max value: 282.40\n",
      "  Cumulative max value: 861.00\n",
      "\n",
      "--- Time Bin 7/11: 1727395200 ---\n",
      "  Tweets in this bin: 23\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 4 unique states\n",
      "      - FLORIDA: 193 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 5 tweets, 8879.0 pixels\n",
      "      - SOUTH CAROLINA: 1 tweets, 4909.0 pixels\n",
      "      - VIRGINIA: 1 tweets, 6782.0 pixels\n",
      "      Total state grid value: 1622088, Max pixel: 198\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 3 unique counties\n",
      "      - MIAMI: 2 tweets × 3 = 6, 91.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 130.0 pixels\n",
      "      - SARASOTA: 1 tweets × 3 = 3, 98.0 pixels\n",
      "      Total county grid value: 1230, Max pixel: 6\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 13 unique cities\n",
      "      - ALPHARETTA: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - APALACHICOLA: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - ASHEVILLE: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ATLANTA: 4 tweets × 5 = 20, 0.0 pixels\n",
      "      - FORT MYERS: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - FORT MYERS BEACH: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - GIBSONTON: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - NASHVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - PANAMA CITY BEACH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - SANDY SPRINGS: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - TALLAHASSEE: 13 tweets × 5 = 65, 3.0 pixels\n",
      "      - TAMPA: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - TARPON SPRINGS: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      Total city grid value: 445, Max pixel: 65\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 3 unique facilities\n",
      "      - 242A, 247: 1 tweets × 10 = 10, KDE at (-9202420, 3526538)\n",
      "      - HOWARD FRANKLAND BRIDGE: 1 tweets × 10 = 10, KDE at (-9193573, 3239927)\n",
      "      - I-4: 5 tweets × 10 = 50, KDE at (-9164827, 3289065)\n",
      "      Processed 3 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 70.00, Max pixel: 1.99\n",
      "binny 1727395200\n",
      "    Saved: helene_increment_1727395200.tif\n",
      "binny 1727395200\n",
      "    Saved: helene_cumulative_1727395200.tif\n",
      "  Incremental max value: 258.00\n",
      "  Cumulative max value: 1119.00\n",
      "\n",
      "--- Time Bin 8/11: 1727409600 ---\n",
      "  Tweets in this bin: 32\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 5 unique states\n",
      "      - FLORIDA: 212 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 24 tweets, 8879.0 pixels\n",
      "      - KENTUCKY: 1 tweets, 6965.0 pixels\n",
      "      - OHIO: 1 tweets, 7589.0 pixels\n",
      "      - SOUTH CAROLINA: 1 tweets, 4909.0 pixels\n",
      "      Total state grid value: 1952727, Max pixel: 236\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 5 unique counties\n",
      "      - CLEARWATER: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - MIAMI: 1 tweets × 3 = 3, 91.0 pixels\n",
      "      - PETERSBURG: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 130.0 pixels\n",
      "      - SARASOTA: 1 tweets × 3 = 3, 98.0 pixels\n",
      "      Total county grid value: 957, Max pixel: 3\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 8 unique cities\n",
      "      - ATLANTA: 5 tweets × 5 = 25, 0.0 pixels\n",
      "      - BRADENTON: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - DANIA BEACH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - PALM HARBOR: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - SAVANNAH: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - TALLAHASSEE: 4 tweets × 5 = 20, 3.0 pixels\n",
      "      - TAMPA: 3 tweets × 5 = 15, 4.0 pixels\n",
      "      - VALDOSTA: 4 tweets × 5 = 20, 4.0 pixels\n",
      "      Total city grid value: 270, Max pixel: 20\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 14 unique facilities\n",
      "      - 10739 BELLS HIGHWAY: 2 tweets × 10 = 20, KDE at (-8981612, 3885315)\n",
      "      - BYRON BUTLER PKWY: 1 tweets × 10 = 10, KDE at (-9303717, 3515353)\n",
      "      - CALF PEN BAY ROAD: 2 tweets × 10 = 20, KDE at (-9033572, 3842579)\n",
      "      - CARTERS MILL ROAD: 2 tweets × 10 = 20, KDE at (-9016686, 3826049)\n",
      "      - DEERFIELD ROAD: 2 tweets × 10 = 20, KDE at (-8881541, 4074355)\n",
      "      - FORT MOORE/COLUMBUS: 1 tweets × 10 = 10, KDE at (-9450569, 3817899)\n",
      "      - FREEDOM PARKWAY: 4 tweets × 10 = 40, KDE at (-9024535, 3791434)\n",
      "      - I-4: 3 tweets × 10 = 30, KDE at (-9176064, 3244613)\n",
      "      - SISTERS FERRY ROAD: 2 tweets × 10 = 20, KDE at (-9015044, 3826712)\n",
      "      - SMITHS XING: 2 tweets × 10 = 20, KDE at (-9013555, 3825200)\n",
      "      - THE BLUE RIDGE PARKWAY: 1 tweets × 10 = 10, KDE at (-9182381, 4240996)\n",
      "      - US-21: 2 tweets × 10 = 20, KDE at (-8979369, 3815535)\n",
      "      - US15: 2 tweets × 10 = 20, KDE at (-8904239, 3875360)\n",
      "      - VENETIAN ISLES: 1 tweets × 10 = 10, KDE at (-9194159, 3225907)\n",
      "      Processed 14 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 270.00, Max pixel: 2.33\n",
      "binny 1727409600\n",
      "    Saved: helene_increment_1727409600.tif\n",
      "binny 1727409600\n",
      "    Saved: helene_cumulative_1727409600.tif\n",
      "  Incremental max value: 236.00\n",
      "  Cumulative max value: 1351.00\n",
      "\n",
      "--- Time Bin 9/11: 1727424000 ---\n",
      "  Tweets in this bin: 21\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 7 unique states\n",
      "      - FLORIDA: 167 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 46 tweets, 8879.0 pixels\n",
      "      - KENTUCKY: 1 tweets, 6965.0 pixels\n",
      "      - NORTH CAROLINA: 6 tweets, 7921.0 pixels\n",
      "      - OHIO: 2 tweets, 7589.0 pixels\n",
      "      - SOUTH CAROLINA: 1 tweets, 4909.0 pixels\n",
      "      - VIRGINIA: 2 tweets, 6782.0 pixels\n",
      "      Total state grid value: 1851614, Max pixel: 213\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 3 unique counties\n",
      "      - CHARLOTTE: 1 tweets × 3 = 3, 110.0 pixels\n",
      "      - HILLSBOROUGH: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - MACON: 1 tweets × 3 = 3, 171.0 pixels\n",
      "      Total county grid value: 843, Max pixel: 3\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 8 unique cities\n",
      "      - ATLANTA: 10 tweets × 5 = 50, 0.0 pixels\n",
      "      - DANIA BEACH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - FORT MYERS: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - JACKSONVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - LOUISVILLE: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - SOPERTON: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - STEINHATCHEE: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - TAMPA: 4 tweets × 5 = 20, 4.0 pixels\n",
      "      Total city grid value: 220, Max pixel: 20\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 3 unique facilities\n",
      "      - CAPITOL: 1 tweets × 10 = 10, KDE at (-9394048, 3995156)\n",
      "      - HARTSFIELD-JACKSON: 1 tweets × 10 = 10, KDE at (-9398684, 3980217)\n",
      "      - I-4: 1 tweets × 10 = 10, KDE at (-9176064, 3244613)\n",
      "      Processed 3 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 30.00, Max pixel: 0.56\n",
      "binny 1727424000\n",
      "    Saved: helene_increment_1727424000.tif\n",
      "binny 1727424000\n",
      "    Saved: helene_cumulative_1727424000.tif\n",
      "  Incremental max value: 213.00\n",
      "  Cumulative max value: 1518.00\n",
      "\n",
      "--- Time Bin 10/11: 1727438400 ---\n",
      "  Tweets in this bin: 34\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 8 unique states\n",
      "      - ALABAMA: 1 tweets, 7854.0 pixels\n",
      "      - FLORIDA: 137 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 14 tweets, 8879.0 pixels\n",
      "      - KENTUCKY: 3 tweets, 6965.0 pixels\n",
      "      - NORTH CAROLINA: 6 tweets, 7921.0 pixels\n",
      "      - OHIO: 1 tweets, 7589.0 pixels\n",
      "      - SOUTH CAROLINA: 1 tweets, 4909.0 pixels\n",
      "      - VIRGINIA: 2 tweets, 6782.0 pixels\n",
      "      Total state grid value: 1338261, Max pixel: 152\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 2 unique counties\n",
      "      - MIAMI: 4 tweets × 3 = 12, 91.0 pixels\n",
      "      - SARASOTA: 1 tweets × 3 = 3, 98.0 pixels\n",
      "      Total county grid value: 1386, Max pixel: 12\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 14 unique cities\n",
      "      - APPALACHIA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ATLANTA: 14 tweets × 5 = 70, 0.0 pixels\n",
      "      - CLEMSON: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - HARTSELLE: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - JACKSONVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - LAKELAND: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - LOUISVILLE: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - MYRTLE BEACH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - NASHVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - ORLANDO: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - SAVANNAH: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - TALLAHASSEE: 3 tweets × 5 = 15, 3.0 pixels\n",
      "      - TAMPA: 5 tweets × 5 = 25, 4.0 pixels\n",
      "      - VALDOSTA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      Total city grid value: 315, Max pixel: 25\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 10 unique facilities\n",
      "      - ABRAHAM LINCOLN BIRTHPLACE NATIONAL HISTORICAL PARK: 1 tweets × 10 = 10, KDE at (-9533710, 4524728)\n",
      "      - AMALIE ARENA: 2 tweets × 10 = 20, KDE at (-9178502, 3241752)\n",
      "      - BUSCH GARDENS: 1 tweets × 10 = 10, KDE at (-9175093, 3253650)\n",
      "      - GREENBRIER RESORT: 1 tweets × 10 = 10, KDE at (-9301588, 4278100)\n",
      "      - I-4: 1 tweets × 10 = 10, KDE at (-9176064, 3244613)\n",
      "      - ST. PETE BEACH: 1 tweets × 10 = 10, KDE at (-9210710, 3214385)\n",
      "      - STEEPLE CLUB: 1 tweets × 10 = 10, KDE at (-9381305, 3564197)\n",
      "      - THE MEMPHIS INTERNATIONAL AIRPORT: 1 tweets × 10 = 10, KDE at (-10016182, 4170169)\n",
      "      - TRADITION HALL: 1 tweets × 10 = 10, KDE at (-8796000, 4002137)\n",
      "      - US 431: 1 tweets × 10 = 10, KDE at (-9601747, 4068260)\n",
      "      Processed 10 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 110.00, Max pixel: 1.34\n",
      "binny 1727438400\n",
      "    Saved: helene_increment_1727438400.tif\n",
      "binny 1727438400\n",
      "    Saved: helene_cumulative_1727438400.tif\n",
      "  Incremental max value: 163.34\n",
      "  Cumulative max value: 1670.40\n",
      "\n",
      "--- Time Bin 11/11: 1727452800 ---\n",
      "  Tweets in this bin: 26\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 7 unique states\n",
      "      - FLORIDA: 82 tweets, 8114.0 pixels\n",
      "      - GEORGIA: 30 tweets, 8879.0 pixels\n",
      "      - NORTH CAROLINA: 15 tweets, 7921.0 pixels\n",
      "      - OHIO: 4 tweets, 7589.0 pixels\n",
      "      - SOUTH CAROLINA: 10 tweets, 4909.0 pixels\n",
      "      - TENNESSEE: 3 tweets, 6933.0 pixels\n",
      "      - VIRGINIA: 2 tweets, 6782.0 pixels\n",
      "      Total state grid value: 1164342, Max pixel: 112\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 5 unique counties\n",
      "      - ATHENS: 1 tweets × 3 = 3, 105.0 pixels\n",
      "      - CLEVELAND: 1 tweets × 3 = 3, 114.0 pixels\n",
      "      - PINELLAS: 1 tweets × 3 = 3, 75.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 130.0 pixels\n",
      "      - SARASOTA: 2 tweets × 3 = 6, 98.0 pixels\n",
      "      Total county grid value: 1860, Max pixel: 6\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 9 unique cities\n",
      "      - ASHEVILLE: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - ATLANTA: 8 tweets × 5 = 40, 0.0 pixels\n",
      "      - BONITA SPRINGS: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - CINCINNATI: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - DUNWOODY: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - PORT CHARLOTTE: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - STEINHATCHEE: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - TALLAHASSEE: 4 tweets × 5 = 20, 3.0 pixels\n",
      "      - TAMPA: 3 tweets × 5 = 15, 4.0 pixels\n",
      "      Total city grid value: 230, Max pixel: 20\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 5 unique facilities\n",
      "      - BAYSHORE BOULEVARD: 1 tweets × 10 = 10, KDE at (-9180541, 3240507)\n",
      "      - I-40: 1 tweets × 10 = 10, KDE at (-9678056, 4313198)\n",
      "      - LAKE LURE DAM: 2 tweets × 10 = 20, KDE at (-9148680, 4221901)\n",
      "      - PASS-A-GRILLE BEACH: 1 tweets × 10 = 10, KDE at (-9210518, 3212923)\n",
      "      - SARASOTA - BEACH ROAD: 1 tweets × 10 = 10, KDE at (-9178151, 3133363)\n",
      "      Processed 5 facilities with sigma=2.00 pixels\n",
      "      Total facility grid value: 60.00, Max pixel: 0.80\n",
      "binny 1727452800\n",
      "    Saved: helene_increment_1727452800.tif\n",
      "binny 1727452800\n",
      "    Saved: helene_cumulative_1727452800.tif\n",
      "  Incremental max value: 112.00\n",
      "  Cumulative max value: 1772.40\n",
      "\n",
      "HELENE processing complete!\n",
      "Output saved to: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\n",
      "\n",
      "============================================================\n",
      "ALL PROCESSING COMPLETE! ✓\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T20:48:39.360291Z",
     "start_time": "2025-09-19T20:48:38.790241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# STEP 5: POST-PROCESSING & ASSEMBLY\n",
    "# ==============================================================================\n",
    "import glob\n",
    "# from osgeo import gdal\n",
    "from rasterio.vrt import WarpedVRT\n",
    "def create_metadata_index(hurricane_name, hurricane_dir):\n",
    "    \"\"\"Create CSV index of all rasters with metadata\"\"\"\n",
    "    print(f\"\\nCreating metadata index for {hurricane_name}...\")\n",
    "\n",
    "    # Get all increment and cumulative TIFFs\n",
    "    increment_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\")))\n",
    "    cumulative_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_cumulative_*.tif\")))\n",
    "\n",
    "    metadata_rows = []\n",
    "\n",
    "    for tif_path in increment_files + cumulative_files:\n",
    "        filename = os.path.basename(tif_path)\n",
    "\n",
    "        # Extract time and type from filename\n",
    "        parts = filename.replace('.tif', '').split('_')\n",
    "        raster_type = parts[-2]  # 'increment' or 'cumulative'\n",
    "        time_str = parts[-1]     # e.g., '20240910_0000'\n",
    "\n",
    "        # Open raster to get stats\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            data = src.read(1)\n",
    "\n",
    "            metadata_rows.append({\n",
    "                'filename': filename,\n",
    "                'type': raster_type,\n",
    "                'time_str': time_str,\n",
    "                'min_value': np.min(data),\n",
    "                'max_value': np.max(data),\n",
    "                'mean_value': np.mean(data),\n",
    "                'total_value': np.sum(data),\n",
    "                'non_zero_pixels': np.count_nonzero(data)\n",
    "            })\n",
    "\n",
    "    # Create DataFrame and save\n",
    "    metadata_df = pd.DataFrame(metadata_rows)\n",
    "    index_path = os.path.join(hurricane_dir, f\"{hurricane_name}_index.csv\")\n",
    "    metadata_df.to_csv(index_path, index=False)\n",
    "\n",
    "    print(f\"  Index saved: {index_path}\")\n",
    "    print(f\"  Total rasters cataloged: {len(metadata_rows)}\")\n",
    "\n",
    "    return metadata_df\n",
    "\n",
    "\n",
    "def create_vrt_stacks(hurricane_name, hurricane_dir):\n",
    "    \"\"\"Create VRT files using rasterio (no GDAL needed)\"\"\"\n",
    "    print(f\"\\nCreating VRT stacks for {hurricane_name}...\")\n",
    "\n",
    "    # Simply skip VRT creation or create a text-based reference file\n",
    "    increment_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\")))\n",
    "\n",
    "    # Create a simple text list file instead\n",
    "    list_file = os.path.join(hurricane_dir, f\"{hurricane_name}_increment_files.txt\")\n",
    "    with open(list_file, 'w') as f:\n",
    "        for file in increment_files:\n",
    "            f.write(file + '\\n')\n",
    "\n",
    "    print(f\"  Created file list: {hurricane_name}_increment_files.txt\")\n",
    "    print(f\"  Import these files directly in ArcGIS Pro\")\n",
    "\n",
    "def print_summary_stats(hurricane_name, hurricane_dir):\n",
    "    \"\"\"Print summary statistics for the hurricane dataset\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUMMARY: {hurricane_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    increment_files = glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\"))\n",
    "    cumulative_files = glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_cumulative_*.tif\"))\n",
    "\n",
    "    print(f\"  Total time slices: {len(increment_files)}\")\n",
    "    print(f\"  Increment rasters: {len(increment_files)}\")\n",
    "    print(f\"  Cumulative rasters: {len(cumulative_files)}\")\n",
    "    print(f\"  Output directory: {hurricane_dir}\")\n",
    "\n",
    "    # Get final cumulative stats\n",
    "    if cumulative_files:\n",
    "        final_cumulative = sorted(cumulative_files)[-1]\n",
    "        with rasterio.open(final_cumulative) as src:\n",
    "            final_data = src.read(1)\n",
    "            print(f\"\\n  Final Cumulative Statistics:\")\n",
    "            print(f\"    Total value: {np.sum(final_data):,.0f}\")\n",
    "            print(f\"    Max pixel value: {np.max(final_data):,.2f}\")\n",
    "            print(f\"    Active pixels: {np.count_nonzero(final_data):,}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# RUN POST-PROCESSING\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: POST-PROCESSING & ASSEMBLY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Process Francine\n",
    "francine_dir = os.path.join(output_dir, 'francine')\n",
    "if os.path.exists(francine_dir):\n",
    "    francine_metadata = create_metadata_index('francine', francine_dir)\n",
    "    create_vrt_stacks('francine', francine_dir)\n",
    "    print_summary_stats('francine', francine_dir)\n",
    "\n",
    "# Process Helene\n",
    "helene_dir = os.path.join(output_dir, 'helene')\n",
    "if os.path.exists(helene_dir):\n",
    "    helene_metadata = create_metadata_index('helene', helene_dir)\n",
    "    create_vrt_stacks('helene', helene_dir)\n",
    "    print_summary_stats('helene', helene_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POST-PROCESSING COMPLETE! ✓\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Open ArcGIS Pro\")\n",
    "print(\"2. Add Multidimensional Raster Layer\")\n",
    "print(\"3. Point to the output folders\")\n",
    "print(\"4. Enable time slider for animation\")"
   ],
   "id": "20a24d59822d8736",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 5: POST-PROCESSING & ASSEMBLY\n",
      "============================================================\n",
      "\n",
      "Creating metadata index for francine...\n",
      "  Index saved: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\\francine_index.csv\n",
      "  Total rasters cataloged: 88\n",
      "\n",
      "Creating VRT stacks for francine...\n",
      "  Created file list: francine_increment_files.txt\n",
      "  Import these files directly in ArcGIS Pro\n",
      "\n",
      "============================================================\n",
      "SUMMARY: FRANCINE\n",
      "============================================================\n",
      "  Total time slices: 44\n",
      "  Increment rasters: 44\n",
      "  Cumulative rasters: 44\n",
      "  Output directory: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\n",
      "\n",
      "  Final Cumulative Statistics:\n",
      "    Total value: 0\n",
      "    Max pixel value: 0.00\n",
      "    Active pixels: 0\n",
      "\n",
      "Creating metadata index for helene...\n",
      "  Index saved: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\helene_index.csv\n",
      "  Total rasters cataloged: 22\n",
      "\n",
      "Creating VRT stacks for helene...\n",
      "  Created file list: helene_increment_files.txt\n",
      "  Import these files directly in ArcGIS Pro\n",
      "\n",
      "============================================================\n",
      "SUMMARY: HELENE\n",
      "============================================================\n",
      "  Total time slices: 11\n",
      "  Increment rasters: 11\n",
      "  Cumulative rasters: 11\n",
      "  Output directory: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\n",
      "\n",
      "  Final Cumulative Statistics:\n",
      "    Total value: 13,605,387\n",
      "    Max pixel value: 1,772.40\n",
      "    Active pixels: 70,069\n",
      "\n",
      "============================================================\n",
      "POST-PROCESSING COMPLETE! ✓\n",
      "============================================================\n",
      "\n",
      "Next Steps:\n",
      "1. Open ArcGIS Pro\n",
      "2. Add Multidimensional Raster Layer\n",
      "3. Point to the output folders\n",
      "4. Enable time slider for animation\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T20:48:39.366623Z",
     "start_time": "2025-09-19T20:48:39.364928Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "530b3a7a47b1f7d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
