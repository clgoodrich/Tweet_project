{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T19:34:30.621450Z",
     "start_time": "2025-10-08T19:34:30.618414Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install fuzzywuzzy python-Levenshtein geopandas pandas numpy matplotlib",
   "id": "203a6780cd79d505",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-08T19:34:30.907178Z",
     "start_time": "2025-10-08T19:34:30.640283Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# This cell handles the initial loading and preparation of the hurricane tweet data.\n",
    "# Key steps include:\n",
    "# 1. Importing necessary libraries for data manipulation, file paths, and time handling.\n",
    "# 2. Constructing file paths to the GeoJSON data for Hurricanes Francine and Helene.\n",
    "# 3. Loading the spatial data into GeoDataFrames.\n",
    "# 4. Standardizing all timestamps to Coordinated Universal Time (UTC).\n",
    "# 5. Aggregating the data into discrete 4-hour time bins for temporal analysis.\n",
    "# 6. Creating various time-related columns (Unix timestamps, readable labels) for later use.\n",
    "# =============================================================================\n",
    "\n",
    "# Import core libraries\n",
    "import geopandas as gpd  # Used for working with geospatial data.\n",
    "import pandas as pd      # Used for data manipulation and analysis in DataFrames.\n",
    "import os                # Provides a way of using operating system dependent functionality, like file paths.\n",
    "from datetime import datetime, timezone # Used for handling date and time objects.\n",
    "\n",
    "# --- 1. Load GeoJSON files ---\n",
    "# Get the parent directory of the current working directory to build relative paths.\n",
    "# This makes the script more portable as it doesn't rely on a hardcoded absolute path.\n",
    "local_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Define the relative paths to the GeoJSON files for each hurricane.\n",
    "francine_dir = r\"\\data\\geojson\\francine.geojson\"\n",
    "helene_dir = r\"\\data\\geojson\\helene.geojson\"\n",
    "\n",
    "# Combine the base path and relative directory to create full, absolute paths to the files.\n",
    "francine_path = f\"{local_path}{francine_dir}\"\n",
    "helene_path = f\"{local_path}{helene_dir}\"\n",
    "\n",
    "# --- 2. Load data into GeoDataFrames ---\n",
    "# A GeoDataFrame is a pandas DataFrame with a special 'geometry' column that allows for spatial operations.\n",
    "francine_gdf = gpd.read_file(francine_path)\n",
    "helene_gdf = gpd.read_file(helene_path)\n",
    "\n",
    "# --- 3. Standardize timestamps to UTC ---\n",
    "# Convert the original 'time' column into a pandas datetime object.\n",
    "# Setting `utc=True` ensures all timestamps are in a single, unambiguous timezone (UTC).\n",
    "# This is crucial for accurate temporal comparisons and binning.\n",
    "francine_gdf['timestamp'] = pd.to_datetime(francine_gdf['time'], utc=True)\n",
    "helene_gdf['timestamp'] = pd.to_datetime(helene_gdf['time'], utc=True)\n",
    "\n",
    "# --- 4. Group data into 4-hour time bins ---\n",
    "# The `dt.floor('4h')` function rounds each timestamp *down* to the nearest 4-hour interval.\n",
    "# For example, 09:35 becomes 08:00, 15:59 becomes 12:00. This aggregates tweets into discrete time windows.\n",
    "francine_gdf['time_bin'] = francine_gdf['timestamp'].dt.floor('4h')\n",
    "helene_gdf['time_bin'] = helene_gdf['timestamp'].dt.floor('4h')\n",
    "\n",
    "# --- 5. Create Unix timestamps and lookup dictionaries ---\n",
    "# Convert the binned datetime objects into Unix timestamps (as an integer).\n",
    "# The `// 1000` division is likely to convert from nanoseconds or microseconds to seconds, a more standard Unix format.\n",
    "francine_gdf['unix_timestamp'] = francine_gdf['time_bin'].astype('int64') // 1000\n",
    "helene_gdf['unix_timestamp'] = helene_gdf['time_bin'].astype('int64') // 1000\n",
    "\n",
    "# Create dictionaries to map the numeric Unix timestamp back to its original datetime object.\n",
    "# This provides a quick way to retrieve the readable time bin later in the script without recalculating it.\n",
    "helene_timestamp_dict = dict(zip(helene_gdf['unix_timestamp'], helene_gdf['time_bin']))\n",
    "francine_timestamp_dict = dict(zip(francine_gdf['unix_timestamp'], francine_gdf['time_bin']))\n",
    "\n",
    "# --- 6. Create readable labels for file naming ---\n",
    "# The `dt.strftime` function formats the datetime object into a specific string format.\n",
    "# Here, '%Y%m%d_%H%M' creates a clean, sortable label like '20240926_0800', which is ideal for filenames.\n",
    "francine_gdf['bin_label'] = francine_gdf['time_bin'].dt.strftime('%Y%m%d_%H%M')\n",
    "helene_gdf['bin_label'] = helene_gdf['time_bin'].dt.strftime('%Y%m%d_%H%M')"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T19:37:57.775564Z",
     "start_time": "2025-10-08T19:34:30.915492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load reference shapefiles\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "states_dir = r\"\\data\\shape_files\\cb_2023_us_state_20m.shp\"\n",
    "counties_dir = r\"\\data\\shape_files\\cb_2023_us_county_20m.shp\"\n",
    "cities_dir = r\"\\data\\shape_files\\US_Cities.shp\"\n",
    "states_path = f\"{local_path}{states_dir}\"\n",
    "counties_path = f\"{local_path}{counties_dir}\"\n",
    "cities_path = f\"{local_path}{cities_dir}\"\n",
    "\n",
    "\n",
    "# Load spatial reference data\n",
    "states_gdf = gpd.read_file(states_path)\n",
    "counties_gdf = gpd.read_file(counties_path)\n",
    "cities_gdf = gpd.read_file(cities_path)\n",
    "\n",
    "# PLACE THIS CODE AFTER LOADING SHAPEFILES BUT BEFORE CREATING SIMPLE LOOKUPS\n",
    "# =============================================================================\n",
    "# MULTI-LEVEL GEOGRAPHIC MATCHING SYSTEM (ALL LEVELS)\n",
    "# =============================================================================\n",
    "\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "def preprocess_place_name(name):\n",
    "    \"\"\"Standardize place names for better matching\"\"\"\n",
    "    if pd.isna(name) or name == 'NAN':\n",
    "        return None\n",
    "\n",
    "    name = str(name).upper().strip()\n",
    "\n",
    "    # Common abbreviation standardizations\n",
    "    name = re.sub(r'\\bST\\.?\\b', 'SAINT', name)  # St. -> Saint\n",
    "    name = re.sub(r'\\bMT\\.?\\b', 'MOUNT', name)  # Mt. -> Mount\n",
    "    name = re.sub(r'\\bFT\\.?\\b', 'FORT', name)   # Ft. -> Fort\n",
    "    name = re.sub(r'\\bN\\.?\\b', 'NORTH', name)   # N. -> North\n",
    "    name = re.sub(r'\\bS\\.?\\b', 'SOUTH', name)   # S. -> South\n",
    "    name = re.sub(r'\\bE\\.?\\b', 'EAST', name)    # E. -> East\n",
    "    name = re.sub(r'\\bW\\.?\\b', 'WEST', name)    # W. -> West\n",
    "\n",
    "    # Remove extra spaces and punctuation\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)  # Remove punctuation\n",
    "    name = re.sub(r'\\s+', ' ', name)     # Normalize spaces\n",
    "\n",
    "    return name.strip()\n",
    "\n",
    "def parse_gpe_entities(gpe_string):\n",
    "    \"\"\"Parse GPE string into multiple potential geographic entities\"\"\"\n",
    "    if not gpe_string or pd.isna(gpe_string) or str(gpe_string).strip() == '':\n",
    "        return []\n",
    "\n",
    "    gpe_string = str(gpe_string).strip()\n",
    "\n",
    "    # Split by common separators\n",
    "    entities = []\n",
    "\n",
    "    # Primary split by comma\n",
    "    parts = [part.strip() for part in gpe_string.split(',')]\n",
    "\n",
    "    for part in parts:\n",
    "        if part:\n",
    "            # Further split by other separators\n",
    "            sub_parts = re.split(r'[;&|]', part)\n",
    "            for sub_part in sub_parts:\n",
    "                sub_part = sub_part.strip()\n",
    "                if sub_part and len(sub_part) > 1:  # Ignore single characters\n",
    "                    entities.append(preprocess_place_name(sub_part))\n",
    "\n",
    "    # Remove None values and duplicates while preserving order\n",
    "    clean_entities = []\n",
    "    seen = set()\n",
    "    for entity in entities:\n",
    "        if entity and entity not in seen:\n",
    "            clean_entities.append(entity)\n",
    "            seen.add(entity)\n",
    "\n",
    "    return clean_entities\n",
    "\n",
    "def create_hierarchical_lookups(states_gdf, counties_gdf, cities_gdf):\n",
    "    \"\"\"Create hierarchical lookup dictionaries for fuzzy matching\"\"\"\n",
    "    print(\"\\nCreating hierarchical lookup dictionaries...\")\n",
    "\n",
    "    # 1. States - simple lookup with preprocessed names + abbreviations\n",
    "    state_lookup = {}\n",
    "    state_abbrev_to_name = {}  # Abbreviation to full name\n",
    "    state_name_to_abbrev = {}  # Full name to abbreviation\n",
    "\n",
    "    for idx, row in states_gdf.iterrows():\n",
    "        state_name = preprocess_place_name(row['NAME'])\n",
    "        if state_name:\n",
    "            state_lookup[state_name] = row.geometry\n",
    "            # Handle abbreviations if available\n",
    "            if 'STUSPS' in row:\n",
    "                abbrev = row['STUSPS'].upper()\n",
    "                state_abbrev_to_name[abbrev] = state_name\n",
    "                state_name_to_abbrev[state_name] = abbrev\n",
    "                # Also add abbreviation as a lookup option\n",
    "                state_lookup[abbrev] = row.geometry\n",
    "\n",
    "    # 2. Counties - organized by state\n",
    "    county_by_state = {}\n",
    "    county_lookup = {}\n",
    "\n",
    "    for idx, row in counties_gdf.iterrows():\n",
    "        county_name = preprocess_place_name(row['NAME'])\n",
    "        state_fips = row.get('STATEFP', '')\n",
    "\n",
    "        if county_name:\n",
    "            county_lookup[county_name] = row.geometry\n",
    "\n",
    "            # Try to get state name from STATEFP or other fields\n",
    "            state_name = None\n",
    "            if 'STATE_NAME' in row:\n",
    "                state_name = preprocess_place_name(row['STATE_NAME'])\n",
    "            else:\n",
    "                # Try to find state by FIPS code\n",
    "                for s_idx, s_row in states_gdf.iterrows():\n",
    "                    if s_row.get('STATEFP', '') == state_fips:\n",
    "                        state_name = preprocess_place_name(s_row['NAME'])\n",
    "                        break\n",
    "\n",
    "            if state_name:\n",
    "                if state_name not in county_by_state:\n",
    "                    county_by_state[state_name] = {}\n",
    "                county_by_state[state_name][county_name] = row.geometry\n",
    "\n",
    "    # 3. Cities - organized by state\n",
    "    city_by_state = {}\n",
    "    city_lookup = {}\n",
    "\n",
    "    for idx, row in cities_gdf.iterrows():\n",
    "        city_name = preprocess_place_name(row['NAME'])\n",
    "        state_abbrev = row.get('ST', '').upper()\n",
    "\n",
    "        if city_name:\n",
    "            city_lookup[city_name] = row.geometry\n",
    "\n",
    "            # Convert state abbreviation to full name\n",
    "            if state_abbrev in state_abbrev_to_name:\n",
    "                state_full = state_abbrev_to_name[state_abbrev]\n",
    "                if state_full not in city_by_state:\n",
    "                    city_by_state[state_full] = {}\n",
    "                city_by_state[state_full][city_name] = row.geometry\n",
    "    #\n",
    "\n",
    "\n",
    "    return {\n",
    "        'state_lookup': state_lookup,\n",
    "        'county_lookup': county_lookup,\n",
    "        'city_lookup': city_lookup,\n",
    "        'county_by_state': county_by_state,\n",
    "        'city_by_state': city_by_state,\n",
    "        'state_abbrev_to_name': state_abbrev_to_name,\n",
    "        'state_name_to_abbrev': state_name_to_abbrev\n",
    "    }\n",
    "\n",
    "def fuzzy_match_entity(entity, candidates, threshold=75):\n",
    "    \"\"\"Fuzzy match an entity against candidates\"\"\"\n",
    "    if not entity or not candidates:\n",
    "        return None, 0\n",
    "\n",
    "    # Try exact match first\n",
    "    if entity in candidates:\n",
    "        return entity, 100\n",
    "\n",
    "    # Use fuzzy matching\n",
    "    match = process.extractOne(entity, candidates.keys(), scorer=fuzz.ratio)\n",
    "\n",
    "    if match and match[1] >= threshold:\n",
    "        return match[0], match[1]\n",
    "\n",
    "    return None, 0\n",
    "\n",
    "def find_all_geographic_matches(entities, lookups):\n",
    "    \"\"\"Find ALL geographic matches (state, county, city) for the entities\"\"\"\n",
    "    if not entities:\n",
    "        return []\n",
    "\n",
    "    state_lookup = lookups['state_lookup']\n",
    "    county_lookup = lookups['county_lookup']\n",
    "    city_lookup = lookups['city_lookup']\n",
    "    county_by_state = lookups['county_by_state']\n",
    "    city_by_state = lookups['city_by_state']\n",
    "\n",
    "    # Store all successful matches\n",
    "    all_matches = []\n",
    "\n",
    "    # Context tracking for better matching\n",
    "    found_states = set()\n",
    "\n",
    "    # STEP 1: Find all state matches first\n",
    "    for entity in entities:\n",
    "        state_match, state_score = fuzzy_match_entity(entity, state_lookup, threshold=75)\n",
    "        if state_match:\n",
    "            all_matches.append(('STATE', state_match, state_lookup[state_match], state_score))\n",
    "            found_states.add(state_match)\n",
    "\n",
    "    # STEP 2: Find county matches (global first, then state-specific)\n",
    "    for entity in entities:\n",
    "        # Global county search\n",
    "        county_match, county_score = fuzzy_match_entity(entity, county_lookup, threshold=75)\n",
    "        if county_match:\n",
    "            all_matches.append(('COUNTY', county_match, county_lookup[county_match], county_score))\n",
    "\n",
    "        # State-specific county search (higher accuracy)\n",
    "        for state_name in found_states:\n",
    "            if state_name in county_by_state:\n",
    "                state_counties = county_by_state[state_name]\n",
    "                state_county_match, state_county_score = fuzzy_match_entity(entity, state_counties, threshold=70)\n",
    "                if state_county_match and state_county_score > county_score:\n",
    "                    # Replace with better state-specific match\n",
    "                    # Remove the global match if it exists\n",
    "                    all_matches = [m for m in all_matches if not (m[0] == 'COUNTY' and m[1] == county_match)]\n",
    "                    all_matches.append(('COUNTY', state_county_match, state_counties[state_county_match], state_county_score))\n",
    "\n",
    "    # STEP 3: Find city matches (global first, then state-specific)\n",
    "    for entity in entities:\n",
    "        # Global city search\n",
    "        city_match, city_score = fuzzy_match_entity(entity, city_lookup, threshold=75)\n",
    "        if city_match:\n",
    "            all_matches.append(('CITY', city_match, city_lookup[city_match], city_score))\n",
    "\n",
    "        # State-specific city search (higher accuracy)\n",
    "        for state_name in found_states:\n",
    "            if state_name in city_by_state:\n",
    "                state_cities = city_by_state[state_name]\n",
    "                state_city_match, state_city_score = fuzzy_match_entity(entity, state_cities, threshold=70)\n",
    "                if state_city_match and state_city_score > city_score:\n",
    "                    # Replace with better state-specific match\n",
    "                    # Remove the global match if it exists\n",
    "                    all_matches = [m for m in all_matches if not (m[0] == 'CITY' and m[1] == city_match)]\n",
    "                    all_matches.append(('CITY', state_city_match, state_cities[state_city_match], state_city_score))\n",
    "\n",
    "    # Remove duplicates (same scale + name)\n",
    "    unique_matches = []\n",
    "    seen_combinations = set()\n",
    "    for match in all_matches:\n",
    "        combo = (match[0], match[1])  # (scale, name)\n",
    "        if combo not in seen_combinations:\n",
    "            unique_matches.append(match)\n",
    "            seen_combinations.add(combo)\n",
    "\n",
    "    return unique_matches\n",
    "\n",
    "def multi_level_assign_scale_levels(row, lookups):\n",
    "    \"\"\"\n",
    "    Return ALL geographic scale levels that match this tweet\n",
    "    Returns a list of matches: [(scale, name, geom, score), ...]\n",
    "    \"\"\"\n",
    "    gpe = str(row.get('GPE', '')).strip()\n",
    "    fac = str(row.get('FAC', '')).strip()\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Parse GPE into multiple entities\n",
    "    entities = parse_gpe_entities(gpe)\n",
    "\n",
    "    if entities:\n",
    "        # Find all geographic matches\n",
    "        geo_matches = find_all_geographic_matches(entities, lookups)\n",
    "        matches.extend(geo_matches)\n",
    "\n",
    "    # Add facility as separate match if available\n",
    "    if fac and fac not in ['nan', 'NAN', '']:\n",
    "        matches.append(('FACILITY', fac, row.geometry, 100))\n",
    "\n",
    "    # If no matches found, return unmatched\n",
    "    if not matches:\n",
    "        matches.append(('UNMATCHED', None, row.geometry, 0))\n",
    "\n",
    "    return matches\n",
    "\n",
    "def expand_tweets_by_matches(gdf, lookups, dataset_name):\n",
    "    \"\"\"\n",
    "    Expand the GeoDataFrame so each tweet creates multiple rows (one per geographic match)\n",
    "    \"\"\"\n",
    "    print(f\"\\nExpanding {dataset_name} tweets by geographic matches...\")\n",
    "\n",
    "    expanded_rows = []\n",
    "\n",
    "    for idx, row in gdf.iterrows():\n",
    "        if idx % 100 == 0:\n",
    "            print(idx)\n",
    "        matches = multi_level_assign_scale_levels(row, lookups)\n",
    "\n",
    "        # Create one row per match\n",
    "        for scale, name, geom, score in matches:\n",
    "            new_row = row.copy()\n",
    "            new_row['scale_level'] = scale\n",
    "            new_row['matched_name'] = name\n",
    "            new_row['matched_geom'] = geom\n",
    "            new_row['match_score'] = score\n",
    "            new_row['original_index'] = idx  # Track original tweet\n",
    "            expanded_rows.append(new_row)\n",
    "\n",
    "    # Create new GeoDataFrame and preserve the original CRS\n",
    "    expanded_gdf = gpd.GeoDataFrame(expanded_rows, crs=gdf.crs)\n",
    "\n",
    "    # Show some examples of multi-level matches\n",
    "    print(f\"  Sample multi-level matches:\")\n",
    "    # Group by original tweet and show ones with multiple matches\n",
    "    multi_matches = expanded_gdf.groupby('original_index').size()\n",
    "    multi_match_indices = multi_matches[multi_matches > 1].head(5).index\n",
    "\n",
    "    for orig_idx in multi_match_indices:\n",
    "        tweet_matches = expanded_gdf[expanded_gdf['original_index'] == orig_idx]\n",
    "        original_gpe = tweet_matches.iloc[0]['GPE']\n",
    "        match_summary = ', '.join([f\"{row['scale_level']}:{row['matched_name']}\" for _, row in tweet_matches.iterrows()])\n",
    "        # print(f\"    '{original_gpe}' → {match_summary}\")\n",
    "\n",
    "    return expanded_gdf\n",
    "\n",
    "# =============================================================================\n",
    "# EXECUTE MULTI-LEVEL FUZZY MATCHING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTI-LEVEL GEOGRAPHIC MATCHING (ALL LEVELS)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create hierarchical lookups\n",
    "lookups = create_hierarchical_lookups(states_gdf, counties_gdf, cities_gdf)\n",
    "\n",
    "# Apply to both datasets (this will expand the datasets)\n",
    "francine_gdf = expand_tweets_by_matches(francine_gdf, lookups, \"FRANCINE\")\n",
    "helene_gdf = expand_tweets_by_matches(helene_gdf, lookups, \"HELENE\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTI-LEVEL FUZZY MATCHING COMPLETE ✓\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNote: Datasets are now expanded - each original tweet may have multiple rows\")\n",
    "print(\"representing different geographic scales (STATE, COUNTY, CITY, etc.)\")"
   ],
   "id": "102cf233829866a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MULTI-LEVEL GEOGRAPHIC MATCHING (ALL LEVELS)\n",
      "============================================================\n",
      "\n",
      "Creating hierarchical lookup dictionaries...\n",
      "\n",
      "Expanding FRANCINE tweets by geographic matches...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "  Sample multi-level matches:\n",
      "\n",
      "Expanding HELENE tweets by geographic matches...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "  Sample multi-level matches:\n",
      "\n",
      "============================================================\n",
      "MULTI-LEVEL FUZZY MATCHING COMPLETE ✓\n",
      "============================================================\n",
      "\n",
      "Note: Datasets are now expanded - each original tweet may have multiple rows\n",
      "representing different geographic scales (STATE, COUNTY, CITY, etc.)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T19:37:57.952732Z",
     "start_time": "2025-10-08T19:37:57.910073Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Group tweets by 4-hour intervals and scale level\n",
    "# Using unix_timestamp for unambiguous temporal grouping\n",
    "\n",
    "# Alternative approach:\n",
    "francine_interval_counts = francine_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).agg({\n",
    "    'matched_geom': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Add count column separately\n",
    "count_series = francine_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).size()\n",
    "francine_interval_counts['count'] = count_series.values\n",
    "\n",
    "# Same for Helene\n",
    "helene_interval_counts = helene_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).agg({\n",
    "    'matched_geom': 'first'\n",
    "}).reset_index()\n",
    "count_series = helene_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).size()\n",
    "helene_interval_counts['count'] = count_series.values\n",
    "\n",
    "# Sort by timestamp to ensure chronological order\n",
    "francine_interval_counts = francine_interval_counts.sort_values('unix_timestamp')\n",
    "helene_interval_counts = helene_interval_counts.sort_values('unix_timestamp')\n",
    "\n",
    "# Calculate cumulative counts\n",
    "francine_interval_counts['cumulative_count'] = francine_interval_counts.groupby(['scale_level', 'matched_name'])['count'].cumsum()\n",
    "helene_interval_counts['cumulative_count'] = helene_interval_counts.groupby(['scale_level', 'matched_name'])['count'].cumsum()\n",
    "\n",
    "# Get unique time bins for iteration\n",
    "francine_time_bins = sorted(francine_gdf['unix_timestamp'].unique())\n",
    "helene_time_bins = sorted(helene_gdf['unix_timestamp'].unique())\n",
    "\n"
   ],
   "id": "95d5ae7c58fc2af4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T19:37:58.125573Z",
     "start_time": "2025-10-08T19:37:57.961239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 1: DEFINE MASTER GRID CANVAS\n",
    "# ==============================================================================\n",
    "\n",
    "# Configuration\n",
    "TARGET_CRS = 'EPSG:3857'  # Web Mercator\n",
    "CELL_SIZE_M = 1000  # 5 km in meters\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: CREATING MASTER GRID CANVAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Project both datasets to target CRS\n",
    "print(f\"\\nProjecting datasets to {TARGET_CRS}...\")\n",
    "francine_proj = francine_gdf.to_crs(TARGET_CRS)\n",
    "helene_proj = helene_gdf.to_crs(TARGET_CRS)\n",
    "\n",
    "# Also project reference geometries\n",
    "print(\"Projecting reference geometries...\")\n",
    "states_proj = states_gdf.to_crs(TARGET_CRS)\n",
    "counties_proj = counties_gdf.to_crs(TARGET_CRS)\n",
    "cities_proj = cities_gdf.to_crs(TARGET_CRS)\n",
    "# Calculate combined extent from both hurricanes\"\n",
    "print(\"\\nCalculating master extent...\")\n",
    "francine_bounds = francine_proj.total_bounds\n",
    "helene_bounds = helene_proj.total_bounds\n",
    "\n",
    "# Get union of both bounding boxes\n",
    "minx = min(francine_bounds[0], helene_bounds[0])\n",
    "miny = min(francine_bounds[1], helene_bounds[1])\n",
    "maxx = max(francine_bounds[2], helene_bounds[2])\n",
    "maxy = max(francine_bounds[3], helene_bounds[3])\n",
    "#\n",
    "# print(f\"  Master bounds (EPSG:3857):\")\n",
    "# print(f\"    minx: {minx:,.2f}\")\n",
    "# print(f\"    miny: {miny:,.2f}\")\n",
    "# print(f\"    maxx: {maxx:,.2f}\")\n",
    "# print(f\"    maxy: {maxy:,.2f}\")\n",
    "\n",
    "# Calculate grid dimensions\n",
    "width = int(np.ceil((maxx - minx) / CELL_SIZE_M))\n",
    "height = int(np.ceil((maxy - miny) / CELL_SIZE_M))\n",
    "\n",
    "print(f\"\\nGrid Configuration:\")\n",
    "print(f\"  Cell size: {CELL_SIZE_M:,} meters ({CELL_SIZE_M/1000} km)\")\n",
    "print(f\"  Grid dimensions: {width} x {height} cells\")\n",
    "print(f\"  Total cells: {width * height:,}\")\n",
    "\n",
    "# Create master transform\n",
    "master_transform = from_bounds(minx, miny, maxx, maxy, width, height)\n",
    "\n",
    "print(f\"\\nMaster Transform:\")\n",
    "print(f\"  {master_transform}\")\n",
    "\n",
    "# Calculate actual coverage area\n",
    "area_km2 = (width * height * CELL_SIZE_M * CELL_SIZE_M) / 1_000_000\n",
    "print(f\"\\nCoverage area: {area_km2:,.2f} km²\")\n",
    "\n",
    "# Store grid parameters for later use\n",
    "grid_params = {\n",
    "    'crs': TARGET_CRS,\n",
    "    'cell_size': CELL_SIZE_M,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'bounds': (minx, miny, maxx, maxy),\n",
    "    'transform': master_transform\n",
    "}\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"MASTER GRID CANVAS READY ✓\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Update lookup dictionaries with projected geometries\n",
    "print(\"\\nUpdating geometry lookups with projected coordinates...\")\n",
    "state_lookup_proj = dict(zip(states_proj['NAME'].str.upper(), states_proj.geometry))\n",
    "county_lookup_proj = dict(zip(counties_proj['NAME'].str.upper(), counties_proj.geometry))\n",
    "cities_lookup_proj = dict(zip(cities_proj['NAME'].str.upper(), cities_proj.geometry))\n",
    "# validation_results = validate_city_matching(francine_gdf, helene_gdf, lookups['city_lookup'], lookups['state_lookup'], lookups['county_lookup'])\n",
    "print(\"Lookup dictionaries updated with projected geometries ✓\")"
   ],
   "id": "5bd77653518eadb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: CREATING MASTER GRID CANVAS\n",
      "============================================================\n",
      "\n",
      "Projecting datasets to EPSG:3857...\n",
      "Projecting reference geometries...\n",
      "\n",
      "Calculating master extent...\n",
      "\n",
      "Grid Configuration:\n",
      "  Cell size: 1,000 meters (1.0 km)\n",
      "  Grid dimensions: 3364 x 2195 cells\n",
      "  Total cells: 7,383,980\n",
      "\n",
      "Master Transform:\n",
      "  | 999.78, 0.00,-11854083.11|\n",
      "| 0.00,-999.98, 5142357.36|\n",
      "| 0.00, 0.00, 1.00|\n",
      "\n",
      "Coverage area: 7,383,980.00 km²\n",
      "\n",
      "============================================================\n",
      "MASTER GRID CANVAS READY ✓\n",
      "============================================================\n",
      "\n",
      "Updating geometry lookups with projected coordinates...\n",
      "\n",
      "============================================================\n",
      "CITY MATCHING VALIDATION\n",
      "============================================================\n",
      "  City matching rate: 16.0%\n",
      "\n",
      "Sample successful city matches:\n",
      "  - VIRGINIA: Polygon\n",
      "  - STEINHATCHEE: Polygon\n",
      "  - WAKULLA: Polygon\n",
      "  - STARKVILLE: Polygon\n",
      "  - PORT CHARLOTTE: Polygon\n",
      "  - TALLAHASSEE: MultiPolygon\n",
      "  - SPARTANBURG: MultiPolygon\n",
      "  - SHREVEPORT: MultiPolygon\n",
      "  - HILLSBOROUGH: MultiPolygon\n",
      "  - RIDGELAND: Polygon\n",
      "\n",
      "============================================================\n",
      "VALIDATION COMPLETE\n",
      "============================================================\n",
      "Lookup dictionaries updated with projected geometries ✓\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-08T20:06:06.616409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.features import geometry_mask\n",
    "# ==============================================================================\n",
    "# STEP 2: MAIN RASTERIZATION LOOP - TIME ITERATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Create output directories\n",
    "rasters_dir = r\"\\rasters_output\"\n",
    "output_dir = f\"{local_path}{rasters_dir}\"\n",
    "# output_dir = os.path.join(local_path, 'rasters_output')\n",
    "# output_dir = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def create_hierarchical_rasters(data, grid_params, time_bin):\n",
    "    \"\"\"Create hierarchically weighted rasters with automatic parent state inclusion\"\"\"\n",
    "    print(f\"    Creating hierarchical raster for time {time_bin}...\")\n",
    "\n",
    "    output_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "    states_to_include = set()  # Track which states need base layers\n",
    "\n",
    "    # 1. First pass: identify all states that need base layers\n",
    "    state_data = data[data['scale_level'] == 'STATE']\n",
    "    if len(state_data) > 0:\n",
    "        states_to_include.update(state_data['matched_name'].unique())\n",
    "\n",
    "    # Check counties - add their parent states\n",
    "    county_data = data[data['scale_level'] == 'COUNTY']\n",
    "    for county_name in county_data['matched_name'].unique():\n",
    "        if county_name in county_lookup_proj:\n",
    "            # Find parent state by spatial containment\n",
    "            county_geom = county_lookup_proj[county_name]\n",
    "            for state_name, state_geom in state_lookup_proj.items():\n",
    "                if state_geom.contains(county_geom.centroid):\n",
    "                    states_to_include.add(state_name)\n",
    "                    break\n",
    "\n",
    "    # Check cities - add their parent states\n",
    "    city_data = data[data['scale_level'] == 'CITY']\n",
    "    for city_name in city_data['matched_name'].unique():\n",
    "        if city_name in cities_lookup_proj:\n",
    "            city_geom = cities_lookup_proj[city_name]\n",
    "            for state_name, state_geom in state_lookup_proj.items():\n",
    "                if state_geom.contains(city_geom.centroid):\n",
    "                    states_to_include.add(state_name)\n",
    "                    break\n",
    "\n",
    "    # 2. Rasterize all states that need inclusion\n",
    "    for state_name in states_to_include:\n",
    "        if state_name in state_lookup_proj:\n",
    "            state_geom = state_lookup_proj[state_name]\n",
    "            mask = rasterize(\n",
    "                [(state_geom, 1)],\n",
    "                out_shape=(grid_params['height'], grid_params['width']),\n",
    "                transform=grid_params['transform'],\n",
    "                fill=0, dtype=np.float32, all_touched=True\n",
    "            )\n",
    "\n",
    "            # Get tweet count if state was mentioned, else use minimal base\n",
    "            if state_name in state_data['matched_name'].values:\n",
    "                tweet_count = state_data[state_data['matched_name'] == state_name]['count'].sum()\n",
    "            else:\n",
    "                tweet_count = 1  # Minimal base for implied states\n",
    "\n",
    "            base_value = np.log1p(tweet_count) * 2\n",
    "            output_grid += mask * base_value\n",
    "\n",
    "    # 3. Add counties (same as before)\n",
    "    if len(county_data) > 0:\n",
    "        county_counts = county_data.groupby('matched_name')['count'].sum()\n",
    "        for county_name, tweet_count in county_counts.items():\n",
    "            if county_name in county_lookup_proj:\n",
    "                mask = rasterize(\n",
    "                    [(county_lookup_proj[county_name], 1)],\n",
    "                    out_shape=(grid_params['height'], grid_params['width']),\n",
    "                    transform=grid_params['transform'],\n",
    "                    fill=0, dtype=np.float32, all_touched=True\n",
    "                )\n",
    "                output_grid += mask * np.log1p(tweet_count) * 5\n",
    "\n",
    "    # 4. Add cities (same as before)\n",
    "    if len(city_data) > 0:\n",
    "        city_counts = city_data.groupby('matched_name')['count'].sum()\n",
    "        for city_name, tweet_count in city_counts.items():\n",
    "            if city_name in cities_lookup_proj:\n",
    "                mask = rasterize(\n",
    "                    [(cities_lookup_proj[city_name], 1)],\n",
    "                    out_shape=(grid_params['height'], grid_params['width']),\n",
    "                    transform=grid_params['transform'],\n",
    "                    fill=0, dtype=np.float32, all_touched=True\n",
    "                )\n",
    "                output_grid += mask * np.log1p(tweet_count) * 10\n",
    "\n",
    "    # 5. Add facilities\n",
    "    facility_data = data[data['scale_level'] == 'FACILITY']\n",
    "    if len(facility_data) > 0:\n",
    "        output_grid += create_facility_raster(data, grid_params)\n",
    "\n",
    "    return output_grid\n",
    "\n",
    "def process_hurricane(hurricane_name, gdf_proj, interval_counts, time_bins, timestamp_dict):\n",
    "    \"\"\"\n",
    "    Process a single hurricane through all time bins\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"PROCESSING: {hurricane_name.upper()}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print()\n",
    "    print(gdf_proj)\n",
    "    # Create hurricane-specific output directory\n",
    "    hurricane_dir = os.path.join(output_dir, hurricane_name.lower())\n",
    "    os.makedirs(hurricane_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize cumulative grid (persists across time bins)\n",
    "    cumulative_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Loop through each time bin chronologically\n",
    "    for idx, time_bin in enumerate(time_bins):\n",
    "        # print(f\"\\n--- Time Bin {idx+1}/{len(time_bins)}: {time_bin} ---\")\n",
    "\n",
    "        # Filter data for current time bin\n",
    "        current_data = interval_counts[interval_counts['unix_timestamp'] == time_bin]\n",
    "        tweet_count = len(current_data)\n",
    "        # print(f\"  Tweets in this bin: {tweet_count}\")\n",
    "\n",
    "        # WITH THIS:\n",
    "        incremental_grid = create_hierarchical_rasters(current_data, grid_params, time_bin)\n",
    "\n",
    "        # === END PLACEHOLDERS ===\n",
    "\n",
    "        # Update cumulative grid\n",
    "        cumulative_grid += incremental_grid\n",
    "        # Save rasters\n",
    "        save_raster(incremental_grid, hurricane_dir, hurricane_name, time_bin, 'increment', timestamp_dict)\n",
    "        save_raster(cumulative_grid, hurricane_dir, hurricane_name, time_bin, 'cumulative', timestamp_dict)\n",
    "\n",
    "        print(f\"  Incremental max value: {np.max(incremental_grid):.2f}\")\n",
    "        print(f\"  Cumulative max value: {np.max(cumulative_grid):.2f}\")\n",
    "\n",
    "    print(f\"\\n{hurricane_name.upper()} processing complete!\")\n",
    "    print(f\"Output saved to: {hurricane_dir}\")\n",
    "    return\n",
    "\n",
    "# ==============================================================================\n",
    "# PLACEHOLDER FUNCTIONS (TO BE IMPLEMENTED)\n",
    "# ==============================================================================\n",
    "\n",
    "def create_facility_raster(data, grid_params):\n",
    "    \"\"\"Create KDE raster for facility points with strong hotspot multiplier\"\"\"\n",
    "    print(\"    [FACILITY] Creating facility raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    facility_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for FACILITY-level tweets only\n",
    "    facility_data = data[data['scale_level'] == 'FACILITY']\n",
    "\n",
    "    if len(facility_data) == 0:\n",
    "        print(\"      No facility-level tweets in this time bin\")\n",
    "        return facility_grid\n",
    "\n",
    "    # Group by facility coordinates (using matched_name as proxy) and sum counts\n",
    "    facility_counts = facility_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(facility_counts)} unique facilities\")\n",
    "\n",
    "    # HOTSPOT PARAMETERS for facilities\n",
    "    sigma_meters = 2 * grid_params['cell_size']  # 10 km for 5km cells\n",
    "    sigma_pixels = sigma_meters / grid_params['cell_size']  # Convert to pixel units\n",
    "    facility_multiplier = 10  # Make facilities 10x more prominent (strongest hotspots)\n",
    "\n",
    "    # Process each facility\n",
    "    facilities_processed = 0\n",
    "    for facility_name, tweet_count in facility_counts.items():\n",
    "        # Get facility data to extract geometry\n",
    "        facility_rows = facility_data[facility_data['matched_name'] == facility_name]\n",
    "\n",
    "        if len(facility_rows) > 0:\n",
    "            # Get the point geometry (should be from the tweet's geocoded location)\n",
    "            facility_point = facility_rows.iloc[0]['matched_geom']\n",
    "\n",
    "            # Project point to grid CRS if needed\n",
    "            if hasattr(facility_point, 'x') and hasattr(facility_point, 'y'):\n",
    "                # Create GeoSeries to handle projection\n",
    "                point_geoseries = gpd.GeoSeries([facility_point], crs='EPSG:4326')\n",
    "                point_proj = point_geoseries.to_crs(grid_params['crs']).iloc[0]\n",
    "\n",
    "                # Convert point coordinates to pixel indices\n",
    "                px = (point_proj.x - grid_params['bounds'][0]) / grid_params['cell_size']\n",
    "                py = (grid_params['bounds'][3] - point_proj.y) / grid_params['cell_size']\n",
    "\n",
    "                # Check if point is within grid bounds\n",
    "                if 0 <= px < grid_params['width'] and 0 <= py < grid_params['height']:\n",
    "                    # Create point raster with tweet count at location\n",
    "                    point_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "                    point_grid[int(py), int(px)] = tweet_count\n",
    "\n",
    "                    # Apply Gaussian filter to create kernel density\n",
    "                    kernel_grid = gaussian_filter(point_grid, sigma=sigma_pixels, mode='constant', cval=0)\n",
    "\n",
    "                    # FIXED: Only add once with proper multiplier\n",
    "                    facility_grid += kernel_grid * facility_multiplier\n",
    "\n",
    "                    facilities_processed += 1\n",
    "                    effective_value = tweet_count * facility_multiplier\n",
    "                else:\n",
    "                    print(f\"      WARNING: Facility '{facility_name}' outside grid bounds\")\n",
    "            else:\n",
    "                print(f\"      WARNING: Invalid geometry for facility '{facility_name}'\")\n",
    "\n",
    "    print(f\"      Processed {facilities_processed} facilities with sigma={sigma_pixels:.2f} pixels\")\n",
    "\n",
    "    total_value = np.sum(facility_grid)\n",
    "    max_value = np.max(facility_grid)\n",
    "    # print(f\"      Total facility grid value: {total_value:.2f}, Max pixel: {max_value:.2f}\")\n",
    "\n",
    "    return facility_grid\n",
    "\n",
    "def save_raster(grid, output_dir, hurricane_name, time_bin, raster_type, timestamp_dict):\n",
    "    \"\"\"Save raster as GeoTIFF in type-specific subdirectory\"\"\"\n",
    "    # Create subdirectory for raster type\n",
    "    type_dir = os.path.join(output_dir, raster_type)\n",
    "    os.makedirs(type_dir, exist_ok=True)\n",
    "    print('max grid', np.max(grid))\n",
    "    # Convert unix timestamp (microseconds) back to datetime\n",
    "    time_str = timestamp_dict[time_bin].strftime('%Y%m%d_%H%M%S')\n",
    "    # time_str = pd.Timestamp(time_bin, unit='us').strftime('%Y%m%d_%H%M%S')\n",
    "    print([time_str])\n",
    "    filename = f\"{hurricane_name}_tweets_{time_str}.tif\"\n",
    "    filepath = os.path.join(type_dir, filename)\n",
    "    print(grid_params)\n",
    "    with rasterio.open(\n",
    "        filepath, 'w',\n",
    "        driver='GTiff',\n",
    "        height=grid_params['height'],\n",
    "        width=grid_params['width'],\n",
    "        count=1,\n",
    "        dtype=grid.dtype,\n",
    "        crs=grid_params['crs'],\n",
    "        transform=grid_params['transform'],\n",
    "        compress='lzw'\n",
    "    ) as dst:\n",
    "        dst.write(grid, 1)\n",
    "\n",
    "    print(f\"    Saved: {raster_type}/{filename}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECUTE PROCESSING FOR BOTH HURRICANES\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STARTING RASTERIZATION PROCESS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process Francine\n",
    "process_hurricane('francine', francine_proj, francine_interval_counts, francine_time_bins, francine_timestamp_dict)\n",
    "\n",
    "# Process Helene\n",
    "process_hurricane('helene', helene_proj, helene_interval_counts, helene_time_bins, helene_timestamp_dict)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL PROCESSING COMPLETE! ✓\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "2e1bc16e47f51e00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING RASTERIZATION PROCESS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING: FRANCINE\n",
      "============================================================\n",
      "\n",
      "     FAC LOC          GPE                      time   Latitude  Longitude  \\\n",
      "0               Louisiana 2024-09-10 23:58:43+00:00  30.870388 -92.007126   \n",
      "0               Louisiana 2024-09-10 23:58:43+00:00  30.870388 -92.007126   \n",
      "0               Louisiana 2024-09-10 23:58:43+00:00  30.870388 -92.007126   \n",
      "1             New Orleans 2024-09-10 23:56:22+00:00  29.975998 -90.078213   \n",
      "1             New Orleans 2024-09-10 23:56:22+00:00  29.975998 -90.078213   \n",
      "...   ..  ..          ...                       ...        ...        ...   \n",
      "2301            Louisiana 2024-09-10 09:56:03+00:00  30.870388 -92.007126   \n",
      "2301            Louisiana 2024-09-10 09:56:03+00:00  30.870388 -92.007126   \n",
      "2302            Louisiana 2024-09-10 09:39:36+00:00  30.870388 -92.007126   \n",
      "2302            Louisiana 2024-09-10 09:39:36+00:00  30.870388 -92.007126   \n",
      "2302            Louisiana 2024-09-10 09:39:36+00:00  30.870388 -92.007126   \n",
      "\n",
      "      make_polygon                           geometry  \\\n",
      "0                1  POINT (-10242186.416 3615927.986)   \n",
      "0                1  POINT (-10242186.416 3615927.986)   \n",
      "0                1  POINT (-10242186.416 3615927.986)   \n",
      "1                0  POINT (-10027460.769 3500465.022)   \n",
      "1                0  POINT (-10027460.769 3500465.022)   \n",
      "...            ...                                ...   \n",
      "2301             1  POINT (-10242186.416 3615927.986)   \n",
      "2301             1  POINT (-10242186.416 3615927.986)   \n",
      "2302             1  POINT (-10242186.416 3615927.986)   \n",
      "2302             1  POINT (-10242186.416 3615927.986)   \n",
      "2302             1  POINT (-10242186.416 3615927.986)   \n",
      "\n",
      "                     timestamp                  time_bin  unix_timestamp  \\\n",
      "0    2024-09-10 23:58:43+00:00 2024-09-10 20:00:00+00:00      1725998400   \n",
      "0    2024-09-10 23:58:43+00:00 2024-09-10 20:00:00+00:00      1725998400   \n",
      "0    2024-09-10 23:58:43+00:00 2024-09-10 20:00:00+00:00      1725998400   \n",
      "1    2024-09-10 23:56:22+00:00 2024-09-10 20:00:00+00:00      1725998400   \n",
      "1    2024-09-10 23:56:22+00:00 2024-09-10 20:00:00+00:00      1725998400   \n",
      "...                        ...                       ...             ...   \n",
      "2301 2024-09-10 09:56:03+00:00 2024-09-10 08:00:00+00:00      1725955200   \n",
      "2301 2024-09-10 09:56:03+00:00 2024-09-10 08:00:00+00:00      1725955200   \n",
      "2302 2024-09-10 09:39:36+00:00 2024-09-10 08:00:00+00:00      1725955200   \n",
      "2302 2024-09-10 09:39:36+00:00 2024-09-10 08:00:00+00:00      1725955200   \n",
      "2302 2024-09-10 09:39:36+00:00 2024-09-10 08:00:00+00:00      1725955200   \n",
      "\n",
      "          bin_label scale_level matched_name  \\\n",
      "0     20240910_2000       STATE    LOUISIANA   \n",
      "0     20240910_2000      COUNTY       LOUISA   \n",
      "0     20240910_2000        CITY    LOUISIANA   \n",
      "1     20240910_2000      COUNTY      ORLEANS   \n",
      "1     20240910_2000        CITY  NEW ORLEANS   \n",
      "...             ...         ...          ...   \n",
      "2301  20240910_0800      COUNTY       LOUISA   \n",
      "2301  20240910_0800        CITY    LOUISIANA   \n",
      "2302  20240910_0800       STATE    LOUISIANA   \n",
      "2302  20240910_0800      COUNTY       LOUISA   \n",
      "2302  20240910_0800        CITY    LOUISIANA   \n",
      "\n",
      "                                           matched_geom  match_score  \\\n",
      "0     POLYGON ((-94.0430515276176 32.6930299766656, ...          100   \n",
      "0     POLYGON ((-91.483995 41.423848, -91.368521 41....           80   \n",
      "0     POLYGON ((-10136318.240295896 4787721.51072714...          100   \n",
      "1     POLYGON ((-72.53328 44.834081, -72.55378002150...           78   \n",
      "1     MULTIPOLYGON (((-10017501.047895897 3489812.12...          100   \n",
      "...                                                 ...          ...   \n",
      "2301  POLYGON ((-91.483995 41.423848, -91.368521 41....           80   \n",
      "2301  POLYGON ((-10136318.240295896 4787721.51072714...          100   \n",
      "2302  POLYGON ((-94.0430515276176 32.6930299766656, ...          100   \n",
      "2302  POLYGON ((-91.483995 41.423848, -91.368521 41....           80   \n",
      "2302  POLYGON ((-10136318.240295896 4787721.51072714...          100   \n",
      "\n",
      "      original_index  \n",
      "0                  0  \n",
      "0                  0  \n",
      "0                  0  \n",
      "1                  1  \n",
      "1                  1  \n",
      "...              ...  \n",
      "2301            2301  \n",
      "2301            2301  \n",
      "2302            2302  \n",
      "2302            2302  \n",
      "2302            2302  \n",
      "\n",
      "[7365 rows x 17 columns]\n",
      "    Creating hierarchical raster for time 1725868800...\n",
      "max grid 12.372417\n",
      "['20240909_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240909_080000.tif\n",
      "max grid 12.372417\n",
      "['20240909_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240909_080000.tif\n",
      "  Incremental max value: 12.37\n",
      "  Cumulative max value: 12.37\n",
      "    Creating hierarchical raster for time 1725883200...\n",
      "max grid 27.776867\n",
      "['20240909_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240909_120000.tif\n",
      "max grid 40.149284\n",
      "['20240909_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240909_120000.tif\n",
      "  Incremental max value: 27.78\n",
      "  Cumulative max value: 40.15\n",
      "    Creating hierarchical raster for time 1725897600...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 1 unique facilities\n",
      "      Processed 1 facilities with sigma=2.00 pixels\n",
      "max grid 36.939774\n",
      "['20240909_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240909_160000.tif\n",
      "max grid 77.08906\n",
      "['20240909_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240909_160000.tif\n",
      "  Incremental max value: 36.94\n",
      "  Cumulative max value: 77.09\n",
      "    Creating hierarchical raster for time 1725912000...\n",
      "max grid 31.831518\n",
      "['20240909_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240909_200000.tif\n",
      "max grid 108.92058\n",
      "['20240909_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240909_200000.tif\n",
      "  Incremental max value: 31.83\n",
      "  Cumulative max value: 108.92\n",
      "    Creating hierarchical raster for time 1725926400...\n",
      "max grid 38.27509\n",
      "['20240910_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240910_000000.tif\n",
      "max grid 147.19566\n",
      "['20240910_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240910_000000.tif\n",
      "  Incremental max value: 38.28\n",
      "  Cumulative max value: 147.20\n",
      "    Creating hierarchical raster for time 1725940800...\n",
      "max grid 20.690184\n",
      "['20240910_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240910_040000.tif\n",
      "max grid 167.88585\n",
      "['20240910_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240910_040000.tif\n",
      "  Incremental max value: 20.69\n",
      "  Cumulative max value: 167.89\n",
      "    Creating hierarchical raster for time 1725955200...\n",
      "max grid 33.575054\n",
      "['20240910_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240910_080000.tif\n",
      "max grid 201.4609\n",
      "['20240910_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240910_080000.tif\n",
      "  Incremental max value: 33.58\n",
      "  Cumulative max value: 201.46\n",
      "    Creating hierarchical raster for time 1725969600...\n",
      "max grid 34.12753\n",
      "['20240910_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240910_120000.tif\n",
      "max grid 235.58844\n",
      "['20240910_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240910_120000.tif\n",
      "  Incremental max value: 34.13\n",
      "  Cumulative max value: 235.59\n",
      "    Creating hierarchical raster for time 1725984000...\n",
      "max grid 29.11218\n",
      "['20240910_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240910_160000.tif\n",
      "max grid 264.70062\n",
      "['20240910_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240910_160000.tif\n",
      "  Incremental max value: 29.11\n",
      "  Cumulative max value: 264.70\n",
      "    Creating hierarchical raster for time 1725998400...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 1 unique facilities\n",
      "      Processed 1 facilities with sigma=2.00 pixels\n",
      "max grid 41.459625\n",
      "['20240910_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240910_200000.tif\n",
      "max grid 306.16025\n",
      "['20240910_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240910_200000.tif\n",
      "  Incremental max value: 41.46\n",
      "  Cumulative max value: 306.16\n",
      "    Creating hierarchical raster for time 1726012800...\n",
      "max grid 40.70455\n",
      "['20240911_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240911_000000.tif\n",
      "max grid 346.8648\n",
      "['20240911_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240911_000000.tif\n",
      "  Incremental max value: 40.70\n",
      "  Cumulative max value: 346.86\n",
      "    Creating hierarchical raster for time 1726027200...\n",
      "max grid 38.036194\n",
      "['20240911_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240911_040000.tif\n",
      "max grid 384.901\n",
      "['20240911_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240911_040000.tif\n",
      "  Incremental max value: 38.04\n",
      "  Cumulative max value: 384.90\n",
      "    Creating hierarchical raster for time 1726041600...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 51.68852\n",
      "['20240911_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240911_080000.tif\n",
      "max grid 436.5015\n",
      "['20240911_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240911_080000.tif\n",
      "  Incremental max value: 51.69\n",
      "  Cumulative max value: 436.50\n",
      "    Creating hierarchical raster for time 1726056000...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 44.29089\n",
      "['20240911_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240911_120000.tif\n",
      "max grid 480.7924\n",
      "['20240911_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240911_120000.tif\n",
      "  Incremental max value: 44.29\n",
      "  Cumulative max value: 480.79\n",
      "    Creating hierarchical raster for time 1726070400...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 47.990475\n",
      "['20240911_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240911_160000.tif\n",
      "max grid 528.78284\n",
      "['20240911_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240911_160000.tif\n",
      "  Incremental max value: 47.99\n",
      "  Cumulative max value: 528.78\n",
      "    Creating hierarchical raster for time 1726084800...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 5 unique facilities\n",
      "      Processed 5 facilities with sigma=2.00 pixels\n",
      "max grid 57.805367\n",
      "['20240911_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240911_200000.tif\n",
      "max grid 586.5882\n",
      "['20240911_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240911_200000.tif\n",
      "  Incremental max value: 57.81\n",
      "  Cumulative max value: 586.59\n",
      "    Creating hierarchical raster for time 1726099200...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 41.459625\n",
      "['20240912_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240912_000000.tif\n",
      "max grid 628.04785\n",
      "['20240912_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240912_000000.tif\n",
      "  Incremental max value: 41.46\n",
      "  Cumulative max value: 628.05\n",
      "    Creating hierarchical raster for time 1726113600...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 49.593903\n",
      "['20240912_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240912_040000.tif\n",
      "max grid 677.6417\n",
      "['20240912_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240912_040000.tif\n",
      "  Incremental max value: 49.59\n",
      "  Cumulative max value: 677.64\n",
      "    Creating hierarchical raster for time 1726128000...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 46.339676\n",
      "['20240912_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240912_080000.tif\n",
      "max grid 723.9814\n",
      "['20240912_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240912_080000.tif\n",
      "  Incremental max value: 46.34\n",
      "  Cumulative max value: 723.98\n",
      "    Creating hierarchical raster for time 1726142400...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 4 unique facilities\n",
      "      Processed 4 facilities with sigma=2.00 pixels\n",
      "max grid 51.580963\n",
      "['20240912_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240912_120000.tif\n",
      "max grid 774.7942\n",
      "['20240912_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240912_120000.tif\n",
      "  Incremental max value: 51.58\n",
      "  Cumulative max value: 774.79\n",
      "    Creating hierarchical raster for time 1726156800...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 3 unique facilities\n",
      "      Processed 3 facilities with sigma=2.00 pixels\n",
      "max grid 46.339676\n",
      "['20240912_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240912_160000.tif\n",
      "max grid 821.13385\n",
      "['20240912_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240912_160000.tif\n",
      "  Incremental max value: 46.34\n",
      "  Cumulative max value: 821.13\n",
      "    Creating hierarchical raster for time 1726171200...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 46.43929\n",
      "['20240912_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240912_200000.tif\n",
      "max grid 866.2475\n",
      "['20240912_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240912_200000.tif\n",
      "  Incremental max value: 46.44\n",
      "  Cumulative max value: 866.25\n",
      "    Creating hierarchical raster for time 1726185600...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 1 unique facilities\n",
      "      Processed 1 facilities with sigma=2.00 pixels\n",
      "max grid 35.726166\n",
      "['20240913_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240913_000000.tif\n",
      "max grid 901.97363\n",
      "['20240913_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240913_000000.tif\n",
      "  Incremental max value: 35.73\n",
      "  Cumulative max value: 901.97\n",
      "    Creating hierarchical raster for time 1726200000...\n",
      "max grid 33.683014\n",
      "['20240913_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240913_040000.tif\n",
      "max grid 935.6566\n",
      "['20240913_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240913_040000.tif\n",
      "  Incremental max value: 33.68\n",
      "  Cumulative max value: 935.66\n",
      "    Creating hierarchical raster for time 1726214400...\n",
      "max grid 27.035788\n",
      "['20240913_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240913_080000.tif\n",
      "max grid 962.6924\n",
      "['20240913_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240913_080000.tif\n",
      "  Incremental max value: 27.04\n",
      "  Cumulative max value: 962.69\n",
      "    Creating hierarchical raster for time 1726228800...\n",
      "max grid 35.726166\n",
      "['20240913_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240913_120000.tif\n",
      "max grid 998.4186\n",
      "['20240913_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240913_120000.tif\n",
      "  Incremental max value: 35.73\n",
      "  Cumulative max value: 998.42\n",
      "    Creating hierarchical raster for time 1726243200...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 1 unique facilities\n",
      "      Processed 1 facilities with sigma=2.00 pixels\n",
      "max grid 36.094635\n",
      "['20240913_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240913_160000.tif\n",
      "max grid 1034.5132\n",
      "['20240913_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240913_160000.tif\n",
      "  Incremental max value: 36.09\n",
      "  Cumulative max value: 1034.51\n",
      "    Creating hierarchical raster for time 1726257600...\n",
      "max grid 37.429947\n",
      "['20240913_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240913_200000.tif\n",
      "max grid 1071.9431\n",
      "['20240913_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240913_200000.tif\n",
      "  Incremental max value: 37.43\n",
      "  Cumulative max value: 1071.94\n",
      "    Creating hierarchical raster for time 1726272000...\n",
      "max grid 24.412146\n",
      "['20240914_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240914_000000.tif\n",
      "max grid 1096.3552\n",
      "['20240914_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240914_000000.tif\n",
      "  Incremental max value: 24.41\n",
      "  Cumulative max value: 1096.36\n",
      "    Creating hierarchical raster for time 1726286400...\n",
      "max grid 26.235361\n",
      "['20240914_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240914_040000.tif\n",
      "max grid 1122.5906\n",
      "['20240914_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240914_040000.tif\n",
      "  Incremental max value: 26.24\n",
      "  Cumulative max value: 1122.59\n",
      "    Creating hierarchical raster for time 1726300800...\n",
      "max grid 17.480673\n",
      "['20240914_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240914_080000.tif\n",
      "max grid 1140.0713\n",
      "['20240914_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240914_080000.tif\n",
      "  Incremental max value: 17.48\n",
      "  Cumulative max value: 1140.07\n",
      "    Creating hierarchical raster for time 1726315200...\n",
      "max grid 31.676306\n",
      "['20240914_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240914_120000.tif\n",
      "max grid 1171.7476\n",
      "['20240914_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240914_120000.tif\n",
      "  Incremental max value: 31.68\n",
      "  Cumulative max value: 1171.75\n",
      "    Creating hierarchical raster for time 1726329600...\n",
      "max grid 29.718428\n",
      "['20240914_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240914_160000.tif\n",
      "max grid 1201.466\n",
      "['20240914_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240914_160000.tif\n",
      "  Incremental max value: 29.72\n",
      "  Cumulative max value: 1201.47\n",
      "    Creating hierarchical raster for time 1726344000...\n",
      "max grid 19.303888\n",
      "['20240914_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240914_200000.tif\n",
      "max grid 1220.7698\n",
      "['20240914_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240914_200000.tif\n",
      "  Incremental max value: 19.30\n",
      "  Cumulative max value: 1220.77\n",
      "    Creating hierarchical raster for time 1726358400...\n",
      "max grid 8.317766\n",
      "['20240915_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240915_000000.tif\n",
      "max grid 1229.0875\n",
      "['20240915_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240915_000000.tif\n",
      "  Incremental max value: 8.32\n",
      "  Cumulative max value: 1229.09\n",
      "    Creating hierarchical raster for time 1726372800...\n",
      "max grid 17.480673\n",
      "['20240915_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240915_040000.tif\n",
      "max grid 1246.5682\n",
      "['20240915_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240915_040000.tif\n",
      "  Incremental max value: 17.48\n",
      "  Cumulative max value: 1246.57\n",
      "    Creating hierarchical raster for time 1726387200...\n",
      "max grid 17.480673\n",
      "['20240915_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240915_080000.tif\n",
      "max grid 1264.049\n",
      "['20240915_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240915_080000.tif\n",
      "  Incremental max value: 17.48\n",
      "  Cumulative max value: 1264.05\n",
      "    Creating hierarchical raster for time 1726401600...\n",
      "max grid 17.480673\n",
      "['20240915_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240915_120000.tif\n",
      "max grid 1281.5297\n",
      "['20240915_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240915_120000.tif\n",
      "  Incremental max value: 17.48\n",
      "  Cumulative max value: 1281.53\n",
      "    Creating hierarchical raster for time 1726416000...\n",
      "max grid 25.365248\n",
      "['20240915_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240915_160000.tif\n",
      "max grid 1306.8949\n",
      "['20240915_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240915_160000.tif\n",
      "  Incremental max value: 25.37\n",
      "  Cumulative max value: 1306.89\n",
      "    Creating hierarchical raster for time 1726430400...\n",
      "max grid 16.635532\n",
      "['20240915_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240915_200000.tif\n",
      "max grid 1322.1442\n",
      "['20240915_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240915_200000.tif\n",
      "  Incremental max value: 16.64\n",
      "  Cumulative max value: 1322.14\n",
      "    Creating hierarchical raster for time 1726473600...\n",
      "max grid 8.317766\n",
      "['20240916_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240916_080000.tif\n",
      "max grid 1330.4619\n",
      "['20240916_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240916_080000.tif\n",
      "  Incremental max value: 8.32\n",
      "  Cumulative max value: 1330.46\n",
      "    Creating hierarchical raster for time 1726488000...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 1 unique facilities\n",
      "      Processed 1 facilities with sigma=2.00 pixels\n",
      "max grid 25.365248\n",
      "['20240916_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/francine_tweets_20240916_120000.tif\n",
      "max grid 1355.8271\n",
      "['20240916_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/francine_tweets_20240916_120000.tif\n",
      "  Incremental max value: 25.37\n",
      "  Cumulative max value: 1355.83\n",
      "\n",
      "FRANCINE processing complete!\n",
      "Output saved to: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\n",
      "\n",
      "============================================================\n",
      "PROCESSING: HELENE\n",
      "============================================================\n",
      "\n",
      "     FAC LOC                        GPE                      time   Latitude  \\\n",
      "0                               Florida 2024-09-26 22:59:53+00:00  27.756767   \n",
      "0                               Florida 2024-09-26 22:59:53+00:00  27.756767   \n",
      "0                               Florida 2024-09-26 22:59:53+00:00  27.756767   \n",
      "1                               Florida 2024-09-26 22:59:49+00:00  27.756767   \n",
      "1                               Florida 2024-09-26 22:59:49+00:00  27.756767   \n",
      "...   ..  ..                        ...                       ...        ...   \n",
      "3005                            Georgia 2024-09-27 19:19:33+00:00  32.329381   \n",
      "3005                            Georgia 2024-09-27 19:19:33+00:00  32.329381   \n",
      "3005                            Georgia 2024-09-27 19:19:33+00:00  32.329381   \n",
      "3006          Gulfport, Pinellas County 2024-09-27 19:19:24+00:00  27.748361   \n",
      "3006          Gulfport, Pinellas County 2024-09-27 19:19:24+00:00  27.748361   \n",
      "\n",
      "      Longitude  make_polygon                          geometry  \\\n",
      "0    -81.463983             1  POINT (-9068529.161 3218342.102)   \n",
      "0    -81.463983             1  POINT (-9068529.161 3218342.102)   \n",
      "0    -81.463983             1  POINT (-9068529.161 3218342.102)   \n",
      "1    -81.463983             1  POINT (-9068529.161 3218342.102)   \n",
      "1    -81.463983             1  POINT (-9068529.161 3218342.102)   \n",
      "...         ...           ...                               ...   \n",
      "3005 -83.113737             1  POINT (-9252178.836 3806625.072)   \n",
      "3005 -83.113737             1  POINT (-9252178.836 3806625.072)   \n",
      "3005 -83.113737             1  POINT (-9252178.836 3806625.072)   \n",
      "3006 -82.703433             0  POINT (-9206504.093 3217284.791)   \n",
      "3006 -82.703433             0  POINT (-9206504.093 3217284.791)   \n",
      "\n",
      "                     timestamp                  time_bin  unix_timestamp  \\\n",
      "0    2024-09-26 22:59:53+00:00 2024-09-26 20:00:00+00:00      1727380800   \n",
      "0    2024-09-26 22:59:53+00:00 2024-09-26 20:00:00+00:00      1727380800   \n",
      "0    2024-09-26 22:59:53+00:00 2024-09-26 20:00:00+00:00      1727380800   \n",
      "1    2024-09-26 22:59:49+00:00 2024-09-26 20:00:00+00:00      1727380800   \n",
      "1    2024-09-26 22:59:49+00:00 2024-09-26 20:00:00+00:00      1727380800   \n",
      "...                        ...                       ...             ...   \n",
      "3005 2024-09-27 19:19:33+00:00 2024-09-27 16:00:00+00:00      1727452800   \n",
      "3005 2024-09-27 19:19:33+00:00 2024-09-27 16:00:00+00:00      1727452800   \n",
      "3005 2024-09-27 19:19:33+00:00 2024-09-27 16:00:00+00:00      1727452800   \n",
      "3006 2024-09-27 19:19:24+00:00 2024-09-27 16:00:00+00:00      1727452800   \n",
      "3006 2024-09-27 19:19:24+00:00 2024-09-27 16:00:00+00:00      1727452800   \n",
      "\n",
      "          bin_label scale_level matched_name  \\\n",
      "0     20240926_2000       STATE      FLORIDA   \n",
      "0     20240926_2000      COUNTY      FLORIDA   \n",
      "0     20240926_2000        CITY      FLORIDA   \n",
      "1     20240926_2000       STATE      FLORIDA   \n",
      "1     20240926_2000      COUNTY      FLORIDA   \n",
      "...             ...         ...          ...   \n",
      "3005  20240927_1600       STATE      GEORGIA   \n",
      "3005  20240927_1600      COUNTY       GEORGE   \n",
      "3005  20240927_1600        CITY    GEORGIANA   \n",
      "3006  20240927_1600      COUNTY     GUILFORD   \n",
      "3006  20240927_1600        CITY     GULFPORT   \n",
      "\n",
      "                                           matched_geom  match_score  \\\n",
      "0     MULTIPOLYGON (((-81.811693 24.568745, -81.7512...          100   \n",
      "0     POLYGON ((-66.588181 18.389408, -66.543079 18....          100   \n",
      "0     POLYGON ((-9372979.897895897 5059865.634627141...          100   \n",
      "1     MULTIPOLYGON (((-81.811693 24.568745, -81.7512...          100   \n",
      "1     POLYGON ((-66.588181 18.389408, -66.543079 18....          100   \n",
      "...                                                 ...          ...   \n",
      "3005  POLYGON ((-85.605165 34.984678, -85.4743388431...          100   \n",
      "3005  POLYGON ((-88.885038 30.910788, -88.834475 30....           77   \n",
      "3005  POLYGON ((-9656324.069495898 3718185.493427141...           88   \n",
      "3006  POLYGON ((-80.043238 36.010758, -80.037791 36....           75   \n",
      "3006  MULTIPOLYGON (((-9907705.966195896 3558409.375...          100   \n",
      "\n",
      "      original_index  \n",
      "0                  0  \n",
      "0                  0  \n",
      "0                  0  \n",
      "1                  1  \n",
      "1                  1  \n",
      "...              ...  \n",
      "3005            3005  \n",
      "3005            3005  \n",
      "3005            3005  \n",
      "3006            3006  \n",
      "3006            3006  \n",
      "\n",
      "[9473 rows x 17 columns]\n",
      "    Creating hierarchical raster for time 1727308800...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 40.89873\n",
      "['20240926_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240926_000000.tif\n",
      "max grid 40.89873\n",
      "['20240926_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240926_000000.tif\n",
      "  Incremental max value: 40.90\n",
      "  Cumulative max value: 40.90\n",
      "    Creating hierarchical raster for time 1727323200...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "max grid 47.23597\n",
      "['20240926_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240926_040000.tif\n",
      "max grid 88.134705\n",
      "['20240926_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240926_040000.tif\n",
      "  Incremental max value: 47.24\n",
      "  Cumulative max value: 88.13\n",
      "    Creating hierarchical raster for time 1727337600...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 1 unique facilities\n",
      "      Processed 1 facilities with sigma=2.00 pixels\n",
      "max grid 52.189014\n",
      "['20240926_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240926_080000.tif\n",
      "max grid 140.32372\n",
      "['20240926_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240926_080000.tif\n",
      "  Incremental max value: 52.19\n",
      "  Cumulative max value: 140.32\n",
      "    Creating hierarchical raster for time 1727352000...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 6 unique facilities\n",
      "      Processed 6 facilities with sigma=2.00 pixels\n",
      "max grid 47.5375\n",
      "['20240926_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240926_120000.tif\n",
      "max grid 187.8612\n",
      "['20240926_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240926_120000.tif\n",
      "  Incremental max value: 47.54\n",
      "  Cumulative max value: 187.86\n",
      "    Creating hierarchical raster for time 1727366400...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 3 unique facilities\n",
      "      Processed 3 facilities with sigma=2.00 pixels\n",
      "max grid 53.091133\n",
      "['20240926_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240926_160000.tif\n",
      "max grid 240.95233\n",
      "['20240926_160000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240926_160000.tif\n",
      "  Incremental max value: 53.09\n",
      "  Cumulative max value: 240.95\n",
      "    Creating hierarchical raster for time 1727380800...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 10 unique facilities\n",
      "      Processed 10 facilities with sigma=2.00 pixels\n",
      "max grid 57.25878\n",
      "['20240926_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240926_200000.tif\n",
      "max grid 298.21112\n",
      "['20240926_200000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240926_200000.tif\n",
      "  Incremental max value: 57.26\n",
      "  Cumulative max value: 298.21\n",
      "    Creating hierarchical raster for time 1727395200...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 5 unique facilities\n",
      "      Processed 5 facilities with sigma=2.00 pixels\n",
      "max grid 58.490566\n",
      "['20240927_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240927_000000.tif\n",
      "max grid 356.7017\n",
      "['20240927_000000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240927_000000.tif\n",
      "  Incremental max value: 58.49\n",
      "  Cumulative max value: 356.70\n",
      "    Creating hierarchical raster for time 1727409600...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 15 unique facilities\n",
      "      Processed 15 facilities with sigma=2.00 pixels\n",
      "max grid 59.069504\n",
      "['20240927_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240927_040000.tif\n",
      "max grid 415.77118\n",
      "['20240927_040000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240927_040000.tif\n",
      "  Incremental max value: 59.07\n",
      "  Cumulative max value: 415.77\n",
      "    Creating hierarchical raster for time 1727424000...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 7 unique facilities\n",
      "      Processed 7 facilities with sigma=2.00 pixels\n",
      "max grid 57.84243\n",
      "['20240927_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240927_080000.tif\n",
      "max grid 473.61362\n",
      "['20240927_080000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240927_080000.tif\n",
      "  Incremental max value: 57.84\n",
      "  Cumulative max value: 473.61\n",
      "    Creating hierarchical raster for time 1727438400...\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 12 unique facilities\n",
      "      Processed 12 facilities with sigma=2.00 pixels\n",
      "max grid 55.855267\n",
      "['20240927_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: increment/helene_tweets_20240927_120000.tif\n",
      "max grid 529.4689\n",
      "['20240927_120000']\n",
      "{'crs': 'EPSG:3857', 'cell_size': 1000, 'width': 3364, 'height': 2195, 'bounds': (np.float64(-11854083.11341075), np.float64(2947395.714660338), np.float64(-8490833.94284347), np.float64(5142357.362880709)), 'transform': Affine(np.float64(999.7768045681569), np.float64(0.0), np.float64(-11854083.11341075),\n",
      "       np.float64(0.0), np.float64(-999.9825276630389), np.float64(5142357.362880709))}\n",
      "    Saved: cumulative/helene_tweets_20240927_120000.tif\n",
      "  Incremental max value: 55.86\n",
      "  Cumulative max value: 529.47\n",
      "    Creating hierarchical raster for time 1727452800...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # ==============================================================================\n",
    "# # STEP 5: POST-PROCESSING & ASSEMBLY\n",
    "# # ==============================================================================\n",
    "# import glob\n",
    "# def create_metadata_index(hurricane_name, hurricane_dir):\n",
    "#     \"\"\"Create CSV index of all rasters with metadata\"\"\"\n",
    "#     print(f\"\\nCreating metadata index for {hurricane_name}...\")\n",
    "#\n",
    "#     # Get all increment and cumulative TIFFs\n",
    "#     increment_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\")))\n",
    "#     cumulative_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_cumulative_*.tif\")))\n",
    "#\n",
    "#     metadata_rows = []\n",
    "#\n",
    "#     for tif_path in increment_files + cumulative_files:\n",
    "#         filename = os.path.basename(tif_path)\n",
    "#\n",
    "#         # Extract time and type from filename\n",
    "#         parts = filename.replace('.tif', '').split('_')\n",
    "#         raster_type = parts[-2]  # 'increment' or 'cumulative'\n",
    "#         time_str = parts[-1]     # e.g., '20240910_0000'\n",
    "#\n",
    "#         # Open raster to get stats\n",
    "#         with rasterio.open(tif_path) as src:\n",
    "#             data = src.read(1)\n",
    "#\n",
    "#             metadata_rows.append({\n",
    "#                 'filename': filename,\n",
    "#                 'type': raster_type,\n",
    "#                 'time_str': time_str,\n",
    "#                 'min_value': np.min(data),\n",
    "#                 'max_value': np.max(data),\n",
    "#                 'mean_value': np.mean(data),\n",
    "#                 'total_value': np.sum(data),\n",
    "#                 'non_zero_pixels': np.count_nonzero(data)\n",
    "#             })\n",
    "#\n",
    "#     # Create DataFrame and save\n",
    "#     metadata_df = pd.DataFrame(metadata_rows)\n",
    "#     index_path = os.path.join(hurricane_dir, f\"{hurricane_name}_index.csv\")\n",
    "#     metadata_df.to_csv(index_path, index=False)\n",
    "#\n",
    "#     print(f\"  Index saved: {index_path}\")\n",
    "#     print(f\"  Total rasters cataloged: {len(metadata_rows)}\")\n",
    "#\n",
    "#     return metadata_df\n",
    "#\n",
    "#\n",
    "# def create_vrt_stacks(hurricane_name, hurricane_dir):\n",
    "#     \"\"\"Create VRT files using rasterio (no GDAL needed)\"\"\"\n",
    "#     print(f\"\\nCreating VRT stacks for {hurricane_name}...\")\n",
    "#\n",
    "#     # Simply skip VRT creation or create a text-based reference file\n",
    "#     increment_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\")))\n",
    "#\n",
    "#     # Create a simple text list file instead\n",
    "#     list_file = os.path.join(hurricane_dir, f\"{hurricane_name}_increment_files.txt\")\n",
    "#     with open(list_file, 'w') as f:\n",
    "#         for file in increment_files:\n",
    "#             f.write(file + '\\n')\n",
    "#\n",
    "#     print(f\"  Created file list: {hurricane_name}_increment_files.txt\")\n",
    "#     print(f\"  Import these files directly in ArcGIS Pro\")\n",
    "#\n",
    "# def print_summary_stats(hurricane_name, hurricane_dir):\n",
    "#     \"\"\"Print summary statistics for the hurricane dataset\"\"\"\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"SUMMARY: {hurricane_name.upper()}\")\n",
    "#     print(f\"{'='*60}\")\n",
    "#\n",
    "#     increment_files = glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\"))\n",
    "#     cumulative_files = glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_cumulative_*.tif\"))\n",
    "#\n",
    "#     print(f\"  Total time slices: {len(increment_files)}\")\n",
    "#     print(f\"  Increment rasters: {len(increment_files)}\")\n",
    "#     print(f\"  Cumulative rasters: {len(cumulative_files)}\")\n",
    "#     print(f\"  Output directory: {hurricane_dir}\")\n",
    "#\n",
    "#     # Get final cumulative stats\n",
    "#     if cumulative_files:\n",
    "#         final_cumulative = sorted(cumulative_files)[-1]\n",
    "#         with rasterio.open(final_cumulative) as src:\n",
    "#             final_data = src.read(1)\n",
    "#             print(f\"\\n  Final Cumulative Statistics:\")\n",
    "#             print(f\"    Total value: {np.sum(final_data):,.0f}\")\n",
    "#             print(f\"    Max pixel value: {np.max(final_data):,.2f}\")\n",
    "#             print(f\"    Active pixels: {np.count_nonzero(final_data):,}\")\n",
    "#\n",
    "# # ==============================================================================\n",
    "# # RUN POST-PROCESSING\n",
    "# # ==============================================================================\n",
    "#\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"STEP 5: POST-PROCESSING & ASSEMBLY\")\n",
    "# print(\"=\"*60)\n",
    "#\n",
    "# # Process Francine\n",
    "# francine_dir = os.path.join(output_dir, 'francine')\n",
    "# if os.path.exists(francine_dir):\n",
    "#     francine_metadata = create_metadata_index('francine', francine_dir)\n",
    "#     create_vrt_stacks('francine', francine_dir)\n",
    "#     print_summary_stats('francine', francine_dir)\n",
    "#\n",
    "# # Process Helene\n",
    "# helene_dir = os.path.join(output_dir, 'helene')\n",
    "# if os.path.exists(helene_dir):\n",
    "#     helene_metadata = create_metadata_index('helene', helene_dir)\n",
    "#     create_vrt_stacks('helene', helene_dir)\n",
    "#     print_summary_stats('helene', helene_dir)\n",
    "#\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"POST-PROCESSING COMPLETE! ✓\")\n"
   ],
   "id": "20a24d59822d8736",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T19:39:02.629771500Z",
     "start_time": "2025-10-08T19:30:07.000795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # PLACE THIS CODE AFTER YOUR RASTER GENERATION IS COMPLETE\n",
    "# # =============================================================================\n",
    "# # HEATMAP POST-PROCESSING AND STYLING\n",
    "# # =============================================================================\n",
    "#\n",
    "# import numpy as np\n",
    "# import rasterio\n",
    "# from scipy import ndimage\n",
    "# from scipy.ndimage import gaussian_filter\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mcolors\n",
    "# from rasterio.plot import show\n",
    "# import glob\n",
    "# import os\n",
    "#\n",
    "# def apply_heatmap_smoothing(input_raster_path, output_raster_path, sigma_multiplier=2.0):\n",
    "#     \"\"\"\n",
    "#     Apply gaussian smoothing to create heatmap effect\n",
    "#\n",
    "#     Parameters:\n",
    "#     - sigma_multiplier: Controls smoothing intensity (higher = more blur)\n",
    "#     \"\"\"\n",
    "#     with rasterio.open(input_raster_path) as src:\n",
    "#         data = src.read(1).astype(np.float32)\n",
    "#         profile = src.profile.copy()\n",
    "#\n",
    "#         # Apply gaussian filter for heatmap smoothing\n",
    "#         # Sigma is relative to cell size for consistent smoothing\n",
    "#         sigma = sigma_multiplier  # pixels\n",
    "#         smoothed_data = gaussian_filter(data, sigma=sigma, mode='constant', cval=0)\n",
    "#\n",
    "#         # Ensure no negative values\n",
    "#         smoothed_data = np.maximum(smoothed_data, 0)\n",
    "#\n",
    "#         # Update profile for output\n",
    "#         profile.update(dtype=rasterio.float32, compress='lzw')\n",
    "#\n",
    "#         # Write smoothed raster\n",
    "#         with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "#             dst.write(smoothed_data, 1)\n",
    "#\n",
    "#     print(f\"  Smoothed: {os.path.basename(output_raster_path)}\")\n",
    "#\n",
    "#     # Return stats\n",
    "#     original_max = np.max(data)\n",
    "#     smoothed_max = np.max(smoothed_data)\n",
    "#     return original_max, smoothed_max\n",
    "#\n",
    "# def create_heatmap_versions(hurricane_dir, hurricane_name, sigma=2.0):\n",
    "#     \"\"\"Create smoothed heatmap versions of all rasters\"\"\"\n",
    "#     print(f\"\\nCreating heatmap versions for {hurricane_name}...\")\n",
    "#\n",
    "#     # Create heatmap subdirectory\n",
    "#     heatmap_dir = os.path.join(hurricane_dir, 'heatmap')\n",
    "#     os.makedirs(heatmap_dir, exist_ok=True)\n",
    "#\n",
    "#     # Process all cumulative rasters (these are usually more interesting for heatmaps)\n",
    "#     cumulative_files = glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_cumulative_*.tif\"))\n",
    "#\n",
    "#     stats = []\n",
    "#     for tif_path in sorted(cumulative_files):\n",
    "#         filename = os.path.basename(tif_path)\n",
    "#         heatmap_filename = filename.replace('.tif', '_heatmap.tif')\n",
    "#         heatmap_path = os.path.join(heatmap_dir, heatmap_filename)\n",
    "#\n",
    "#         orig_max, smooth_max = apply_heatmap_smoothing(tif_path, heatmap_path, sigma)\n",
    "#         stats.append((filename, orig_max, smooth_max))\n",
    "#\n",
    "#     print(f\"  Created {len(cumulative_files)} heatmap rasters in: {heatmap_dir}\")\n",
    "#\n",
    "#     # Print smoothing statistics\n",
    "#     print(f\"  Smoothing statistics:\")\n",
    "#     for filename, orig_max, smooth_max in stats[:3]:  # Show first 3\n",
    "#         print(f\"    {filename}: {orig_max:.1f} → {smooth_max:.1f} (max value)\")\n",
    "#\n",
    "#     return heatmap_dir\n",
    "#\n",
    "# def create_heatmap_colormap():\n",
    "#     \"\"\"Create yellow-to-red heatmap colormap with transparent zero\"\"\"\n",
    "#     colors = [\n",
    "#         (0, 0, 0, 0),        # Transparent for 0\n",
    "#         (1, 1, 0, 1),        # Yellow (low values)\n",
    "#         (1, 0.75, 0, 1),     # Yellow-Orange\n",
    "#         (1, 0.5, 0, 1),      # Orange\n",
    "#         (1, 0.25, 0, 1),     # Orange-Red\n",
    "#         (1, 0, 0, 1),        # Red (high values)\n",
    "#         (0.55, 0, 0, 1),     # Dark Red (highest)\n",
    "#     ]\n",
    "#\n",
    "#     cmap = mcolors.LinearSegmentedColormap.from_list('heatmap', colors, N=256)\n",
    "#     cmap.set_under(color=(0, 0, 0, 0))  # Ensure values <= 0 are transparent\n",
    "#\n",
    "#     return cmap\n",
    "#\n",
    "# def preview_heatmap(raster_path, title=\"Heatmap Preview\"):\n",
    "#     \"\"\"Create a preview of the heatmap with proper styling\"\"\"\n",
    "#\n",
    "#     with rasterio.open(raster_path) as src:\n",
    "#         data = src.read(1)\n",
    "#\n",
    "#         # Create figure\n",
    "#         fig, ax = plt.subplots(figsize=(12, 8))\n",
    "#\n",
    "#         # Get custom colormap\n",
    "#         cmap = create_heatmap_colormap()\n",
    "#\n",
    "#         # Set up visualization\n",
    "#         # Use 95th percentile for max to avoid outliers dominating the scale\n",
    "#         vmax = np.percentile(data[data > 0], 95) if np.any(data > 0) else np.max(data)\n",
    "#         vmin = 0\n",
    "#\n",
    "#         # Display raster\n",
    "#         show(src, ax=ax, cmap=cmap, vmin=vmin, vmax=vmax, alpha=0.8)\n",
    "#\n",
    "#         # Styling\n",
    "#         ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "#         ax.set_aspect('equal')\n",
    "#\n",
    "#         # Add colorbar\n",
    "#         im = ax.images[0]\n",
    "#         cbar = plt.colorbar(im, ax=ax, shrink=0.8, aspect=20)\n",
    "#         cbar.set_label('Tweet Density', rotation=270, labelpad=20)\n",
    "#\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "#\n",
    "#         # Print statistics\n",
    "#         print(f\"  Data range: {np.min(data):.1f} - {np.max(data):.1f}\")\n",
    "#         print(f\"  95th percentile: {vmax:.1f}\")\n",
    "#         print(f\"  Non-zero pixels: {np.count_nonzero(data):,}\")\n",
    "#\n",
    "# def export_styled_geotiff(input_path, output_path, apply_colormap=True):\n",
    "#     \"\"\"Export a styled GeoTIFF with embedded colormap for direct use in web maps\"\"\"\n",
    "#\n",
    "#     with rasterio.open(input_path) as src:\n",
    "#         data = src.read(1)\n",
    "#         profile = src.profile.copy()\n",
    "#\n",
    "#         if apply_colormap:\n",
    "#             # Convert to 8-bit for colormap application\n",
    "#             # vmax = np.percentile(data[data > 0], 95) if np.any(data > 0) else np.max(data)\n",
    "#             # data_normalized = np.clip((data / vmax) * 255, 0, 255).astype(np.uint8)\n",
    "#\n",
    "#             # Update profile for 8-bit output\n",
    "#             profile.update(\n",
    "#                 dtype=rasterio.uint8,\n",
    "#                 count=1,\n",
    "#                 compress='lzw'\n",
    "#             )\n",
    "#\n",
    "#             # Write the normalized data\n",
    "#             with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "#                 dst.write(data, 1)\n",
    "#\n",
    "#                 # Create and write colormap\n",
    "#                 cmap = create_heatmap_colormap()\n",
    "#                 colormap = {}\n",
    "#                 for i in range(256):\n",
    "#                     rgba = cmap(i / 255.0)\n",
    "#                     # Convert to 0-255 range\n",
    "#                     colormap[i] = tuple(int(c * 255) for c in rgba)\n",
    "#\n",
    "#                 dst.write_colormap(1, colormap)\n",
    "#         else:\n",
    "#             # Keep as float32\n",
    "#             with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "#                 dst.write(data, 1)\n",
    "#\n",
    "#     print(f\"  Exported styled raster: {os.path.basename(output_path)}\")\n",
    "#\n",
    "# # =============================================================================\n",
    "# # EXECUTE HEATMAP PROCESSING\n",
    "# # =============================================================================\n",
    "#\n",
    "# def process_hurricane_heatmaps(hurricane_name, hurricane_dir, preview_latest=True):\n",
    "#     \"\"\"Complete heatmap processing pipeline for a hurricane\"\"\"\n",
    "#\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"HEATMAP PROCESSING: {hurricane_name.upper()}\")\n",
    "#     print(f\"{'='*60}\")\n",
    "#\n",
    "#     # Step 1: Create smoothed heatmap versions\n",
    "#     heatmap_dir = create_heatmap_versions(hurricane_dir, hurricane_name, sigma=2.5)\n",
    "#\n",
    "#     # Step 2: Create web-ready styled versions\n",
    "#     styled_dir = os.path.join(hurricane_dir, 'styled')\n",
    "#     os.makedirs(styled_dir, exist_ok=True)\n",
    "#\n",
    "#     heatmap_files = glob.glob(os.path.join(heatmap_dir, \"*.tif\"))\n",
    "#\n",
    "#     for heatmap_file in sorted(heatmap_files):\n",
    "#         filename = os.path.basename(heatmap_file)\n",
    "#         styled_filename = filename.replace('_heatmap.tif', '_styled.tif')\n",
    "#         styled_path = os.path.join(styled_dir, styled_filename)\n",
    "#\n",
    "#         # export_styled_geotiff(heatmap_file, styled_path, apply_colormap=True)\n",
    "#\n",
    "#     # Step 3: Preview the latest heatmap\n",
    "#     if preview_latest and heatmap_files:\n",
    "#         latest_heatmap = sorted(heatmap_files)[-1]\n",
    "#         preview_heatmap(latest_heatmap, f\"{hurricane_name.title()} - Latest Cumulative Heatmap\")\n",
    "#\n",
    "#     print(f\"\\n✓ {hurricane_name.upper()} heatmap processing complete!\")\n",
    "#     print(f\"  Smoothed rasters: {heatmap_dir}\")\n",
    "#     print(f\"  Styled rasters: {styled_dir}\")\n",
    "#\n",
    "#     return heatmap_dir, styled_dir\n",
    "#\n",
    "# # Run processing for your hurricanes\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"HEATMAP POST-PROCESSING\")\n",
    "# print(\"=\"*60)\n",
    "#\n",
    "# # Process both hurricanes\n",
    "# francine_dir = os.path.join(output_dir, 'francine')\n",
    "# helene_dir = os.path.join(output_dir, 'helene')\n",
    "#\n",
    "# if os.path.exists(francine_dir):\n",
    "#     francine_heatmap_dir, francine_styled_dir = process_hurricane_heatmaps('francine', francine_dir)\n",
    "#\n",
    "# if os.path.exists(helene_dir):\n",
    "#     helene_heatmap_dir, helene_styled_dir = process_hurricane_heatmaps('helene', helene_dir)\n",
    "#\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"ALL HEATMAP PROCESSING COMPLETE! 🔥\")\n"
   ],
   "id": "530b3a7a47b1f7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HEATMAP POST-PROCESSING\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "HEATMAP PROCESSING: FRANCINE\n",
      "============================================================\n",
      "\n",
      "Creating heatmap versions for francine...\n",
      "  Created 0 heatmap rasters in: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\\heatmap\n",
      "  Smoothing statistics:\n",
      "\n",
      "✓ FRANCINE heatmap processing complete!\n",
      "  Smoothed rasters: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\\heatmap\n",
      "  Styled rasters: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\\styled\n",
      "\n",
      "============================================================\n",
      "HEATMAP PROCESSING: HELENE\n",
      "============================================================\n",
      "\n",
      "Creating heatmap versions for helene...\n",
      "  Smoothed: helene_cumulative_1727308800_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727323200_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727337600_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727352000_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727366400_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727380800_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727395200_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727409600_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727424000_heatmap.tif\n",
      "  Smoothed: helene_cumulative_1727438400_heatmap.tif\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "Deleting C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\heatmap\\helene_cumulative_1727452800_heatmap.tif failed: Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m                      Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 222\u001B[39m\n\u001B[32m    219\u001B[39m     francine_heatmap_dir, francine_styled_dir = process_hurricane_heatmaps(\u001B[33m'\u001B[39m\u001B[33mfrancine\u001B[39m\u001B[33m'\u001B[39m, francine_dir)\n\u001B[32m    221\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m os.path.exists(helene_dir):\n\u001B[32m--> \u001B[39m\u001B[32m222\u001B[39m     helene_heatmap_dir, helene_styled_dir = \u001B[43mprocess_hurricane_heatmaps\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mhelene\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhelene_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    224\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m + \u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m*\u001B[32m60\u001B[39m)\n\u001B[32m    225\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mALL HEATMAP PROCESSING COMPLETE! 🔥\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 183\u001B[39m, in \u001B[36mprocess_hurricane_heatmaps\u001B[39m\u001B[34m(hurricane_name, hurricane_dir, preview_latest)\u001B[39m\n\u001B[32m    180\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m=\u001B[39m\u001B[33m'\u001B[39m*\u001B[32m60\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    182\u001B[39m \u001B[38;5;66;03m# Step 1: Create smoothed heatmap versions\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m183\u001B[39m heatmap_dir = \u001B[43mcreate_heatmap_versions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhurricane_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhurricane_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2.5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    185\u001B[39m \u001B[38;5;66;03m# Step 2: Create web-ready styled versions\u001B[39;00m\n\u001B[32m    186\u001B[39m styled_dir = os.path.join(hurricane_dir, \u001B[33m'\u001B[39m\u001B[33mstyled\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 66\u001B[39m, in \u001B[36mcreate_heatmap_versions\u001B[39m\u001B[34m(hurricane_dir, hurricane_name, sigma)\u001B[39m\n\u001B[32m     63\u001B[39m     heatmap_filename = filename.replace(\u001B[33m'\u001B[39m\u001B[33m.tif\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m_heatmap.tif\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     64\u001B[39m     heatmap_path = os.path.join(heatmap_dir, heatmap_filename)\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m     orig_max, smooth_max = \u001B[43mapply_heatmap_smoothing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtif_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheatmap_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     67\u001B[39m     stats.append((filename, orig_max, smooth_max))\n\u001B[32m     69\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  Created \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(cumulative_files)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m heatmap rasters in: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mheatmap_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 39\u001B[39m, in \u001B[36mapply_heatmap_smoothing\u001B[39m\u001B[34m(input_raster_path, output_raster_path, sigma_multiplier)\u001B[39m\n\u001B[32m     36\u001B[39m     profile.update(dtype=rasterio.float32, compress=\u001B[33m'\u001B[39m\u001B[33mlzw\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     38\u001B[39m     \u001B[38;5;66;03m# Write smoothed raster\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mrasterio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_raster_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mw\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mprofile\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m dst:\n\u001B[32m     40\u001B[39m         dst.write(smoothed_data, \u001B[32m1\u001B[39m)\n\u001B[32m     42\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  Smoothed: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mos.path.basename(output_raster_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\Tweet_project\\.venv\\Lib\\site-packages\\rasterio\\env.py:463\u001B[39m, in \u001B[36mensure_env_with_credentials.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwds)\u001B[39m\n\u001B[32m    460\u001B[39m     session = DummySession()\n\u001B[32m    462\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m env_ctor(session=session):\n\u001B[32m--> \u001B[39m\u001B[32m463\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\Tweet_project\\.venv\\Lib\\site-packages\\rasterio\\__init__.py:378\u001B[39m, in \u001B[36mopen\u001B[39m\u001B[34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, opener, **kwargs)\u001B[39m\n\u001B[32m    376\u001B[39m writer = get_writer_for_driver(driver)\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m378\u001B[39m     dataset = \u001B[43mwriter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcount\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcount\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcrs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnodata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnodata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m        \u001B[49m\u001B[43msharing\u001B[49m\u001B[43m=\u001B[49m\u001B[43msharing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    393\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m DriverCapabilityError(\n\u001B[32m    394\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWriter does not exist for driver: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m % \u001B[38;5;28mstr\u001B[39m(driver)\n\u001B[32m    395\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio\\\\_io.pyx:1509\u001B[39m, in \u001B[36mrasterio._io.DatasetWriterBase.__init__\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio\\\\_io.pyx:322\u001B[39m, in \u001B[36mrasterio._io._delete_dataset_if_exists\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio\\\\_err.pyx:289\u001B[39m, in \u001B[36mrasterio._err.exc_wrap_int\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m: Deleting C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\heatmap\\helene_cumulative_1727452800_heatmap.tif failed: Permission denied"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import arcpy\n",
    "import os\n",
    "\n",
    "def create_mosaic_preserve_values(gdb_path, mosaic_name, raster_folder, spatial_ref=None):\n",
    "    \"\"\"Create mosaic dataset that preserves original pixel values\"\"\"\n",
    "\n",
    "    mosaic_path = os.path.join(gdb_path, mosaic_name)\n",
    "\n",
    "    # Delete if exists\n",
    "    if arcpy.Exists(mosaic_path):\n",
    "        arcpy.Delete_management(mosaic_path)\n",
    "\n",
    "    # Get spatial reference from first raster if not provided\n",
    "    if not spatial_ref:\n",
    "        first_raster = [f for f in os.listdir(raster_folder) if f.endswith('.tif')][0]\n",
    "        spatial_ref = arcpy.Describe(os.path.join(raster_folder, first_raster)).spatialReference\n",
    "\n",
    "    # Create mosaic dataset with 32-bit float to preserve values\n",
    "    arcpy.CreateMosaicDataset_management(\n",
    "        gdb_path,\n",
    "        mosaic_name,\n",
    "        spatial_ref,\n",
    "        num_bands=1,\n",
    "        pixel_type=\"32_BIT_FLOAT\"\n",
    "    )\n",
    "\n",
    "    # Add rasters WITHOUT calculating statistics initially\n",
    "    arcpy.AddRastersToMosaicDataset_management(\n",
    "        mosaic_path,\n",
    "        \"Raster Dataset\",\n",
    "        raster_folder,\n",
    "        update_cellsize_ranges=\"NO_CELL_SIZES\",\n",
    "        update_boundary=\"UPDATE_BOUNDARY\",\n",
    "        update_overviews=\"NO_OVERVIEWS\",\n",
    "        calculate_statistics=\"NO_STATISTICS\"  # Don't calculate yet\n",
    "    )\n",
    "\n",
    "    # Calculate statistics with no sampling (skip factor = 1)\n",
    "    arcpy.CalculateStatistics_management(\n",
    "        mosaic_path,\n",
    "        x_skip_factor=1,  # No skipping - check every pixel\n",
    "        y_skip_factor=1,\n",
    "        skip_existing=\"OVERWRITE\"\n",
    "    )\n",
    "\n",
    "    # Set basic mosaic properties to prevent value alteration\n",
    "    arcpy.SetMosaicDatasetProperties_management(\n",
    "        mosaic_path,\n",
    "        resampling_type=\"NEAREST\",  # Preserve exact values\n",
    "        mosaic_operator=\"FIRST\"  # No blending\n",
    "    )\n",
    "\n",
    "    return mosaic_path\n",
    "\n",
    "def check_value_ranges(mosaic_path, raster_folder):\n",
    "    \"\"\"Compare original raster values with mosaic values\"\"\"\n",
    "\n",
    "    print(\"\\n=== VALUE COMPARISON ===\")\n",
    "\n",
    "    # Check mosaic statistics\n",
    "    mosaic_min = float(arcpy.GetRasterProperties_management(mosaic_path, \"MINIMUM\").getOutput(0))\n",
    "    mosaic_max = float(arcpy.GetRasterProperties_management(mosaic_path, \"MAXIMUM\").getOutput(0))\n",
    "    print(f\"\\nMosaic Dataset Range: {mosaic_min:.2f} to {mosaic_max:.2f}\")\n",
    "\n",
    "    # Check original rasters\n",
    "    print(\"\\nOriginal Raster Ranges:\")\n",
    "    tif_files = [f for f in os.listdir(raster_folder) if f.endswith('.tif')]\n",
    "\n",
    "    overall_min = float('inf')\n",
    "    overall_max = float('-inf')\n",
    "\n",
    "    for tif in tif_files[:5]:  # Check first 5 files\n",
    "        raster_path = os.path.join(raster_folder, tif)\n",
    "        r_min = float(arcpy.GetRasterProperties_management(raster_path, \"MINIMUM\").getOutput(0))\n",
    "        r_max = float(arcpy.GetRasterProperties_management(raster_path, \"MAXIMUM\").getOutput(0))\n",
    "        print(f\"  {tif}: {r_min:.2f} to {r_max:.2f}\")\n",
    "\n",
    "        overall_min = min(overall_min, r_min)\n",
    "        overall_max = max(overall_max, r_max)\n",
    "\n",
    "    print(f\"\\nOriginal Data Range: {overall_min:.2f} to {overall_max:.2f}\")\n",
    "\n",
    "    if abs(mosaic_max - overall_max) > 0.01:\n",
    "        print(\"\\n⚠️ WARNING: Mosaic max doesn't match original data!\")\n",
    "        print(\"   Recalculating statistics...\")\n",
    "\n",
    "        # Force recalculation\n",
    "        arcpy.CalculateStatistics_management(\n",
    "            mosaic_path,\n",
    "            x_skip_factor=1,\n",
    "            y_skip_factor=1,\n",
    "            skip_existing=\"OVERWRITE\"\n",
    "        )\n",
    "\n",
    "        # Check again\n",
    "        new_max = float(arcpy.GetRasterProperties_management(mosaic_path, \"MAXIMUM\").getOutput(0))\n",
    "        print(f\"   New mosaic max: {new_max:.2f}\")\n",
    "\n",
    "def add_date_attribute(mosaic_path):\n",
    "    \"\"\"Add date field to footprints table\"\"\"\n",
    "\n",
    "    footprint_table = os.path.join(mosaic_path, \"Footprint\")\n",
    "\n",
    "    # Add date field\n",
    "    if \"AcquisitionDate\" not in [f.name for f in arcpy.ListFields(footprint_table)]:\n",
    "        arcpy.AddField_management(footprint_table, \"AcquisitionDate\", \"TEXT\", field_length=20)\n",
    "\n",
    "    # Update based on filename - modify this pattern for your files\n",
    "    with arcpy.da.UpdateCursor(footprint_table, [\"Name\", \"AcquisitionDate\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            filename = row[0]\n",
    "            # Extract date from your filename pattern\n",
    "            # Example: if files are named like \"data_20231215.tif\"\n",
    "            import re\n",
    "            date_match = re.search(r'(\\d{8})', filename)\n",
    "            if date_match:\n",
    "                row[1] = date_match.group(1)\n",
    "                cursor.updateRow(row)\n",
    "\n",
    "# MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your paths\n",
    "    gdb_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\Tweet_project.gdb\"\n",
    "    mosaic_name = \"helene_cumulative_mosaic_v3\"\n",
    "    raster_folder = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\cumulative\"\n",
    "\n",
    "    # Create mosaic\n",
    "    mosaic_path = create_mosaic_preserve_values(gdb_path, mosaic_name, raster_folder)\n",
    "\n",
    "    # Verify values are preserved\n",
    "    check_value_ranges(mosaic_path, raster_folder)\n",
    "\n",
    "    # Add dates if needed\n",
    "    add_date_attribute(mosaic_path)\n",
    "\n",
    "    print(f\"\\n✓ Mosaic created: {mosaic_path}\")"
   ],
   "id": "83136045c059935d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import arcpy\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def add_time_to_mosaic(mosaic_path, date_field_name=\"AcquisitionDate\"):\n",
    "    \"\"\"Add and configure time attribute for mosaic dataset\"\"\"\n",
    "\n",
    "    # 1. Add date field to footprint table\n",
    "    footprint_table = os.path.join(mosaic_path, \"Footprint\")\n",
    "\n",
    "    # Check if field exists\n",
    "    existing_fields = [f.name for f in arcpy.ListFields(footprint_table)]\n",
    "\n",
    "    if date_field_name not in existing_fields:\n",
    "        arcpy.AddField_management(footprint_table, date_field_name, \"DATE\")\n",
    "        print(f\"Added {date_field_name} field\")\n",
    "\n",
    "    # 2. Populate dates from filenames\n",
    "    print(\"\\nPopulating dates from filenames...\")\n",
    "    with arcpy.da.UpdateCursor(footprint_table, [\"Name\", date_field_name]) as cursor:\n",
    "        for row in cursor:\n",
    "            filename = row[0]\n",
    "\n",
    "            # MODIFY THIS SECTION based on your filename pattern\n",
    "            # Example patterns:\n",
    "\n",
    "            # Pattern 1: YYYYMMDD somewhere in filename (e.g., \"data_20231215.tif\")\n",
    "            date_match = re.search(r'(\\d{8})', filename)\n",
    "            if date_match:\n",
    "                date_str = date_match.group(1)\n",
    "                date_obj = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "                row[1] = date_obj\n",
    "                cursor.updateRow(row)\n",
    "                print(f\"  {filename} → {date_obj.strftime('%Y-%m-%d')}\")\n",
    "                continue\n",
    "\n",
    "            # Pattern 2: YYYY-MM-DD format\n",
    "            date_match = re.search(r'(\\d{4})-(\\d{2})-(\\d{2})', filename)\n",
    "            if date_match:\n",
    "                year, month, day = date_match.groups()\n",
    "                date_obj = datetime(int(year), int(month), int(day))\n",
    "                row[1] = date_obj\n",
    "                cursor.updateRow(row)\n",
    "                print(f\"  {filename} → {date_obj.strftime('%Y-%m-%d')}\")\n",
    "                continue\n",
    "\n",
    "            # Pattern 3: Julian day (e.g., \"2023_365.tif\" for year_dayofyear)\n",
    "            date_match = re.search(r'(\\d{4})_(\\d{3})', filename)\n",
    "            if date_match:\n",
    "                year = int(date_match.group(1))\n",
    "                julian_day = int(date_match.group(2))\n",
    "                date_obj = datetime(year, 1, 1) + timedelta(days=julian_day - 1)\n",
    "                row[1] = date_obj\n",
    "                cursor.updateRow(row)\n",
    "                print(f\"  {filename} → {date_obj.strftime('%Y-%m-%d')}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"  ⚠️ No date found in: {filename}\")\n",
    "\n",
    "    # 3. Build attribute table to ensure field is recognized\n",
    "    arcpy.BuildRasterAttributeTable_management(mosaic_path, \"OVERWRITE\")\n",
    "\n",
    "    # 4. Configure mosaic to use time\n",
    "    print(f\"\\nConfiguring mosaic to order by {date_field_name}...\")\n",
    "    arcpy.SetMosaicDatasetProperties_management(\n",
    "        mosaic_path,\n",
    "        default_mosaic_method=\"ByAttribute\",\n",
    "        order_field=date_field_name,\n",
    "        order_base=\"\",\n",
    "        sorting_order=\"ASCENDING\"  # or \"DESCENDING\" for newest first\n",
    "    )\n",
    "\n",
    "    print(\"\\n✓ Time configuration complete!\")\n",
    "    print(f\"Mosaic will now order rasters by {date_field_name}\")\n",
    "\n",
    "def verify_dates(mosaic_path, date_field_name=\"AcquisitionDate\"):\n",
    "    \"\"\"Check that dates were properly assigned\"\"\"\n",
    "\n",
    "    footprint_table = os.path.join(mosaic_path, \"Footprint\")\n",
    "\n",
    "    print(\"\\nDate verification:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    with arcpy.da.SearchCursor(footprint_table, [\"Name\", date_field_name]) as cursor:\n",
    "        dates_found = 0\n",
    "        dates_missing = 0\n",
    "\n",
    "        for row in cursor:\n",
    "            if row[1]:\n",
    "                dates_found += 1\n",
    "                if dates_found <= 5:  # Show first 5\n",
    "                    print(f\"{row[0]}: {row[1]}\")\n",
    "            else:\n",
    "                dates_missing += 1\n",
    "\n",
    "        print(f\"\\nSummary: {dates_found} dates found, {dates_missing} missing\")\n",
    "\n",
    "def enable_time_slider(mosaic_path, date_field_name=\"AcquisitionDate\"):\n",
    "    \"\"\"Enable time properties for use with time slider in ArcGIS Pro\"\"\"\n",
    "\n",
    "    # This enables the time dimension\n",
    "    arcpy.EnableTime_management(mosaic_path, date_field_name)\n",
    "    print(f\"\\n✓ Time slider enabled using {date_field_name}\")\n",
    "    print(\"In ArcGIS Pro: View tab → Time group → Time slider\")\n",
    "\n",
    "# Alternative: Parse dates from TIFF metadata\n",
    "def extract_dates_from_metadata(mosaic_path):\n",
    "    \"\"\"Extract dates from TIFF metadata if available\"\"\"\n",
    "\n",
    "    footprint_table = os.path.join(mosaic_path, \"Footprint\")\n",
    "\n",
    "    with arcpy.da.UpdateCursor(footprint_table, [\"Raster\", \"AcquisitionDate\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            raster_path = row[0]\n",
    "\n",
    "            try:\n",
    "                # Get raster properties\n",
    "                raster = arcpy.Raster(raster_path)\n",
    "\n",
    "                # Check for date in metadata\n",
    "                # Common tags: TIFFTAG_DATETIME, acquisition_date, etc.\n",
    "                desc = arcpy.Describe(raster_path)\n",
    "\n",
    "                # Try to get from properties\n",
    "                if hasattr(raster, 'acquisition_date'):\n",
    "                    row[1] = raster.acquisition_date\n",
    "                    cursor.updateRow(row)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    raster_folder = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\cumulative\"\n",
    "    mosaic_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\Tweet_project.gdb\\helene_cumulative_mosaic_v3\"\n",
    "\n",
    "    # Add time attribute\n",
    "    add_time_to_mosaic(mosaic_path)\n",
    "\n",
    "    # Verify it worked\n",
    "    verify_dates(mosaic_path)\n",
    "\n",
    "    # Optional: Enable for time slider\n",
    "    enable_time_slider(mosaic_path)"
   ],
   "id": "5227a4c24b0527b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import arcpy\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Note this is to be inserted into the python command window\n",
    "# Paths\n",
    "gdb_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\Tweet_project.gdb\"\n",
    "\n",
    "\n",
    "raster_folder = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\cumulative\"\n",
    "mosaic_name = \"helene_cumulative_mosaic_v2\"\n",
    "\n",
    "raster_folder = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\increment\"\n",
    "mosaic_name = \"helene_increment_mosaic_v2\"\n",
    "\n",
    "raster_folder = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\\cumulative\"\n",
    "mosaic_name = \"francine_cumulative_mosaic_v2\"\n",
    "\n",
    "raster_folder = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\\increment\"\n",
    "mosaic_name = \"francine_increment_mosaic_v2\"\n",
    "\n",
    "\n",
    "\n",
    "# Create geodatabase if it doesn't exist\n",
    "if not arcpy.Exists(gdb_path):\n",
    "    arcpy.CreateFileGDB_management(os.path.dirname(gdb_path), os.path.basename(gdb_path))\n",
    "\n",
    "# Create mosaic dataset\n",
    "mosaic_path = os.path.join(gdb_path, mosaic_name)\n",
    "if arcpy.Exists(mosaic_path):\n",
    "    arcpy.Delete_management(mosaic_path)\n",
    "\n",
    "arcpy.CreateMosaicDataset_management(gdb_path, mosaic_name, \"PROJCS['WGS_1984_Web_Mercator_Auxiliary_Sphere',GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]],PROJECTION['Mercator_Auxiliary_Sphere'],PARAMETER['False_Easting',0.0],PARAMETER['False_Northing',0.0],PARAMETER['Central_Meridian',0.0],PARAMETER['Standard_Parallel_1',0.0],PARAMETER['Auxiliary_Sphere_Type',0.0],UNIT['Meter',1.0]]\")\n",
    "\n",
    "print(f\"Created mosaic dataset: {mosaic_path}\")\n",
    "\n",
    "# Add rasters to mosaic\n",
    "arcpy.AddRastersToMosaicDataset_management(\n",
    "    mosaic_path,\n",
    "    \"Raster Dataset\",\n",
    "    raster_folder,\n",
    "    filter=\"*.tif\"\n",
    ")\n",
    "\n",
    "print(\"Added rasters to mosaic dataset\")\n",
    "\n",
    "# Add time field\n",
    "arcpy.AddField_management(mosaic_path, \"date\", \"DATE\")\n",
    "\n",
    "# Calculate time from filename\n",
    "with arcpy.da.UpdateCursor(mosaic_path, [\"Name\", \"date\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        filename = row[0]\n",
    "        # Remove .tif extension and split\n",
    "        parts = filename.replace(\".tif\", \"\").split(\"_\")\n",
    "\n",
    "        # Join last two parts to get full timestamp: 20240926 + 080000\n",
    "        time_str = parts[-2] + parts[-1]  # Combines date and time\n",
    "\n",
    "        # Parse: 20240926080000 -> datetime\n",
    "        dt = datetime.strptime(time_str, \"%Y%m%d%H%M%S\")\n",
    "        print(f\"{filename} -> {time_str} -> {dt}\")\n",
    "        row[1] = dt\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Time field populated\")\n",
    "\n",
    "# Configure mosaic properties\n",
    "arcpy.SetMosaicDatasetProperties_management(\n",
    "    mosaic_path,\n",
    "    start_time_field=\"date\"\n",
    ")\n",
    "\n",
    "print(\"Mosaic dataset configured with time dimension\")\n",
    "\n",
    "print(f\"\\nMosaic dataset complete: {mosaic_path}\")\n",
    "print(\"To apply symbology in ArcGIS Pro:\")\n",
    "print(f\"1. Add mosaic to map: {mosaic_path}\")\n",
    "print(f\"2. Right-click layer > Symbology > Import\")\n",
    "print(f\"3. Select: {symbology_file}\")\n",
    "print(\"4. Enable time slider to animate cumulative growth\")"
   ],
   "id": "80b96b516fb40db0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "43d165e312079ee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import arcpy\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "#\n",
    "# # Paths\n",
    "#\n",
    "# raster_folder = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\increment\"\n",
    "# gdb_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\Tweet_project.gdb\"\n",
    "# mosaic_name = \"helene_cumulative_mosaic_v3\"\n",
    "# coordinate_system = \"PROJCS['WGS_1984_Web_Mercator_Auxiliary_Sphere',GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]],PROJECTION['Mercator_Auxiliary_Sphere'],PARAMETER['False_Easting',0.0],PARAMETER['False_Northing',0.0],PARAMETER['Central_Meridian',0.0],PARAMETER['Standard_Parallel_1',0.0],PARAMETER['Auxiliary_Sphere_Type',0.0],UNIT['Meter',1.0]]\"\n",
    "# # Create geodatabase if it doesn't exist\n",
    "# if not arcpy.Exists(gdb_path):\n",
    "#     arcpy.CreateFileGDB_management(os.path.dirname(gdb_path), os.path.basename(gdb_path))\n",
    "#\n",
    "# # Create mosaic dataset\n",
    "# # Create mosaic dataset with the CORRECT pixel type\n",
    "# mosaic_path = os.path.join(gdb_path, mosaic_name)\n",
    "# if arcpy.Exists(mosaic_path):\n",
    "#     arcpy.Delete_management(mosaic_path)\n",
    "#\n",
    "# # --- THIS IS THE LINE TO CHANGE ---\n",
    "# arcpy.CreateMosaicDataset_management(\n",
    "#     in_workspace=gdb_path,\n",
    "#     in_mosaicdataset_name=mosaic_name,\n",
    "#     coordinate_system=coordinate_system,\n",
    "#     num_bands=1, # Add this line\n",
    "#     pixel_type='32_BIT_FLOAT' # Add this line\n",
    "# )\n",
    "# print(f\"Created mosaic dataset: {mosaic_path}\")\n",
    "#\n",
    "# # Add rasters to mosaic\n",
    "# arcpy.AddRastersToMosaicDataset_management(\n",
    "#     mosaic_path,\n",
    "#     \"Raster Dataset\",\n",
    "#     raster_folder,\n",
    "#     filter=\"*.tif\"\n",
    "# )\n",
    "#\n",
    "# print(\"Added rasters to mosaic dataset\")\n",
    "#\n",
    "# # Add time field\n",
    "# arcpy.AddField_management(mosaic_path, \"date\", \"DATE\")\n",
    "#\n",
    "# # Calculate time from filename\n",
    "# # Calculate time from filename\n",
    "# # Calculate time from filename\n",
    "# with arcpy.da.UpdateCursor(mosaic_path, [\"Name\", \"date\"]) as cursor:\n",
    "#     for row in cursor:\n",
    "#         filename = row[0]\n",
    "#         # Remove .tif extension and split\n",
    "#         parts = filename.replace(\".tif\", \"\").split(\"_\")\n",
    "#\n",
    "#         # Join last two parts to get full timestamp: 20240926 + 080000\n",
    "#         time_str = parts[-2] + parts[-1]  # Combines date and time\n",
    "#\n",
    "#         # Parse: 20240926080000 -> datetime\n",
    "#         dt = datetime.strptime(time_str, \"%Y%m%d%H%M%S\")\n",
    "#         print(f\"{filename} -> {time_str} -> {dt}\")\n",
    "#         row[1] = dt\n",
    "#         cursor.updateRow(row)\n",
    "#\n",
    "# print(\"Time field populated\")\n",
    "#\n",
    "# # Configure mosaic properties\n",
    "# arcpy.SetMosaicDatasetProperties_management(\n",
    "#     mosaic_path,\n",
    "#     start_time_field=\"date\"\n",
    "# )\n",
    "#\n",
    "# print(\"Mosaic dataset configured with time dimension\")\n",
    "# arcpy.CalculateStatistics_management(mosaic_path)\n",
    "# print(f\"\\nMosaic dataset complete: {mosaic_path}\")\n",
    "# print(\"To apply symbology in ArcGIS Pro:\")\n",
    "# print(f\"1. Add mosaic to map: {mosaic_path}\")\n",
    "# print(f\"2. Right-click layer > Symbology > Import\")\n",
    "# print(f\"3. Select: {symbology_file}\")\n",
    "# print(\"4. Enable time slider to animate cumulative growth\")"
   ],
   "id": "622b557da0d7f13a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8f404f28c680cff4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
