{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T18:50:44.776871Z",
     "start_time": "2025-09-22T18:50:44.774630Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install fuzzywuzzy python-Levenshtein geopandas pandas numpy matplotlib",
   "id": "203a6780cd79d505",
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T18:50:44.938897Z",
     "start_time": "2025-09-22T18:50:44.781735Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Load GeoJSON files\n",
    "local_path = os.getcwd()\n",
    "local_path = os.path.join(os.getcwd(),r'GitHub\\Tweet_project')\n",
    "# Correctly join the paths without a leading slash\n",
    "# The 'r' prefix is not necessary here, but it doesn't hurt\n",
    "francine_dir = r\"\\data\\geojson\\francine.geojson\"\n",
    "helene_dir = r\"\\data\\geojson\\helene.geojson\"\n",
    "francine_path = f\"{local_path}{francine_dir}\"\n",
    "helene_path = f\"{local_path}{helene_dir}\"\n",
    "# francine_path = os.path.join(local_path, '\\data\\geojson', 'francine.geojson')\n",
    "# helene_path = os.path.join(local_path, '\\data\\geojson', 'helene.geojson')\n",
    "print(francine_path)\n",
    "\n",
    "# francine_path = os.path.join(os.getcwd(), r'data\\geojson\\francine.geojson')\n",
    "# helene_path = os.path.join(os.getcwd(), r'data\\geojson\\helene.geojson')\n",
    "\n",
    "\n",
    "# francine_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\geojson\\francine.geojson\"\n",
    "# helene_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\geojson\\helene.geojson\"\n",
    "\n",
    "# Load into GeoDataFrames\n",
    "francine_gdf = gpd.read_file(francine_path)\n",
    "helene_gdf = gpd.read_file(helene_path)\n",
    "\n",
    "# Standardize timestamps to UTC\n",
    "francine_gdf['timestamp'] = pd.to_datetime(francine_gdf['time'], utc=True)\n",
    "# print(francine_gdf['time'])\n",
    "helene_gdf['timestamp'] = pd.to_datetime(helene_gdf['time'], utc=True)\n",
    "\n",
    "\n",
    "# Floor to 4-hour bins\n",
    "francine_gdf['time_bin'] = francine_gdf['timestamp'].dt.floor('4h')\n",
    "helene_gdf['time_bin'] = helene_gdf['timestamp'].dt.floor('4h')\n",
    "all_data = francine_gdf['time_bin'].unique()\n",
    "francine_gdf['unix_timestamp'] = francine_gdf['time_bin'].astype('int64') // 1000\n",
    "helene_gdf['unix_timestamp'] = helene_gdf['time_bin'].astype('int64') // 1000\n",
    "# Create readable bin labels for file naming\n",
    "francine_gdf['bin_label'] = francine_gdf['time_bin'].dt.strftime('%Y%m%d_%H%M')\n",
    "helene_gdf['bin_label'] = helene_gdf['time_bin'].dt.strftime('%Y%m%d_%H%M')\n",
    "# Display summary\n",
    "# print(\"FRANCINE Dataset:\")\n",
    "# print(f\"  Total tweets: {len(francine_gdf)}\")\n",
    "# print(f\"  Time range: {francine_gdf['time_bin'].min()} to {francine_gdf['time_bin'].max()}\")\n",
    "# print(f\"  Number of 4-hour bins: {francine_gdf['time_bin'].nunique()}\")\n",
    "# print(f\"\\nHELENE Dataset:\")\n",
    "# print(f\"  Total tweets: {len(helene_gdf)}\")\n",
    "# print(f\"  Time range: {helene_gdf['time_bin'].min()} to {helene_gdf['time_bin'].max()}\")\n",
    "# print(f\"  Number of 4-hour bins: {helene_gdf['time_bin'].nunique()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clgoodr2\\Documents\\GitHub\\Tweet_project\\data\\geojson\\francine.geojson\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T20:10:33.127667Z",
     "start_time": "2025-09-22T20:00:33.305381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load reference shapefiles\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "# states_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\shape_files\\cb_2023_us_state_20m.shp\"\n",
    "# counties_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\shape_files\\cb_2023_us_county_20m.shp\"\n",
    "# cities_path = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data\\shape_files\\US_Cities.shp\"\n",
    "states_dir = r\"\\data\\shape_files\\cb_2023_us_state_20m.shp\"\n",
    "counties_dir = r\"\\data\\shape_files\\cb_2023_us_county_20m.shp\"\n",
    "cities_dir = r\"\\data\\shape_files\\US_Cities.shp\"\n",
    "states_path = f\"{local_path}{states_dir}\"\n",
    "counties_path = f\"{local_path}{counties_dir}\"\n",
    "cities_path = f\"{local_path}{cities_dir}\"\n",
    "\n",
    "#\n",
    "# states_path = os.path.join(local_path, '\\data\\shape_files', 'cb_2023_us_state_20m.shp')\n",
    "# counties_path = os.path.join(local_path, '\\data\\shape_files', 'cb_2023_us_county_20m.shp')\n",
    "# cities_path = os.path.join(local_path, '\\data\\shape_files', 'US_Cities.shp')\n",
    "\n",
    "# Load spatial reference data\n",
    "states_gdf = gpd.read_file(states_path)\n",
    "counties_gdf = gpd.read_file(counties_path)\n",
    "cities_gdf = gpd.read_file(cities_path)\n",
    "\n",
    "# PLACE THIS CODE AFTER LOADING SHAPEFILES BUT BEFORE CREATING SIMPLE LOOKUPS\n",
    "# =============================================================================\n",
    "# MULTI-LEVEL GEOGRAPHIC MATCHING SYSTEM (ALL LEVELS)\n",
    "# =============================================================================\n",
    "\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "def preprocess_place_name(name):\n",
    "    \"\"\"Standardize place names for better matching\"\"\"\n",
    "    if pd.isna(name) or name == 'NAN':\n",
    "        return None\n",
    "\n",
    "    name = str(name).upper().strip()\n",
    "\n",
    "    # Common abbreviation standardizations\n",
    "    name = re.sub(r'\\bST\\.?\\b', 'SAINT', name)  # St. -> Saint\n",
    "    name = re.sub(r'\\bMT\\.?\\b', 'MOUNT', name)  # Mt. -> Mount\n",
    "    name = re.sub(r'\\bFT\\.?\\b', 'FORT', name)   # Ft. -> Fort\n",
    "    name = re.sub(r'\\bN\\.?\\b', 'NORTH', name)   # N. -> North\n",
    "    name = re.sub(r'\\bS\\.?\\b', 'SOUTH', name)   # S. -> South\n",
    "    name = re.sub(r'\\bE\\.?\\b', 'EAST', name)    # E. -> East\n",
    "    name = re.sub(r'\\bW\\.?\\b', 'WEST', name)    # W. -> West\n",
    "\n",
    "    # Remove extra spaces and punctuation\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)  # Remove punctuation\n",
    "    name = re.sub(r'\\s+', ' ', name)     # Normalize spaces\n",
    "\n",
    "    return name.strip()\n",
    "\n",
    "def parse_gpe_entities(gpe_string):\n",
    "    \"\"\"Parse GPE string into multiple potential geographic entities\"\"\"\n",
    "    if not gpe_string or pd.isna(gpe_string) or str(gpe_string).strip() == '':\n",
    "        return []\n",
    "\n",
    "    gpe_string = str(gpe_string).strip()\n",
    "\n",
    "    # Split by common separators\n",
    "    entities = []\n",
    "\n",
    "    # Primary split by comma\n",
    "    parts = [part.strip() for part in gpe_string.split(',')]\n",
    "\n",
    "    for part in parts:\n",
    "        if part:\n",
    "            # Further split by other separators\n",
    "            sub_parts = re.split(r'[;&|]', part)\n",
    "            for sub_part in sub_parts:\n",
    "                sub_part = sub_part.strip()\n",
    "                if sub_part and len(sub_part) > 1:  # Ignore single characters\n",
    "                    entities.append(preprocess_place_name(sub_part))\n",
    "\n",
    "    # Remove None values and duplicates while preserving order\n",
    "    clean_entities = []\n",
    "    seen = set()\n",
    "    for entity in entities:\n",
    "        if entity and entity not in seen:\n",
    "            clean_entities.append(entity)\n",
    "            seen.add(entity)\n",
    "\n",
    "    return clean_entities\n",
    "\n",
    "def create_hierarchical_lookups(states_gdf, counties_gdf, cities_gdf):\n",
    "    \"\"\"Create hierarchical lookup dictionaries for fuzzy matching\"\"\"\n",
    "    print(\"\\nCreating hierarchical lookup dictionaries...\")\n",
    "\n",
    "    # 1. States - simple lookup with preprocessed names + abbreviations\n",
    "    state_lookup = {}\n",
    "    state_abbrev_to_name = {}  # Abbreviation to full name\n",
    "    state_name_to_abbrev = {}  # Full name to abbreviation\n",
    "\n",
    "    for idx, row in states_gdf.iterrows():\n",
    "        state_name = preprocess_place_name(row['NAME'])\n",
    "        if state_name:\n",
    "            state_lookup[state_name] = row.geometry\n",
    "            # Handle abbreviations if available\n",
    "            if 'STUSPS' in row:\n",
    "                abbrev = row['STUSPS'].upper()\n",
    "                state_abbrev_to_name[abbrev] = state_name\n",
    "                state_name_to_abbrev[state_name] = abbrev\n",
    "                # Also add abbreviation as a lookup option\n",
    "                state_lookup[abbrev] = row.geometry\n",
    "\n",
    "    # 2. Counties - organized by state\n",
    "    county_by_state = {}\n",
    "    county_lookup = {}\n",
    "\n",
    "    for idx, row in counties_gdf.iterrows():\n",
    "        county_name = preprocess_place_name(row['NAME'])\n",
    "        state_fips = row.get('STATEFP', '')\n",
    "\n",
    "        if county_name:\n",
    "            county_lookup[county_name] = row.geometry\n",
    "\n",
    "            # Try to get state name from STATEFP or other fields\n",
    "            state_name = None\n",
    "            if 'STATE_NAME' in row:\n",
    "                state_name = preprocess_place_name(row['STATE_NAME'])\n",
    "            else:\n",
    "                # Try to find state by FIPS code\n",
    "                for s_idx, s_row in states_gdf.iterrows():\n",
    "                    if s_row.get('STATEFP', '') == state_fips:\n",
    "                        state_name = preprocess_place_name(s_row['NAME'])\n",
    "                        break\n",
    "\n",
    "            if state_name:\n",
    "                if state_name not in county_by_state:\n",
    "                    county_by_state[state_name] = {}\n",
    "                county_by_state[state_name][county_name] = row.geometry\n",
    "\n",
    "    # 3. Cities - organized by state\n",
    "    city_by_state = {}\n",
    "    city_lookup = {}\n",
    "\n",
    "    for idx, row in cities_gdf.iterrows():\n",
    "        city_name = preprocess_place_name(row['NAME'])\n",
    "        state_abbrev = row.get('ST', '').upper()\n",
    "\n",
    "        if city_name:\n",
    "            city_lookup[city_name] = row.geometry\n",
    "\n",
    "            # Convert state abbreviation to full name\n",
    "            if state_abbrev in state_abbrev_to_name:\n",
    "                state_full = state_abbrev_to_name[state_abbrev]\n",
    "                if state_full not in city_by_state:\n",
    "                    city_by_state[state_full] = {}\n",
    "                city_by_state[state_full][city_name] = row.geometry\n",
    "\n",
    "    print(f\"  States: {len(state_lookup)} (including abbreviations)\")\n",
    "    print(f\"  Counties: {len(county_lookup)} (organized by {len(county_by_state)} states)\")\n",
    "    print(f\"  Cities: {len(city_lookup)} (organized by {len(city_by_state)} states)\")\n",
    "\n",
    "    return {\n",
    "        'state_lookup': state_lookup,\n",
    "        'county_lookup': county_lookup,\n",
    "        'city_lookup': city_lookup,\n",
    "        'county_by_state': county_by_state,\n",
    "        'city_by_state': city_by_state,\n",
    "        'state_abbrev_to_name': state_abbrev_to_name,\n",
    "        'state_name_to_abbrev': state_name_to_abbrev\n",
    "    }\n",
    "\n",
    "def fuzzy_match_entity(entity, candidates, threshold=75):\n",
    "    \"\"\"Fuzzy match an entity against candidates\"\"\"\n",
    "    if not entity or not candidates:\n",
    "        return None, 0\n",
    "\n",
    "    # Try exact match first\n",
    "    if entity in candidates:\n",
    "        return entity, 100\n",
    "\n",
    "    # Use fuzzy matching\n",
    "    match = process.extractOne(entity, candidates.keys(), scorer=fuzz.ratio)\n",
    "\n",
    "    if match and match[1] >= threshold:\n",
    "        return match[0], match[1]\n",
    "\n",
    "    return None, 0\n",
    "\n",
    "def find_all_geographic_matches(entities, lookups):\n",
    "    \"\"\"Find ALL geographic matches (state, county, city) for the entities\"\"\"\n",
    "    if not entities:\n",
    "        return []\n",
    "\n",
    "    state_lookup = lookups['state_lookup']\n",
    "    county_lookup = lookups['county_lookup']\n",
    "    city_lookup = lookups['city_lookup']\n",
    "    county_by_state = lookups['county_by_state']\n",
    "    city_by_state = lookups['city_by_state']\n",
    "\n",
    "    # Store all successful matches\n",
    "    all_matches = []\n",
    "\n",
    "    # Context tracking for better matching\n",
    "    found_states = set()\n",
    "\n",
    "    # STEP 1: Find all state matches first\n",
    "    for entity in entities:\n",
    "        state_match, state_score = fuzzy_match_entity(entity, state_lookup, threshold=75)\n",
    "        if state_match:\n",
    "            all_matches.append(('STATE', state_match, state_lookup[state_match], state_score))\n",
    "            found_states.add(state_match)\n",
    "\n",
    "    # STEP 2: Find county matches (global first, then state-specific)\n",
    "    for entity in entities:\n",
    "        # Global county search\n",
    "        county_match, county_score = fuzzy_match_entity(entity, county_lookup, threshold=75)\n",
    "        if county_match:\n",
    "            all_matches.append(('COUNTY', county_match, county_lookup[county_match], county_score))\n",
    "\n",
    "        # State-specific county search (higher accuracy)\n",
    "        for state_name in found_states:\n",
    "            if state_name in county_by_state:\n",
    "                state_counties = county_by_state[state_name]\n",
    "                state_county_match, state_county_score = fuzzy_match_entity(entity, state_counties, threshold=70)\n",
    "                if state_county_match and state_county_score > county_score:\n",
    "                    # Replace with better state-specific match\n",
    "                    # Remove the global match if it exists\n",
    "                    all_matches = [m for m in all_matches if not (m[0] == 'COUNTY' and m[1] == county_match)]\n",
    "                    all_matches.append(('COUNTY', state_county_match, state_counties[state_county_match], state_county_score))\n",
    "\n",
    "    # STEP 3: Find city matches (global first, then state-specific)\n",
    "    for entity in entities:\n",
    "        # Global city search\n",
    "        city_match, city_score = fuzzy_match_entity(entity, city_lookup, threshold=75)\n",
    "        if city_match:\n",
    "            all_matches.append(('CITY', city_match, city_lookup[city_match], city_score))\n",
    "\n",
    "        # State-specific city search (higher accuracy)\n",
    "        for state_name in found_states:\n",
    "            if state_name in city_by_state:\n",
    "                state_cities = city_by_state[state_name]\n",
    "                state_city_match, state_city_score = fuzzy_match_entity(entity, state_cities, threshold=70)\n",
    "                if state_city_match and state_city_score > city_score:\n",
    "                    # Replace with better state-specific match\n",
    "                    # Remove the global match if it exists\n",
    "                    all_matches = [m for m in all_matches if not (m[0] == 'CITY' and m[1] == city_match)]\n",
    "                    all_matches.append(('CITY', state_city_match, state_cities[state_city_match], state_city_score))\n",
    "\n",
    "    # Remove duplicates (same scale + name)\n",
    "    unique_matches = []\n",
    "    seen_combinations = set()\n",
    "    for match in all_matches:\n",
    "        combo = (match[0], match[1])  # (scale, name)\n",
    "        if combo not in seen_combinations:\n",
    "            unique_matches.append(match)\n",
    "            seen_combinations.add(combo)\n",
    "\n",
    "    return unique_matches\n",
    "\n",
    "def multi_level_assign_scale_levels(row, lookups):\n",
    "    \"\"\"\n",
    "    Return ALL geographic scale levels that match this tweet\n",
    "    Returns a list of matches: [(scale, name, geom, score), ...]\n",
    "    \"\"\"\n",
    "    gpe = str(row.get('GPE', '')).strip()\n",
    "    fac = str(row.get('FAC', '')).strip()\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Parse GPE into multiple entities\n",
    "    entities = parse_gpe_entities(gpe)\n",
    "\n",
    "    if entities:\n",
    "        # Find all geographic matches\n",
    "        geo_matches = find_all_geographic_matches(entities, lookups)\n",
    "        matches.extend(geo_matches)\n",
    "\n",
    "    # Add facility as separate match if available\n",
    "    if fac and fac not in ['nan', 'NAN', '']:\n",
    "        matches.append(('FACILITY', fac, row.geometry, 100))\n",
    "\n",
    "    # If no matches found, return unmatched\n",
    "    if not matches:\n",
    "        matches.append(('UNMATCHED', None, row.geometry, 0))\n",
    "\n",
    "    return matches\n",
    "import time\n",
    "# def expand_tweets_by_matches(gdf, lookups, dataset_name):\n",
    "#\n",
    "#     print(f\"Function called at {time.time()}\")  # Add this line\n",
    "#     \"\"\"\n",
    "#     Expand the GeoDataFrame so each tweet creates multiple rows (one per geographic match)\n",
    "#     \"\"\"\n",
    "#     print(f\"\\nExpanding {dataset_name} tweets by geographic matches...\")\n",
    "#     gdf = gdf.reset_index(drop=True)\n",
    "#     expanded_rows = []\n",
    "#\n",
    "#     for idx, row in gdf.iterrows():\n",
    "#         # print(idx)\n",
    "#         if idx % 100 == 0:\n",
    "#             print(idx)\n",
    "#         matches = multi_level_assign_scale_levels(row, lookups)\n",
    "#\n",
    "#         # Create one row per match\n",
    "#         for scale, name, geom, score in matches:\n",
    "#             new_row = row.copy()\n",
    "#             new_row['scale_level'] = scale\n",
    "#             new_row['matched_name'] = name\n",
    "#             new_row['matched_geom'] = geom\n",
    "#             new_row['match_score'] = score\n",
    "#             new_row['original_index'] = idx  # Track original tweet\n",
    "#             expanded_rows.append(new_row)\n",
    "#\n",
    "#     # Create new GeoDataFrame and preserve the original CRS\n",
    "#     expanded_gdf = gpd.GeoDataFrame(expanded_rows, crs=gdf.crs)\n",
    "#\n",
    "#     # Print statistics\n",
    "#     original_count = len(gdf)\n",
    "#     expanded_count = len(expanded_gdf)\n",
    "#     expansion_ratio = expanded_count / original_count\n",
    "#\n",
    "#     print(f\"  Original tweets: {original_count}\")\n",
    "#     print(f\"  Expanded rows: {expanded_count}\")\n",
    "#     print(f\"  Expansion ratio: {expansion_ratio:.2f}x\")\n",
    "#\n",
    "#     # Print scale distribution\n",
    "#     scale_counts = expanded_gdf['scale_level'].value_counts()\n",
    "#     print(f\"  {dataset_name} scale distribution:\")\n",
    "#     for scale, count in scale_counts.items():\n",
    "#         print(f\"    {scale}: {count}\")\n",
    "#\n",
    "#     # Print average match scores by scale level\n",
    "#     print(f\"  Average match scores:\")\n",
    "#     for scale in ['STATE', 'COUNTY', 'CITY', 'FACILITY']:\n",
    "#         if scale in expanded_gdf['scale_level'].values:\n",
    "#             avg_score = expanded_gdf[expanded_gdf['scale_level'] == scale]['match_score'].mean()\n",
    "#             print(f\"    {scale}: {avg_score:.1f}%\")\n",
    "#\n",
    "#     # Show some examples of multi-level matches\n",
    "#     print(f\"  Sample multi-level matches:\")\n",
    "#     # Group by original tweet and show ones with multiple matches\n",
    "#     multi_matches = expanded_gdf.groupby('original_index').size()\n",
    "#     multi_match_indices = multi_matches[multi_matches > 1].head(5).index\n",
    "#\n",
    "#     for orig_idx in multi_match_indices:\n",
    "#         tweet_matches = expanded_gdf[expanded_gdf['original_index'] == orig_idx]\n",
    "#         original_gpe = tweet_matches.iloc[0]['GPE']\n",
    "#         match_summary = ', '.join([f\"{row['scale_level']}:{row['matched_name']}\" for _, row in tweet_matches.iterrows()])\n",
    "#         print(f\"    '{original_gpe}' → {match_summary}\")\n",
    "#\n",
    "#     return expanded_gdf\n",
    "def expand_tweets_by_matches_fastest(gdf, lookups, dataset_name):\n",
    "    \"\"\"\n",
    "    Fastest version using list comprehensions and minimal copies\n",
    "    \"\"\"\n",
    "    print(f\"\\nExpanding {dataset_name} tweets by geographic matches...\")\n",
    "\n",
    "    # Convert to records for faster iteration\n",
    "    records = gdf.to_dict('records')\n",
    "    indices = gdf.index.tolist()\n",
    "\n",
    "    expanded_data = []\n",
    "\n",
    "    for idx, (original_idx, record) in enumerate(zip(indices, records)):\n",
    "        if idx % 100 == 0:\n",
    "            print(idx)\n",
    "\n",
    "        # Create a mock row object for compatibility\n",
    "        class MockRow:\n",
    "            def __init__(self, data, idx):\n",
    "                self.__dict__.update(data)\n",
    "                self.Index = idx\n",
    "\n",
    "        mock_row = MockRow(record, original_idx)\n",
    "        matches = multi_level_assign_scale_levels(mock_row, lookups)\n",
    "\n",
    "        # List comprehension for matches (faster than loop)\n",
    "        expanded_data.extend([\n",
    "            {**record,\n",
    "             'scale_level': scale, 'matched_name': name,\n",
    "             'matched_geom': geom, 'match_score': score,\n",
    "             'original_index': original_idx}\n",
    "            for scale, name, geom, score in matches\n",
    "        ])\n",
    "\n",
    "    # Rest of the function same as above...\n",
    "    expanded_gdf = gpd.GeoDataFrame(expanded_data, crs=gdf.crs)\n",
    "    # Vectorized statistics (much faster)\n",
    "    original_count = len(gdf)\n",
    "    expanded_count = len(expanded_gdf)\n",
    "    expansion_ratio = expanded_count / original_count\n",
    "\n",
    "    print(f\"  Original tweets: {original_count}\")\n",
    "    print(f\"  Expanded rows: {expanded_count}\")\n",
    "    print(f\"  Expansion ratio: {expansion_ratio:.2f}x\")\n",
    "\n",
    "    # Vectorized scale distribution\n",
    "    scale_counts = expanded_gdf['scale_level'].value_counts()\n",
    "    print(f\"  {dataset_name} scale distribution:\")\n",
    "    for scale, count in scale_counts.items():\n",
    "        print(f\"    {scale}: {count}\")\n",
    "\n",
    "    # Vectorized average scores\n",
    "    print(f\"  Average match scores:\")\n",
    "    avg_scores = expanded_gdf.groupby('scale_level')['match_score'].mean()\n",
    "    for scale in ['STATE', 'COUNTY', 'CITY', 'FACILITY']:\n",
    "        if scale in avg_scores.index:\n",
    "            print(f\"    {scale}: {avg_scores[scale]:.1f}%\")\n",
    "\n",
    "    # Optimized multi-match examples\n",
    "    print(f\"  Sample multi-level matches:\")\n",
    "    multi_matches = expanded_gdf.groupby('original_index').size()\n",
    "    multi_match_samples = multi_matches[multi_matches > 1].head(5)\n",
    "\n",
    "    # More efficient example building\n",
    "    for orig_idx in multi_match_samples.index:\n",
    "        matches_df = expanded_gdf[expanded_gdf['original_index'] == orig_idx]\n",
    "        original_gpe = matches_df['GPE'].iloc[0]\n",
    "        match_parts = [f\"{row['scale_level']}:{row['matched_name']}\"\n",
    "                      for _, row in matches_df[['scale_level', 'matched_name']].iterrows()]\n",
    "        print(f\"    '{original_gpe}' → {', '.join(match_parts)}\")\n",
    "\n",
    "    return expanded_gdf\n",
    "# =============================================================================\n",
    "# EXECUTE MULTI-LEVEL FUZZY MATCHING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTI-LEVEL GEOGRAPHIC MATCHING (ALL LEVELS)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create hierarchical lookups\n",
    "lookups = create_hierarchical_lookups(states_gdf, counties_gdf, cities_gdf)\n",
    "\n",
    "# Apply to both datasets (this will expand the datasets)\n",
    "# francine_gdf = expand_tweets_by_matches(francine_gdf, lookups, \"FRANCINE\")\n",
    "\n",
    "helene_gdf = expand_tweets_by_matches(helene_gdf, lookups, \"HELENE\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTI-LEVEL FUZZY MATCHING COMPLETE ✓\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNote: Datasets are now expanded - each original tweet may have multiple rows\")\n",
    "print(\"representing different geographic scales (STATE, COUNTY, CITY, etc.)\")"
   ],
   "id": "102cf233829866a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MULTI-LEVEL GEOGRAPHIC MATCHING (ALL LEVELS)\n",
      "============================================================\n",
      "\n",
      "Creating hierarchical lookup dictionaries...\n",
      "  States: 104 (including abbreviations)\n",
      "  Counties: 1915 (organized by 52 states)\n",
      "  Cities: 20806 (organized by 51 states)\n",
      "Function called at 1758571234.876987\n",
      "\n",
      "Expanding HELENE tweets by geographic matches...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "  Original tweets: 34433\n",
      "  Expanded rows: 141413\n",
      "  Expansion ratio: 4.11x\n",
      "  HELENE scale distribution:\n",
      "    CITY: 52083\n",
      "    COUNTY: 47174\n",
      "    STATE: 40509\n",
      "    FACILITY: 1590\n",
      "    UNMATCHED: 57\n",
      "  Average match scores:\n",
      "    STATE: 99.9%\n",
      "    COUNTY: 93.2%\n",
      "    CITY: 96.8%\n",
      "    FACILITY: 100.0%\n",
      "  Sample multi-level matches:\n",
      "    'Florida' → STATE:FLORIDA, COUNTY:FLORIDA, CITY:FLORIDA\n",
      "    'Florida' → STATE:FLORIDA, COUNTY:FLORIDA, CITY:FLORIDA\n",
      "    'Florida' → STATE:FLORIDA, COUNTY:FLORIDA, CITY:FLORIDA\n",
      "    'Florida' → STATE:FLORIDA, COUNTY:FLORIDA, CITY:FLORIDA\n",
      "    'Florida' → STATE:FLORIDA, COUNTY:FLORIDA, CITY:FLORIDA\n",
      "\n",
      "============================================================\n",
      "MULTI-LEVEL FUZZY MATCHING COMPLETE ✓\n",
      "============================================================\n",
      "\n",
      "Note: Datasets are now expanded - each original tweet may have multiple rows\n",
      "representing different geographic scales (STATE, COUNTY, CITY, etc.)\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T18:52:02.737559Z",
     "start_time": "2025-09-22T18:52:02.724406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_city_matching(francine_gdf, helene_gdf, cities_lookup, state_lookup, county_lookup):\n",
    "    \"\"\"\n",
    "    Validate which cities from tweets are found in the cities shapefile\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CITY MATCHING VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Combine both datasets\n",
    "    all_tweets = pd.concat([francine_gdf, helene_gdf], ignore_index=True)\n",
    "\n",
    "    # Extract all unique GPE values (potential cities)\n",
    "    all_gpe_values = set()\n",
    "    for gpe in all_tweets['GPE'].dropna():\n",
    "        gpe_clean = str(gpe).upper().strip()\n",
    "        if gpe_clean and gpe_clean != 'NAN':\n",
    "            all_gpe_values.add(gpe_clean)\n",
    "\n",
    "    # print(f\"Total unique GPE values in tweets: {len(all_gpe_values)}\")\n",
    "\n",
    "    # Check matches against each lookup\n",
    "    state_matches = set(gpe for gpe in all_gpe_values if gpe in state_lookup)\n",
    "    county_matches = set(gpe for gpe in all_gpe_values if gpe in county_lookup)\n",
    "    city_matches = set(gpe for gpe in all_gpe_values if gpe in cities_lookup)\n",
    "\n",
    "    # Calculate what's left after state/county matching\n",
    "    remaining_after_states = all_gpe_values - state_matches\n",
    "    remaining_after_counties = remaining_after_states - county_matches\n",
    "    potential_cities = remaining_after_counties\n",
    "    print(potential_cities)\n",
    "    print(f\"\\nMatching Results:\")\n",
    "    print(f\"  States matched: {len(state_matches)}\")\n",
    "    print(f\"  Counties matched: {len(county_matches)}\")\n",
    "    print(f\"  Cities matched: {len(city_matches)}\")\n",
    "    print(f\"  Potential cities (not state/county): {len(potential_cities)}\")\n",
    "    print(f\"  Cities found in shapefile: {len(city_matches)}\")\n",
    "\n",
    "    # Calculate city matching rate\n",
    "    if len(potential_cities) > 0:\n",
    "        city_match_rate = len(city_matches) / len(potential_cities) * 100\n",
    "        print(f\"  City matching rate: {city_match_rate:.1f}%\")\n",
    "\n",
    "    # Show some examples of successful city matches\n",
    "    print(f\"\\nSample successful city matches:\")\n",
    "    sample_cities = list(city_matches)[:10]\n",
    "    for city in sample_cities:\n",
    "        geom_type = cities_lookup[city].geom_type\n",
    "        print(f\"  - {city}: {geom_type}\")\n",
    "\n",
    "    # Show unmatched potential cities\n",
    "    unmatched_cities = potential_cities - city_matches\n",
    "    print(f\"\\nUnmatched potential cities (first 20):\")\n",
    "    unmatched_list = sorted(list(unmatched_cities))[:20]\n",
    "    for city in unmatched_list:\n",
    "        print(f\"  - {city}\")\n",
    "\n",
    "    if len(unmatched_cities) > 20:\n",
    "        print(f\"  ... and {len(unmatched_cities) - 20} more\")\n",
    "\n",
    "    # Show shapefile city name samples for comparison\n",
    "    print(f\"\\nSample city names from shapefile (first 20):\")\n",
    "    shapefile_cities = sorted(list(cities_lookup.keys()))[:20]\n",
    "    for city in shapefile_cities:\n",
    "        print(f\"  - {city}\")\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDATION COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return {\n",
    "        'total_gpe': len(all_gpe_values),\n",
    "        'state_matches': len(state_matches),\n",
    "        'county_matches': len(county_matches),\n",
    "        'city_matches': len(city_matches),\n",
    "        'potential_cities': len(potential_cities),\n",
    "        'unmatched_cities': unmatched_cities,\n",
    "        'city_match_rate': city_match_rate if len(potential_cities) > 0 else 0\n",
    "    }\n",
    "# Run the validation after creating lookups\n",
    "validation_results = validate_city_matching(francine_gdf, helene_gdf, lookups['city_lookup'], lookups['state_lookup'], lookups['county_lookup'])"
   ],
   "id": "3d73e674a16cc4cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CITY MATCHING VALIDATION\n",
      "============================================================\n",
      "{'FLORIDA, ORLANDO', 'FL, PERRY', 'CATAWBA COUNTY', \"COOPER CITY'S\", 'JEFFERSON PARISH, KENNER', 'ASCENSION PARISH', 'GEORGIA, SANDERSVILLE', 'CHAUVIN, LOUISIANA', 'MASSACHUSETTS, NORTH CAROLINA', 'ATLANTA, US', 'LA., METAIRIE, NEW ORLEANS', 'BATON ROUGE, LOUISIANA', 'FL, FL, PANAMA CITY', 'ROCK HILL, YORK COUNTY', 'TAMPA, TAMPA', 'PENSACOLA', 'ORLEANS PARISH', 'ACADIANA, LOUISIANA', 'HOUMA, LOUISIANA', 'COLLETON COUNTY, SC, WALTERBORO, SC', 'ATLANTA, GA', 'CHAUVIN, LA, LOUISIANA', 'FL, FL, FLORIDA, THE SUNSHINE STATE', 'ASHEVILLE, NORTH CAROLINA', 'S. CAROLINA', 'LA, LOUISIANA, LA', 'ALABAMA, FLORIDA', 'FLORIDA, LAKE CITY', 'KY, OHIO, TN', 'OCALA', 'TANGIPAHOA PARISH', 'NEW ORLEANS, ST. ROCH', 'FLORIDA, SOUTH PASADENA', 'BONITA SPRINGS, FLORIDA', 'LOUISIANA, TEXAS', 'JEFFERSON PARISH, LOUISIANA', 'MS, NEW ORLEANS', 'ATLANTA, FLORIDA', 'TAMPA FLA', 'FRANCINE, LOUISIANA', 'ST. JAMES PARISH', 'FULTON COUNTY’S', 'STEINHATCHEE', 'FLORIDA, OTTAWA', 'ROCK HILL, SC', 'LAFAYETTE COUNTY', 'FLORIDA, ALABAMA', 'ASHEVILLE, GEORGIA', 'DENHAM SPRINGS', 'SOUTH CAROLINA, SPARTANBURG', 'LOUISIANA, MS', 'COCODRIE, LOUISIANA', 'LA, LOUISIANA, NEW ORLEANS, LA', 'FLA., PANACEA, PANACEA', 'CARBONDALE, ILLINOIS', 'ALMA, GA, GEORGIA, GA', 'GLYNN COUNTY', 'LELAND, NORTH CAROLINA', 'NASHVILLE', 'LAFOURCHE PARISH', 'FLORIDA, PLANT CITY', 'LA, NEW ORLEANS, LA', 'FLORIDA, TALLAHASSEE, TAMPA', 'EVANS, GA', 'LAROSE', 'FLORIDA, ST. PETERSBURG', 'BATON ROUGE, JACKSON', 'FORT MYERS BEACH', 'BLUFFTON, FL', 'SAVANNAH', 'LA., PEARL RIVER', 'DULAC, LOUISIANA', 'MILLS RIVER, NC', 'IBERVILLE PARISH', 'ALABAMA, ATLANTA', 'LAKELAND', 'APALACHICOLA, FLORIDA, FLORIDA', 'GALVESTON, HOUSTON', 'AIKEN COUNTY', 'SHREVEPORT', 'ARIZONA, FLORIDA', 'LOUISIANA, USA', 'FLORIDA, JAPAN', 'FLORIDA, TALLAHASSEE, UNITED STATES', 'FL, FL, FLORIDA, NORTH CAROLINA', 'DUNWOODY', 'FLORIDA, MEXICO BEACH', 'FL, FLORIDA, PERRY', 'HAMMOND, LA.', 'FLORIDA, PINELLAS COUNTY', 'FLORIDA, TAMPA', 'FLORIDA, ST PETERSBURG', 'FORKED ISLAND, LOUISIANA', 'CLEARWATER, FLORIDA, FLORIDA', 'ATL, GEORGIA', 'JACKSONVILLE, TALLAHASSEE', 'THE SOUTHEASTERN UNITED STATES', 'IREDELL COUNTY', 'LOUISIANA, NOLA, NEW ORLEANS', 'COOK COUNTY, GEORGIA', 'HIGHLAND, ILLINOIS', 'FLORIDA, GEORGIA', 'HOUMA, LA', 'FLORIDA, PASCO COUNTY', 'CLEARWATER, FLORIDA, TAMPA', 'ASSUMPTION PARISH', 'FLORIDA, MIAMI-DADE COUNTY', 'JACKSONVILLE', 'FLORIDA, FLORIDA, TALLAHASSEE', 'FLORIDA, LAKE COUNTY, ORLANDO', 'PINELLAS COUNTY', 'MEXICO BEACH, TENNESSEE', 'JONESBOROUGH, TN, TN', 'METAIRIE, NEW ORLEANS', 'MEXICO, US', 'DOTHAN', 'ST. TAMMANY, TANGIPAHOA', 'PEARL RIVER COUNTY', 'CALIFORNIA, FLORIDA', 'NEW_ORLEANS, LOUISIANA', 'HOUMA, LOUISIANA, US, UNITED STATES', 'KENNER', 'LOUISIANA, MIAMI', 'APPALACHIA', 'MANATEE, SARASOTA', 'FL, FL, FLORIDA, FORT MYERS, LEE COUNTY, FL', 'FLORIDA, SAN ANTONIO', 'HERNANDO COUNTY', 'FL, SHELL POINT BEACH', 'FORT MYERS', 'LOUISIANA, NEBRASKA', 'BUCKHEAD, GEORGIA', 'HOUMA, LOUISIANA, LOUISIANA', 'LAURENS COUNTY', 'BIG BEND, FL, FL', 'HOUSTON, LOUISIANA', 'BURKE COUNTY', 'CHARLOTTE, NC, TAMPA', 'MORGAN CITY, ST. MARY PARISH', 'FLORIDA, USA', 'FLORIDA, MADEIRA BEACH, ST PETERSBURG', 'FL, STEINHATCHEE', 'FL PASCO COUNTY', 'FL, TAYLOR COUNTY', 'NC, NORTH CAROLINA', 'LAFAYETTE, LOUISIANA', 'FRANKLIN, ST. MARY PARISH', 'CINNAMON, LOUISIANA', 'FLORIDA, FORT MYERS, US', 'GUNTERSVILLE, MARSHALL COUNTY', 'CLEARWATER, FLORIDA', 'MEMPHIS, TENNESSEE', 'HOUSTON, TEXAS', 'CARROLLTON, NEW ORLEANS', 'APALACHICOLA', 'SOUTHEAST RALEIGH', 'U.S., US', 'FLORIDA, PASADENA', 'AMELIA, LOUISIANA', 'FLORIDA, PANACEA', 'GEORGIA, SOUTH CAROLINA', 'SANDY SPRINGS', 'COCODRIE, COCODRIE, LA, LOUISIANA, LA', 'DESTIN, FLORIDA', 'APALACHICOLA, FLORIDA', 'BEAUFORT COUNTY, HILTON HEAD', 'FL, FLORIDA, FORT MYERS, FL, FLORIDA', 'BOCA CHICA, FL, FL', 'GASTON, MECKLENBURG', 'FLORIDA, GA, GA', 'FLORIDA, STEINHATCHEE', 'FL KEYS, FLORIDA KEYS', 'NORTH CAROLINA, SOUTH CAROLINA', 'FLORIDA, FLORIDA, PERRY', 'LAKE CHARLES, LOUISIANA', 'GALVESTON, TEXAS', 'GEORGIA, OCALA', 'GA, STATESBORO', 'CAROLINA, CAROLINAS', 'FLORIDA, MIAMI', 'COLUMBUS, OHIO', 'LOUISIANA, WE', 'ALABAMA, LOUISIANA', 'COLUMBIA, SC', 'FL, JACKSONVILLE', 'LA, MANDEVILLE', 'TALLAHASSEE, WOODVILLE', 'TUPELO', 'BREVARD COUNTY', 'APOLLO BEACH, FLORIDA', 'FLORIDA, SOUTH CAROLINA', 'LOUISIANA, MISSISSIPPI', 'LA, LOUISIANA', 'ALPHARETTA', 'FL, FL, TAMPA', 'FLORIDA, US, THE SUNSHINE STATE', 'BIG BEND, TALLAHASSEE', 'LA, METAIRIE', 'LA, LOUISIANA, THERIOT', 'PANAMA CITY BEACH', 'MIAMI, SURFSIDE', 'ATL', 'COCODRIE, LA, LOUISIANA, LA', 'FL, PINELLAS', 'GA, SC', 'ILLINOIS, INDIANA', 'ASHEVILLE', 'WILKES COUNTY', 'TAMPA BAY', 'FLORIDA, GEORGIA, TAMPA', 'FLORIDA, MARCO ISLAND', 'ATLANTA, FL, GA', 'YBOR CITY', 'FLA., LEVY COUNTY', 'FLORIDA, ST MARKS', 'FLORIDA, OHIO', 'BEAUFORT CO, SC, SC', 'HOUMA', 'ASCENSION PARISH, DONALDSONVILLE', 'GREENVILLE, SOUTH CAROLINA’S', 'FLORIDA, LEE', 'SWFL', 'DULAC, LA, LA', 'LOUISIANA, US', 'FLORIDA, FORT MYERS', 'GEORGIA, MACON', 'CAMERON PARISH, HOLLY BEACH', 'LAKE CHARLES', 'FLORIDA, TAYLOR COUNTY', 'CARRABELLE, FLORIDA', 'THIBODAUX', 'HOUMA, LA.', 'ALLIGATOR POINT, FL', 'FL, FL, FLORIDA, PERRY', 'FLORIDA, ST. PETE BEACH', 'VALDOSTA GEORGIA', 'COBB COUNTY', 'RIDGELAND, SC, SC', 'NEW ORLEANS, TERREBONNE PARISH', 'MYRTLE BEACH, NORTH CAROLINA', 'HOUMA, LA, LA', '-LAFAYETTE, LA, LA', 'AMERICA, TALLAHASSEE', 'GRAY, LA', 'LAWRENCEVILLE', 'FLORIDA, ST. PETERSBURG, TAMPA', 'GREENVILLE, SOUTH CAROLINA', 'FLORIDA, GEORGIA, US, US', 'BIG BEND, FLORIDA', 'DEKLE BEACH, FL', 'MACON-BIBB COUNTY', 'ERWIN, TENNESSEE', 'ARLINGTON, TEXAS', 'GA, MACON', 'DULAC, LA, LOUISIANA, LA', 'BATON ROUGE, NEW ORLEANS', 'SARASOTA, FLORIDA', 'LOUISIANA, NOLA', 'LOUISIANA, MOBILE', 'FL, FL, FLORIDA, TALLAHASSEE', 'NEWPORT, NORTH CAROLINA', 'PERRY, FLORIDA', 'FLORIDA, TYNDALL', 'LOUISIANA, ORLANDO', 'BATON ROUGE, LA.', 'LOUISIANA, U.S., LOUISIANA', 'NC, RUTHERFORD COUNTY', 'ALABAMA, FLORIDA, LOUISIANA', 'FLORIDA, NEW ORLEANS', 'ASCENSION, LIVINGSTON PARISH', 'NASHVILLE, TN', 'FLORIDA, MADEIRA BEACH', 'ALABAMA, ANDALUSIA', 'FLORIDA, JACKSONVILLE, TALLAHASSEE', 'LIVINGSTON PARISH', 'LA, TERREBONNE PARISH', 'LOUISIANA, TANGIPAHOA PARISH', 'RUSSELL COUNTY, VIRGINIA', 'SENATOBIA', 'MIAMI FL', '/TENNESSEE', 'LOUISIANA, OKLAHOMA', 'FLORIDA, VERO BEACH', 'MANATEE COUNTY', 'AUGUSTA, GA', 'ALGIERS, LOUISIANA, NEW ORLEANS', 'TALLAHASSEE', 'ORLANDO', 'LOUISIANA, U.S., UNITED STATES', 'FL, PANACEA', 'LOUISIANA, WATSON', 'MCCOMB', 'BEAUMONT, LOUISIANA', 'DULAC, TERREBONNE PARISH, TERREBONNE PARISH', 'INDIANA, INDY', 'NORTH KENNER', 'FLORIDA, TAMPA BAY', 'RIDGELAND', 'FLORIDA, SARASOTA COUNTY', 'DULAC, DULAC, LA, LOUISIANA, LA', 'ST. PETE BEACH', 'ATLANTA, FL, MIAMI, FL', 'FLORIDA, KEATON BEACH', 'FLORIDA, JENA', 'FAYETTEVILLE, FLORIDA', 'PASCO COUNTY', 'NEWBERRY COUNTY', 'CITY, FLORIDA', 'CHICAGO', 'ALABAMA, CT, LOUISIANA', 'FLORIDA, JACKSONVILLE', 'EAST BATON ROUGE PARISH', 'LOUISIANA, LOUISIANA, US', 'COCODRIE', 'LA, THERIOT', 'STARKVILLE', 'FLORIDA, MANATEE COUNTY, SARASOTA', 'FL, TALLAHASSEE', 'BUNCOMBE COUNTY', 'PERRY, TALLAHASSEE', 'PORT RICHEY', 'GEORGIA, US', 'FL, GA', 'ATLANTA, CHAMBLEE, GEORGIA', 'PORT CHARLOTTE', 'FLORIDA, FLORIDA, US', 'LA, NOLA', 'GIBSONTON', 'PARAGOULD', 'FLORIDA, GA, GEORGIA', 'FL, GA, GA', 'GEORGIA, FLORIDA', 'FL, LECANTO', 'FL, FL, STEINHATCHEE', 'COLUMBIA, SOUTH CAROLINA', 'SC, SC', 'FLORIDA, LEVY COUNTY', 'LOUISIANA, WEST', 'FLORIDA, FRANKLIN COUNTY', 'FL, TITUSVILLE', 'GEORGIA, NORTH CAROLINA', 'FL, TAMPA', 'NEW IBERIA', 'FLORIDA, NASHVILLE', 'GEORGIA, TENNESSEE', 'ATLANTA', 'ST. BERNARD PARISH', 'KENTUCKY, TENNESSEE', 'DULAC', 'GONZALES, LOUISIANA', 'ASHEVILLE, WNC', 'TENNESSEE, US', 'NORTH SARASOTA', 'LOUISIANA, NEW ORLEANS, NEW ORLEANS', 'LOUISVILLE', 'CALHOUN COUNTY', 'BUNCOMBE, NC, NC', 'HOUSTON, LA', 'SOUTH LOUISIANA', 'BUCKHEAD', 'FLORIDA, TALLAHASSEE', 'FLORIDA USA', 'MYRTLE BEACH, SC', 'LA, THIBODAUX', 'INDIANA, LOUISIANA', 'FLORIDA, MULBERRY', 'UNIVERSAL ORLANDO', 'TALLAHASSEE, TAMPA', 'BATON ROUGE', 'DESANTIS, FLORIDA', 'TALLAHASSEE, THE BIG BEND', 'NEWPORT TN', 'ATLANTA, HELENE', 'LOUISIANA, RACELAND', 'FLORIDA, KANSAS', 'LOUISIANA, THERIOT', 'ASHEVILLE, BILTMORE VILLAGE', 'FLORIDA, SHELL POINT', 'FLA, FLORIDA', 'COLLIERVILLE', 'AUSTRALIA, FLORIDA, US, US', 'GEORGIA, STONECREST', 'KC, NOLA', 'FLORIDA, NORTH PORT', 'GEORGIA, WHEELER COUNTY', 'ST. MARKS', 'FLORIDA, SIESTA KEY', 'OHIO, ORLANDO', 'FLORIDA, MILWAUKEE', 'MORGAN CITY', 'NAPOLEONVILLE', 'CRAWFORDVILLE, FLORIDA, FLORIDA', 'FLORIDA, PINELLAS COUNTY, ST. PETERSBURG, TAMPA', 'LOUISIANA, NEW ORLEANS, US', 'FLORIDA, HENDRY COUNTY', 'LIVINGSTON, LOUISIANA', 'LAPLACE', 'PALM BEACH COUNTY', 'DORAL, FLORIDA', 'CHARLESTON COUNTY', 'FLORIDA, JACKSONVILLE, SAVANNAH', 'BEAUMONT, TEXAS', 'CHARLESTON, GREENVILLE', 'FL, HIGH SPRINGS', 'MAGGIE VALLEY, NC', 'BLACKSBURG, CHRISTIANSBURG', 'GEORGETOWN, HORRY COUNTY', 'BAY COUNTY', 'FL, FL, LANARK VILLAGE', 'SOPERTON', 'BALDWIN, LOUISIANA', 'US, USA, US', 'BLACKSHEAR, GA', '., FL', 'FL, MIAMI', 'PINELLAS COUNTY, ST. PETERSBURG', 'SLIDELL', 'MIAMI-DADE COUNTY', 'SOUTH TERREBONNE', 'GULFPORT', 'GEORGIA, METTER', 'FL, MATLACHA', 'MS, SHERWOOD, TN', 'ALLIGATOR POINT, FL, FL, FLORIDA, FL', 'LOUISIANA, THIBODAUX', 'LOUISIANA, TERREBONNE PARISH', 'DEFUNIAK SPRINGS, WALTON COUNTY', 'CINCINNATI', 'CANCÚN, FLORIDA', 'NORTH CAROLINA, RUTHERFORD COUNTY', 'FL, FL, FLORIDA, GA, SC, SUWANNEE', 'GOODLETTSVILLE', 'MISSISSIPPI, MISSISSIPPI', 'LA, LA, LA', 'BERWICK, LA', 'CHICAGO, FLORIDA', 'BONITA SPRINGS', 'ALEXANDRIA, SHENANDOAH, VA', 'PALM HARBOR', 'VOLUSIA COUNTY', 'FRANKLIN, LA, LA', 'TAMPA, TAMPA BAY', 'TAMPA', 'LA, MORGAN CITY', 'FLORIDA, NYC', 'GREENSBORO', 'DULAC, DULAC, LOUISIANA, LOUISIANA', 'SOWELA', 'FLORIDA, PORT RICHEY', 'FLORIDA, SINGAPORE', 'FL, FL, FLORIDA', 'TENN.', 'DFW', 'KANSAS CITY', 'FORT MYERS BEACH, LEE COUNTY', 'CHATHAM COUNTY, SAVANNAH', 'PORT CANAVERAL, PORT CANAVERAL', 'VALDOSTA', 'ST. MARY, ST. MARY PARISH', 'BROWARD COUNTY', 'MECKLENBURG COUNTY', 'GA, LIBERTY COUNTY', 'ASHEVILLE, NC, NC', 'BLOWING ROCK', 'NOLA, NOLA', 'BRADENTON, FL', 'FLORIDA, HILLSBOROUGH COUNTY', 'BRADENTON, FLORIDA', 'FLORIDA, FORT MYERS BEACH, US', 'FLORIDA, PERRY, US', 'ACADIANA', 'FLORIDA, MADISON', 'DEKLE BEACH, FLORIDA', 'FLORIDA, LOUISIANA', 'ALABAMA, GEORGIA', 'LARGO FL', 'LOUISIANA, US, US', 'FORTMYERS', 'TPA, TAMPA', 'GEORGIA, SAVANNAH', 'HOUMA, LOUISIANA, HOUMA', 'CAROLINAS, GEORGIA', 'JASPER CO, SC, SC', 'GONZALES, LA', 'CHARLOTTE-MECKLENBURG', 'ALBANY, FLORIDA, GA', 'FLORIDA, UNITED STATES', 'FLORIDA, NORTH CAROLINA', 'FLORIDA, PERRY', 'FL, GAINESVILLE', 'CRAWFORDVILLE, TALLAHASSEE', 'SARASOTA COUNTY', 'ST. PETE, ST. PETERSBURG', 'FRANKLIN, LOUISIANA', 'GA, GEORGIA', 'FLORIDA, MANATEE COUNTY', 'FL, FL, FLORIDA, TAMPA', 'BERWICK LA', 'FL, FL, FLORIDA, GA', 'FLORIDA, FORT LAUDERDALE', 'CLEMSON, SOUTH CAROLINA', 'FRANKLIN, LOUISIANNA', 'FL, FL, ST. PETERSBURG', 'CAMERON PARISH', 'GEORGIA, LOUISIANA', 'BEAUFORT COUNTY', 'BATON ROUGE, LA', 'HAMMOND, LA', 'HARTSELLE', 'LA, NEW ORLEANS', 'JEFFERSON PARISH', 'FL, ST. MARKS', 'KENTUCKY, LOUISIANA', 'CLEMSON', 'COCODRIE, LA', 'CUT OFF, LA., LOUISIANA', 'LOUISIANA, MORGAN CITY', 'FL, PASCO, PASCO COUNTY', 'HOUMA, LA, LOUISIANA, LA', 'TAMPA FLORIDA', 'FLORIDA, GEORGIA, USA', 'ALEXANDRIA, LOUISIANA, VA.', 'FLORIDA, US, USA, US', 'LOUISIANA, NEW ORLEANS', 'LOUISIANA, MORGAN CITY, SAINT MARY PARISH', 'HOUMA, TERREBONNE PARISH', 'HAMMOND', 'FLORIDA, GULFPORT', 'GADSDEN CO.', 'NOLA', 'HOUMA, LA, LA, LAFAYETTE', 'NEW ORLEANS', 'SALUDA COUNTY, SOUTH CAROLINA', 'FLORIDA, TAYLOR COUNTY, KEATON BEACH', 'LAPLACE, LOUISIANA', 'CHICAGO, LOUISIANA', 'AUGUSTA, GEORGIA', 'MECKLENBURG CO', 'FLORIDA, PORT CHARLOTTE', 'KEATON BEACH', 'BRADENTON', 'DUBLIN, GA', 'S.C., SPARTANBURG', 'GEORGIA, GLYNN COUNTY', 'AL, ORANGE BEACH', 'FLORIDA, WALTON COUNTY', 'GEORGIA, ATLANTA', 'SAINT PETERSBURG, ST. PETE BEACH', 'JENSEN BEACH', 'FLA', 'ATLANTA, GEORGIA', 'FLORIDA, FORT MYERS, FLORIDA', 'JAX, TALLAHASSEE', 'SCOTT COUNTY', 'LOUISIANA, MANDEVILLE', 'LA, NORCO', 'HOUMA, LA, LOUISIANA, TERREBONNE PARISH, THERIOT', 'FL, ORLANDO', 'ASHEVILLE, NC', 'SUMTER COUNTY', 'FLORIDA, FORT WALTON BEACH', 'FLORIDA, SOUTHAMPTON', 'TARPON SPRINGS', 'DORCHESTER CO, SC, SC', 'CRAWFORDVILLE, FLORIDA', 'ASHEVILLE, BILTMORE, BILTMORE, BILTMORE VILLAGE, NC', 'SC, SOUTH CAROLINA, SC', 'HOUMA, LOUISIANA, TERREBONNE', 'FLORIDA, US', 'FLORIDA, TORONTO', 'MEMPHIS', 'ST. MARY PARISH', 'LOUISIANA, MEMPHIS', 'ALLIGATOR POINT, FLORIDA', 'FLORIDA, OKLAHOMA', 'FLORIDA, VENICE', 'TERREBONNE PARISH', 'MYRTLE BEACH', 'ATLANTA, GA, FLORIDA', 'US_LOUISIANA', 'ASHEVILLE NC, FLORIDA', 'COLUMBUS, GEORGIA', 'CROSS CITY, FLORIDA', 'MULBERRY', 'PICKENS COUNTY', 'LOUISIANA, NATCHITOCHES', 'FLORIDA, FORT MYERS BEACH', 'MISSISSIPPI, NEW ORLEANS', 'ST. MARY', 'FLORIDA, FLORIDA, TAMPA, TAMPA', 'METAIRIE', 'FULTON COUNTY, GEORGIA', 'UNIVERSITY CITY', 'ATLANTA, NC, TENNESSEE', 'APALACHICOLA, FL', 'KENTUCKY, OHIO', 'CRYSTAL RIVER, FL, FL', 'LOUISIANA, SLIDELL', 'BROWARD COUNTY, FLORIDA', 'LA., LAPLACE', 'COCODRIE, LA, LA', 'ST. MARY, VERMILION', 'GEORGIA, U.S.', 'MEMPHIS, MISS', \"FLORIDA, ST. JOHNS COUNTY'S\", 'DULAC, LOUISIANA, TERREBONNE PARISH', 'FLORIDA, ST PETE BEACH', 'CHARLESTON, FLORIDA', 'FLORIDA, MIAMI FL', 'JACKSON, MS, NEW ORLEANS', 'FLA., PERRY', 'TEXAS, TX', 'CHACAHOULA, LOUISIANA', 'FLORIDA, PERRY, FLORIDA, PERRY', 'ARKANSAS, LOUISIANA', 'FLORIDA, THE BIG BEND', 'NEW ORLEANS, US', 'LOUISIANA, MISSISSIPPI, NEW ORLEANS', 'PANACEA', 'WAKULLA COUNTY', 'FL, GA, SC', 'KENNER, LOUISIANA', 'ASHEVILLE, BUNCOMBE COUNTY', '--LOUISIANA, TEXAS', 'BATON ROUGE, LOUISIANA, NEW ORLEANS', 'FLORIDA, GEORGIA, US', 'GA, GEORGIA, JORDAN, WHEELER COUNTY', 'LOUISIANA, LOUISIANA', 'GA, TX', 'ATLANTA, GEORGIA, ATLANTA', 'GEORGIA, VALDOSTA', 'FLORIDA, SARASOTA', 'ST. CHARLES PARISH', 'D.C., FLORIDA', 'LA, LA, TERREBONNE PARISH', 'LOUISIANA, UNITED STATES', 'HAMMOND, LA, US', 'LAFOURCHE PARISH, THIBODAUX', 'FLORIDA, LEE COUNTY', 'FLORIDA, KENTUCKY', 'LA., MORGAN CITY', 'FLORIDA, GA', 'IL, IL', 'ESCAMBIA, FLORIDA, SANTA ROSA', 'GULFPORT, PINELLAS COUNTY', 'BUNCOMBE, HENDERSON', 'LOUISIANA, PLATTENVILLE', 'BOCA RATON, FL', 'PEACHTREE CITY', 'GRAND ISLE, LOUISIANA', 'DANIA BEACH', 'FLORIDA, TARPON SPRINGS', 'FLORIDA, LAKELAND', 'SCHRIEVER', 'FLORIDA, THE SUNSHINE STATE'}\n",
      "\n",
      "Matching Results:\n",
      "  States matched: 19\n",
      "  Counties matched: 32\n",
      "  Cities matched: 105\n",
      "  Potential cities (not state/county): 655\n",
      "  Cities found in shapefile: 105\n",
      "  City matching rate: 16.0%\n",
      "\n",
      "Sample successful city matches:\n",
      "  - ATLANTA: Polygon\n",
      "  - DULAC: Polygon\n",
      "  - HARTSELLE: Polygon\n",
      "  - RALEIGH: Polygon\n",
      "  - NORTH SARASOTA: Polygon\n",
      "  - LOUISVILLE: Polygon\n",
      "  - CLEMSON: Polygon\n",
      "  - PENSACOLA: Polygon\n",
      "  - HOUSTON: MultiPolygon\n",
      "  - LAFAYETTE: Polygon\n",
      "\n",
      "Unmatched potential cities (first 20):\n",
      "  - --LOUISIANA, TEXAS\n",
      "  - -LAFAYETTE, LA, LA\n",
      "  - ., FL\n",
      "  - /TENNESSEE\n",
      "  - ACADIANA\n",
      "  - ACADIANA, LOUISIANA\n",
      "  - AIKEN COUNTY\n",
      "  - AL, ORANGE BEACH\n",
      "  - ALABAMA, ANDALUSIA\n",
      "  - ALABAMA, ATLANTA\n",
      "  - ALABAMA, CT, LOUISIANA\n",
      "  - ALABAMA, FLORIDA\n",
      "  - ALABAMA, FLORIDA, LOUISIANA\n",
      "  - ALABAMA, GEORGIA\n",
      "  - ALABAMA, LOUISIANA\n",
      "  - ALBANY, FLORIDA, GA\n",
      "  - ALEXANDRIA, LOUISIANA, VA.\n",
      "  - ALEXANDRIA, SHENANDOAH, VA\n",
      "  - ALGIERS, LOUISIANA, NEW ORLEANS\n",
      "  - ALLIGATOR POINT, FL\n",
      "  ... and 559 more\n",
      "\n",
      "Sample city names from shapefile (first 20):\n",
      "  - AARONSBURG\n",
      "  - ABANDA\n",
      "  - ABBEVILLE\n",
      "  - ABBOTSFORD\n",
      "  - ABBOTT\n",
      "  - ABBOTTSTOWN\n",
      "  - ABBS VALLEY\n",
      "  - ABBYVILLE\n",
      "  - ABERCROMBIE\n",
      "  - ABERDEEN\n",
      "  - ABERDEEN GARDENS\n",
      "  - ABERDEEN PROVING GROUND\n",
      "  - ABERNATHY\n",
      "  - ABEYTAS\n",
      "  - ABIE\n",
      "  - ABILENE\n",
      "  - ABINGDON\n",
      "  - ABINGTON\n",
      "  - ABIQUIU\n",
      "  - ABITA SPRINGS\n",
      "\n",
      "============================================================\n",
      "VALIDATION COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T18:52:02.761322Z",
     "start_time": "2025-09-22T18:52:02.742477Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Group tweets by 4-hour intervals and scale level\n",
    "# Using unix_timestamp for unambiguous temporal grouping\n",
    "\n",
    "# Alternative approach:\n",
    "francine_interval_counts = francine_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).agg({\n",
    "    'matched_geom': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Add count column separately\n",
    "count_series = francine_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).size()\n",
    "francine_interval_counts['count'] = count_series.values\n",
    "\n",
    "# Same for Helene\n",
    "helene_interval_counts = helene_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).agg({\n",
    "    'matched_geom': 'first'\n",
    "}).reset_index()\n",
    "count_series = helene_gdf.groupby(['unix_timestamp', 'scale_level', 'matched_name']).size()\n",
    "helene_interval_counts['count'] = count_series.values\n",
    "\n",
    "# Sort by timestamp to ensure chronological order\n",
    "francine_interval_counts = francine_interval_counts.sort_values('unix_timestamp')\n",
    "helene_interval_counts = helene_interval_counts.sort_values('unix_timestamp')\n",
    "\n",
    "# Calculate cumulative counts\n",
    "francine_interval_counts['cumulative_count'] = francine_interval_counts.groupby(['scale_level', 'matched_name'])['count'].cumsum()\n",
    "helene_interval_counts['cumulative_count'] = helene_interval_counts.groupby(['scale_level', 'matched_name'])['count'].cumsum()\n",
    "\n",
    "# Get unique time bins for iteration\n",
    "francine_time_bins = sorted(francine_gdf['unix_timestamp'].unique())\n",
    "helene_time_bins = sorted(helene_gdf['unix_timestamp'].unique())\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"FRANCINE Time Binning Summary:\")\n",
    "print(f\"  Total time bins: {len(francine_time_bins)}\")\n",
    "print(f\"  Total location-time combinations: {len(francine_interval_counts)}\")\n",
    "print(f\"\\nSample interval counts:\")\n",
    "print(francine_interval_counts.head(10))\n",
    "\n",
    "print(f\"\\nHELENE Time Binning Summary:\")\n",
    "print(f\"  Total time bins: {len(helene_time_bins)}\")\n",
    "print(f\"  Total location-time combinations: {len(helene_interval_counts)}\")\n",
    "print(f\"\\nSample interval counts:\")\n",
    "print(helene_interval_counts.head(10))"
   ],
   "id": "95d5ae7c58fc2af4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRANCINE Time Binning Summary:\n",
      "  Total time bins: 42\n",
      "  Total location-time combinations: 1085\n",
      "\n",
      "Sample interval counts:\n",
      "   unix_timestamp scale_level matched_name  \\\n",
      "0      1725868800        CITY    LOUISIANA   \n",
      "1      1725868800        CITY          TEA   \n",
      "2      1725868800      COUNTY       LOUISA   \n",
      "3      1725868800      COUNTY        TEXAS   \n",
      "4      1725868800       STATE    LOUISIANA   \n",
      "5      1725868800       STATE        TEXAS   \n",
      "6      1725883200        CITY     ARKANSAW   \n",
      "7      1725883200        CITY       DALLAS   \n",
      "8      1725883200        CITY    LAFAYETTE   \n",
      "9      1725883200        CITY    LOUISIANA   \n",
      "\n",
      "                                        matched_geom  count  cumulative_count  \n",
      "0  POLYGON ((-10136318.240295896 4787721.51072714...      2                 2  \n",
      "1  MULTIPOLYGON (((-10777546.559795897 5381296.69...      2                 2  \n",
      "2  POLYGON ((-91.483995 41.423848, -91.368521 41....      2                 2  \n",
      "3  POLYGON ((-102.028204191045 36.9931451471083, ...      2                 2  \n",
      "4  POLYGON ((-94.0430515276176 32.6930299766656, ...      2                 2  \n",
      "5  POLYGON ((-106.623445 31.914034, -106.630114 3...      2                 2  \n",
      "6  POLYGON ((-10242932.812895898 5563732.70342714...      1                 1  \n",
      "7  POLYGON ((-10219014.707095897 5661331.32592714...      1                 1  \n",
      "8  POLYGON ((-8929241.483295897 4472460.005527141...      1                 1  \n",
      "9  POLYGON ((-10136318.240295896 4787721.51072714...     13                15  \n",
      "\n",
      "HELENE Time Binning Summary:\n",
      "  Total time bins: 11\n",
      "  Total location-time combinations: 961\n",
      "\n",
      "Sample interval counts:\n",
      "   unix_timestamp scale_level    matched_name  \\\n",
      "0      1727308800        CITY       ASHEVILLE   \n",
      "1      1727308800        CITY         ATLANTA   \n",
      "2      1727308800        CITY    BLOWING ROCK   \n",
      "3      1727308800        CITY        BUNCOMBE   \n",
      "4      1727308800        CITY  CAPE CANAVERAL   \n",
      "5      1727308800        CITY       CHARLOTTE   \n",
      "6      1727308800        CITY         FLORIDA   \n",
      "7      1727308800        CITY       GEORGIANA   \n",
      "8      1727308800        CITY       HENDERSON   \n",
      "9      1727308800        CITY          KALAMA   \n",
      "\n",
      "                                        matched_geom  count  cumulative_count  \n",
      "0  MULTIPOLYGON (((-9185732.944595898 4227465.844...      1                 1  \n",
      "1  POLYGON ((-10478036.460495897 3914629.82582714...      2                 2  \n",
      "2  MULTIPOLYGON (((-9090015.993695896 4316203.068...      1                 1  \n",
      "3  POLYGON ((-9904114.910795897 4504249.000727141...      2                 2  \n",
      "4  POLYGON ((-8972697.050195897 3300272.504727141...      2                 2  \n",
      "5  POLYGON ((-10987850.673895897 3359027.06782714...      1                 1  \n",
      "6  POLYGON ((-9372979.897895897 5059865.634627141...     51                51  \n",
      "7  POLYGON ((-9656324.069495898 3718185.493427141...      4                 4  \n",
      "8  POLYGON ((-9143377.882095898 4698236.999527141...      1                 1  \n",
      "9  MULTIPOLYGON (((-13671172.601795897 5777154.87...      1                 1  \n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T18:52:03.104800Z",
     "start_time": "2025-09-22T18:52:02.765160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 1: DEFINE MASTER GRID CANVAS\n",
    "# ==============================================================================\n",
    "\n",
    "# Configuration\n",
    "TARGET_CRS = 'EPSG:3857'  # Web Mercator\n",
    "CELL_SIZE_M = 1000  # 5 km in meters\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: CREATING MASTER GRID CANVAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Project both datasets to target CRS\n",
    "print(f\"\\nProjecting datasets to {TARGET_CRS}...\")\n",
    "francine_proj = francine_gdf.to_crs(TARGET_CRS)\n",
    "helene_proj = helene_gdf.to_crs(TARGET_CRS)\n",
    "\n",
    "# Also project reference geometries\n",
    "print(\"Projecting reference geometries...\")\n",
    "states_proj = states_gdf.to_crs(TARGET_CRS)\n",
    "counties_proj = counties_gdf.to_crs(TARGET_CRS)\n",
    "cities_proj = cities_gdf.to_crs(TARGET_CRS)\n",
    "# Calculate combined extent from both hurricanes\"\n",
    "print(\"\\nCalculating master extent...\")\n",
    "francine_bounds = francine_proj.total_bounds\n",
    "helene_bounds = helene_proj.total_bounds\n",
    "\n",
    "# Get union of both bounding boxes\n",
    "minx = min(francine_bounds[0], helene_bounds[0])\n",
    "miny = min(francine_bounds[1], helene_bounds[1])\n",
    "maxx = max(francine_bounds[2], helene_bounds[2])\n",
    "maxy = max(francine_bounds[3], helene_bounds[3])\n",
    "\n",
    "print(f\"  Master bounds (EPSG:3857):\")\n",
    "print(f\"    minx: {minx:,.2f}\")\n",
    "print(f\"    miny: {miny:,.2f}\")\n",
    "print(f\"    maxx: {maxx:,.2f}\")\n",
    "print(f\"    maxy: {maxy:,.2f}\")\n",
    "\n",
    "# Calculate grid dimensions\n",
    "width = int(np.ceil((maxx - minx) / CELL_SIZE_M))\n",
    "height = int(np.ceil((maxy - miny) / CELL_SIZE_M))\n",
    "\n",
    "print(f\"\\nGrid Configuration:\")\n",
    "print(f\"  Cell size: {CELL_SIZE_M:,} meters ({CELL_SIZE_M/1000} km)\")\n",
    "print(f\"  Grid dimensions: {width} x {height} cells\")\n",
    "print(f\"  Total cells: {width * height:,}\")\n",
    "\n",
    "# Create master transform\n",
    "master_transform = from_bounds(minx, miny, maxx, maxy, width, height)\n",
    "\n",
    "print(f\"\\nMaster Transform:\")\n",
    "print(f\"  {master_transform}\")\n",
    "\n",
    "# Calculate actual coverage area\n",
    "area_km2 = (width * height * CELL_SIZE_M * CELL_SIZE_M) / 1_000_000\n",
    "print(f\"\\nCoverage area: {area_km2:,.2f} km²\")\n",
    "\n",
    "# Store grid parameters for later use\n",
    "grid_params = {\n",
    "    'crs': TARGET_CRS,\n",
    "    'cell_size': CELL_SIZE_M,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'bounds': (minx, miny, maxx, maxy),\n",
    "    'transform': master_transform\n",
    "}\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"MASTER GRID CANVAS READY ✓\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Update lookup dictionaries with projected geometries\n",
    "print(\"\\nUpdating geometry lookups with projected coordinates...\")\n",
    "state_lookup_proj = dict(zip(states_proj['NAME'].str.upper(), states_proj.geometry))\n",
    "county_lookup_proj = dict(zip(counties_proj['NAME'].str.upper(), counties_proj.geometry))\n",
    "cities_lookup_proj = dict(zip(cities_proj['NAME'].str.upper(), cities_proj.geometry))\n",
    "validation_results = validate_city_matching(francine_gdf, helene_gdf, lookups['city_lookup'], lookups['state_lookup'], lookups['county_lookup'])\n",
    "print(\"Lookup dictionaries updated with projected geometries ✓\")"
   ],
   "id": "5bd77653518eadb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: CREATING MASTER GRID CANVAS\n",
      "============================================================\n",
      "\n",
      "Projecting datasets to EPSG:3857...\n",
      "Projecting reference geometries...\n",
      "\n",
      "Calculating master extent...\n",
      "  Master bounds (EPSG:3857):\n",
      "    minx: -11,854,083.11\n",
      "    miny: 2,947,395.71\n",
      "    maxx: -8,490,833.94\n",
      "    maxy: 5,142,357.36\n",
      "\n",
      "Grid Configuration:\n",
      "  Cell size: 1,000 meters (1.0 km)\n",
      "  Grid dimensions: 3364 x 2195 cells\n",
      "  Total cells: 7,383,980\n",
      "\n",
      "Master Transform:\n",
      "  | 999.78, 0.00,-11854083.11|\n",
      "| 0.00,-999.98, 5142357.36|\n",
      "| 0.00, 0.00, 1.00|\n",
      "\n",
      "Coverage area: 7,383,980.00 km²\n",
      "\n",
      "============================================================\n",
      "MASTER GRID CANVAS READY ✓\n",
      "============================================================\n",
      "\n",
      "Updating geometry lookups with projected coordinates...\n",
      "\n",
      "============================================================\n",
      "CITY MATCHING VALIDATION\n",
      "============================================================\n",
      "{'FLORIDA, ORLANDO', 'FL, PERRY', 'CATAWBA COUNTY', \"COOPER CITY'S\", 'JEFFERSON PARISH, KENNER', 'ASCENSION PARISH', 'GEORGIA, SANDERSVILLE', 'CHAUVIN, LOUISIANA', 'MASSACHUSETTS, NORTH CAROLINA', 'ATLANTA, US', 'LA., METAIRIE, NEW ORLEANS', 'BATON ROUGE, LOUISIANA', 'FL, FL, PANAMA CITY', 'ROCK HILL, YORK COUNTY', 'TAMPA, TAMPA', 'PENSACOLA', 'ORLEANS PARISH', 'ACADIANA, LOUISIANA', 'HOUMA, LOUISIANA', 'COLLETON COUNTY, SC, WALTERBORO, SC', 'ATLANTA, GA', 'CHAUVIN, LA, LOUISIANA', 'FL, FL, FLORIDA, THE SUNSHINE STATE', 'ASHEVILLE, NORTH CAROLINA', 'S. CAROLINA', 'LA, LOUISIANA, LA', 'ALABAMA, FLORIDA', 'FLORIDA, LAKE CITY', 'KY, OHIO, TN', 'OCALA', 'TANGIPAHOA PARISH', 'NEW ORLEANS, ST. ROCH', 'FLORIDA, SOUTH PASADENA', 'BONITA SPRINGS, FLORIDA', 'LOUISIANA, TEXAS', 'JEFFERSON PARISH, LOUISIANA', 'MS, NEW ORLEANS', 'ATLANTA, FLORIDA', 'TAMPA FLA', 'FRANCINE, LOUISIANA', 'ST. JAMES PARISH', 'FULTON COUNTY’S', 'STEINHATCHEE', 'FLORIDA, OTTAWA', 'ROCK HILL, SC', 'LAFAYETTE COUNTY', 'FLORIDA, ALABAMA', 'ASHEVILLE, GEORGIA', 'DENHAM SPRINGS', 'SOUTH CAROLINA, SPARTANBURG', 'LOUISIANA, MS', 'COCODRIE, LOUISIANA', 'LA, LOUISIANA, NEW ORLEANS, LA', 'FLA., PANACEA, PANACEA', 'CARBONDALE, ILLINOIS', 'ALMA, GA, GEORGIA, GA', 'GLYNN COUNTY', 'LELAND, NORTH CAROLINA', 'NASHVILLE', 'LAFOURCHE PARISH', 'FLORIDA, PLANT CITY', 'LA, NEW ORLEANS, LA', 'FLORIDA, TALLAHASSEE, TAMPA', 'EVANS, GA', 'LAROSE', 'FLORIDA, ST. PETERSBURG', 'BATON ROUGE, JACKSON', 'FORT MYERS BEACH', 'BLUFFTON, FL', 'SAVANNAH', 'LA., PEARL RIVER', 'DULAC, LOUISIANA', 'MILLS RIVER, NC', 'IBERVILLE PARISH', 'ALABAMA, ATLANTA', 'LAKELAND', 'APALACHICOLA, FLORIDA, FLORIDA', 'GALVESTON, HOUSTON', 'AIKEN COUNTY', 'SHREVEPORT', 'ARIZONA, FLORIDA', 'LOUISIANA, USA', 'FLORIDA, JAPAN', 'FLORIDA, TALLAHASSEE, UNITED STATES', 'FL, FL, FLORIDA, NORTH CAROLINA', 'DUNWOODY', 'FLORIDA, MEXICO BEACH', 'FL, FLORIDA, PERRY', 'HAMMOND, LA.', 'FLORIDA, PINELLAS COUNTY', 'FLORIDA, TAMPA', 'FLORIDA, ST PETERSBURG', 'FORKED ISLAND, LOUISIANA', 'CLEARWATER, FLORIDA, FLORIDA', 'ATL, GEORGIA', 'JACKSONVILLE, TALLAHASSEE', 'THE SOUTHEASTERN UNITED STATES', 'IREDELL COUNTY', 'LOUISIANA, NOLA, NEW ORLEANS', 'COOK COUNTY, GEORGIA', 'HIGHLAND, ILLINOIS', 'FLORIDA, GEORGIA', 'HOUMA, LA', 'FLORIDA, PASCO COUNTY', 'CLEARWATER, FLORIDA, TAMPA', 'ASSUMPTION PARISH', 'FLORIDA, MIAMI-DADE COUNTY', 'JACKSONVILLE', 'FLORIDA, FLORIDA, TALLAHASSEE', 'FLORIDA, LAKE COUNTY, ORLANDO', 'PINELLAS COUNTY', 'MEXICO BEACH, TENNESSEE', 'JONESBOROUGH, TN, TN', 'METAIRIE, NEW ORLEANS', 'MEXICO, US', 'DOTHAN', 'ST. TAMMANY, TANGIPAHOA', 'PEARL RIVER COUNTY', 'CALIFORNIA, FLORIDA', 'NEW_ORLEANS, LOUISIANA', 'HOUMA, LOUISIANA, US, UNITED STATES', 'KENNER', 'LOUISIANA, MIAMI', 'APPALACHIA', 'MANATEE, SARASOTA', 'FL, FL, FLORIDA, FORT MYERS, LEE COUNTY, FL', 'FLORIDA, SAN ANTONIO', 'HERNANDO COUNTY', 'FL, SHELL POINT BEACH', 'FORT MYERS', 'LOUISIANA, NEBRASKA', 'BUCKHEAD, GEORGIA', 'HOUMA, LOUISIANA, LOUISIANA', 'LAURENS COUNTY', 'BIG BEND, FL, FL', 'HOUSTON, LOUISIANA', 'BURKE COUNTY', 'CHARLOTTE, NC, TAMPA', 'MORGAN CITY, ST. MARY PARISH', 'FLORIDA, USA', 'FLORIDA, MADEIRA BEACH, ST PETERSBURG', 'FL, STEINHATCHEE', 'FL PASCO COUNTY', 'FL, TAYLOR COUNTY', 'NC, NORTH CAROLINA', 'LAFAYETTE, LOUISIANA', 'FRANKLIN, ST. MARY PARISH', 'CINNAMON, LOUISIANA', 'FLORIDA, FORT MYERS, US', 'GUNTERSVILLE, MARSHALL COUNTY', 'CLEARWATER, FLORIDA', 'MEMPHIS, TENNESSEE', 'HOUSTON, TEXAS', 'CARROLLTON, NEW ORLEANS', 'APALACHICOLA', 'SOUTHEAST RALEIGH', 'U.S., US', 'FLORIDA, PASADENA', 'AMELIA, LOUISIANA', 'FLORIDA, PANACEA', 'GEORGIA, SOUTH CAROLINA', 'SANDY SPRINGS', 'COCODRIE, COCODRIE, LA, LOUISIANA, LA', 'DESTIN, FLORIDA', 'APALACHICOLA, FLORIDA', 'BEAUFORT COUNTY, HILTON HEAD', 'FL, FLORIDA, FORT MYERS, FL, FLORIDA', 'BOCA CHICA, FL, FL', 'GASTON, MECKLENBURG', 'FLORIDA, GA, GA', 'FLORIDA, STEINHATCHEE', 'FL KEYS, FLORIDA KEYS', 'NORTH CAROLINA, SOUTH CAROLINA', 'FLORIDA, FLORIDA, PERRY', 'LAKE CHARLES, LOUISIANA', 'GALVESTON, TEXAS', 'GEORGIA, OCALA', 'GA, STATESBORO', 'CAROLINA, CAROLINAS', 'FLORIDA, MIAMI', 'COLUMBUS, OHIO', 'LOUISIANA, WE', 'ALABAMA, LOUISIANA', 'COLUMBIA, SC', 'FL, JACKSONVILLE', 'LA, MANDEVILLE', 'TALLAHASSEE, WOODVILLE', 'TUPELO', 'BREVARD COUNTY', 'APOLLO BEACH, FLORIDA', 'FLORIDA, SOUTH CAROLINA', 'LOUISIANA, MISSISSIPPI', 'LA, LOUISIANA', 'ALPHARETTA', 'FL, FL, TAMPA', 'FLORIDA, US, THE SUNSHINE STATE', 'BIG BEND, TALLAHASSEE', 'LA, METAIRIE', 'LA, LOUISIANA, THERIOT', 'PANAMA CITY BEACH', 'MIAMI, SURFSIDE', 'ATL', 'COCODRIE, LA, LOUISIANA, LA', 'FL, PINELLAS', 'GA, SC', 'ILLINOIS, INDIANA', 'ASHEVILLE', 'WILKES COUNTY', 'TAMPA BAY', 'FLORIDA, GEORGIA, TAMPA', 'FLORIDA, MARCO ISLAND', 'ATLANTA, FL, GA', 'YBOR CITY', 'FLA., LEVY COUNTY', 'FLORIDA, ST MARKS', 'FLORIDA, OHIO', 'BEAUFORT CO, SC, SC', 'HOUMA', 'ASCENSION PARISH, DONALDSONVILLE', 'GREENVILLE, SOUTH CAROLINA’S', 'FLORIDA, LEE', 'SWFL', 'DULAC, LA, LA', 'LOUISIANA, US', 'FLORIDA, FORT MYERS', 'GEORGIA, MACON', 'CAMERON PARISH, HOLLY BEACH', 'LAKE CHARLES', 'FLORIDA, TAYLOR COUNTY', 'CARRABELLE, FLORIDA', 'THIBODAUX', 'HOUMA, LA.', 'ALLIGATOR POINT, FL', 'FL, FL, FLORIDA, PERRY', 'FLORIDA, ST. PETE BEACH', 'VALDOSTA GEORGIA', 'COBB COUNTY', 'RIDGELAND, SC, SC', 'NEW ORLEANS, TERREBONNE PARISH', 'MYRTLE BEACH, NORTH CAROLINA', 'HOUMA, LA, LA', '-LAFAYETTE, LA, LA', 'AMERICA, TALLAHASSEE', 'GRAY, LA', 'LAWRENCEVILLE', 'FLORIDA, ST. PETERSBURG, TAMPA', 'GREENVILLE, SOUTH CAROLINA', 'FLORIDA, GEORGIA, US, US', 'BIG BEND, FLORIDA', 'DEKLE BEACH, FL', 'MACON-BIBB COUNTY', 'ERWIN, TENNESSEE', 'ARLINGTON, TEXAS', 'GA, MACON', 'DULAC, LA, LOUISIANA, LA', 'BATON ROUGE, NEW ORLEANS', 'SARASOTA, FLORIDA', 'LOUISIANA, NOLA', 'LOUISIANA, MOBILE', 'FL, FL, FLORIDA, TALLAHASSEE', 'NEWPORT, NORTH CAROLINA', 'PERRY, FLORIDA', 'FLORIDA, TYNDALL', 'LOUISIANA, ORLANDO', 'BATON ROUGE, LA.', 'LOUISIANA, U.S., LOUISIANA', 'NC, RUTHERFORD COUNTY', 'ALABAMA, FLORIDA, LOUISIANA', 'FLORIDA, NEW ORLEANS', 'ASCENSION, LIVINGSTON PARISH', 'NASHVILLE, TN', 'FLORIDA, MADEIRA BEACH', 'ALABAMA, ANDALUSIA', 'FLORIDA, JACKSONVILLE, TALLAHASSEE', 'LIVINGSTON PARISH', 'LA, TERREBONNE PARISH', 'LOUISIANA, TANGIPAHOA PARISH', 'RUSSELL COUNTY, VIRGINIA', 'SENATOBIA', 'MIAMI FL', '/TENNESSEE', 'LOUISIANA, OKLAHOMA', 'FLORIDA, VERO BEACH', 'MANATEE COUNTY', 'AUGUSTA, GA', 'ALGIERS, LOUISIANA, NEW ORLEANS', 'TALLAHASSEE', 'ORLANDO', 'LOUISIANA, U.S., UNITED STATES', 'FL, PANACEA', 'LOUISIANA, WATSON', 'MCCOMB', 'BEAUMONT, LOUISIANA', 'DULAC, TERREBONNE PARISH, TERREBONNE PARISH', 'INDIANA, INDY', 'NORTH KENNER', 'FLORIDA, TAMPA BAY', 'RIDGELAND', 'FLORIDA, SARASOTA COUNTY', 'DULAC, DULAC, LA, LOUISIANA, LA', 'ST. PETE BEACH', 'ATLANTA, FL, MIAMI, FL', 'FLORIDA, KEATON BEACH', 'FLORIDA, JENA', 'FAYETTEVILLE, FLORIDA', 'PASCO COUNTY', 'NEWBERRY COUNTY', 'CITY, FLORIDA', 'CHICAGO', 'ALABAMA, CT, LOUISIANA', 'FLORIDA, JACKSONVILLE', 'EAST BATON ROUGE PARISH', 'LOUISIANA, LOUISIANA, US', 'COCODRIE', 'LA, THERIOT', 'STARKVILLE', 'FLORIDA, MANATEE COUNTY, SARASOTA', 'FL, TALLAHASSEE', 'BUNCOMBE COUNTY', 'PERRY, TALLAHASSEE', 'PORT RICHEY', 'GEORGIA, US', 'FL, GA', 'ATLANTA, CHAMBLEE, GEORGIA', 'PORT CHARLOTTE', 'FLORIDA, FLORIDA, US', 'LA, NOLA', 'GIBSONTON', 'PARAGOULD', 'FLORIDA, GA, GEORGIA', 'FL, GA, GA', 'GEORGIA, FLORIDA', 'FL, LECANTO', 'FL, FL, STEINHATCHEE', 'COLUMBIA, SOUTH CAROLINA', 'SC, SC', 'FLORIDA, LEVY COUNTY', 'LOUISIANA, WEST', 'FLORIDA, FRANKLIN COUNTY', 'FL, TITUSVILLE', 'GEORGIA, NORTH CAROLINA', 'FL, TAMPA', 'NEW IBERIA', 'FLORIDA, NASHVILLE', 'GEORGIA, TENNESSEE', 'ATLANTA', 'ST. BERNARD PARISH', 'KENTUCKY, TENNESSEE', 'DULAC', 'GONZALES, LOUISIANA', 'ASHEVILLE, WNC', 'TENNESSEE, US', 'NORTH SARASOTA', 'LOUISIANA, NEW ORLEANS, NEW ORLEANS', 'LOUISVILLE', 'CALHOUN COUNTY', 'BUNCOMBE, NC, NC', 'HOUSTON, LA', 'SOUTH LOUISIANA', 'BUCKHEAD', 'FLORIDA, TALLAHASSEE', 'FLORIDA USA', 'MYRTLE BEACH, SC', 'LA, THIBODAUX', 'INDIANA, LOUISIANA', 'FLORIDA, MULBERRY', 'UNIVERSAL ORLANDO', 'TALLAHASSEE, TAMPA', 'BATON ROUGE', 'DESANTIS, FLORIDA', 'TALLAHASSEE, THE BIG BEND', 'NEWPORT TN', 'ATLANTA, HELENE', 'LOUISIANA, RACELAND', 'FLORIDA, KANSAS', 'LOUISIANA, THERIOT', 'ASHEVILLE, BILTMORE VILLAGE', 'FLORIDA, SHELL POINT', 'FLA, FLORIDA', 'COLLIERVILLE', 'AUSTRALIA, FLORIDA, US, US', 'GEORGIA, STONECREST', 'KC, NOLA', 'FLORIDA, NORTH PORT', 'GEORGIA, WHEELER COUNTY', 'ST. MARKS', 'FLORIDA, SIESTA KEY', 'OHIO, ORLANDO', 'FLORIDA, MILWAUKEE', 'MORGAN CITY', 'NAPOLEONVILLE', 'CRAWFORDVILLE, FLORIDA, FLORIDA', 'FLORIDA, PINELLAS COUNTY, ST. PETERSBURG, TAMPA', 'LOUISIANA, NEW ORLEANS, US', 'FLORIDA, HENDRY COUNTY', 'LIVINGSTON, LOUISIANA', 'LAPLACE', 'PALM BEACH COUNTY', 'DORAL, FLORIDA', 'CHARLESTON COUNTY', 'FLORIDA, JACKSONVILLE, SAVANNAH', 'BEAUMONT, TEXAS', 'CHARLESTON, GREENVILLE', 'FL, HIGH SPRINGS', 'MAGGIE VALLEY, NC', 'BLACKSBURG, CHRISTIANSBURG', 'GEORGETOWN, HORRY COUNTY', 'BAY COUNTY', 'FL, FL, LANARK VILLAGE', 'SOPERTON', 'BALDWIN, LOUISIANA', 'US, USA, US', 'BLACKSHEAR, GA', '., FL', 'FL, MIAMI', 'PINELLAS COUNTY, ST. PETERSBURG', 'SLIDELL', 'MIAMI-DADE COUNTY', 'SOUTH TERREBONNE', 'GULFPORT', 'GEORGIA, METTER', 'FL, MATLACHA', 'MS, SHERWOOD, TN', 'ALLIGATOR POINT, FL, FL, FLORIDA, FL', 'LOUISIANA, THIBODAUX', 'LOUISIANA, TERREBONNE PARISH', 'DEFUNIAK SPRINGS, WALTON COUNTY', 'CINCINNATI', 'CANCÚN, FLORIDA', 'NORTH CAROLINA, RUTHERFORD COUNTY', 'FL, FL, FLORIDA, GA, SC, SUWANNEE', 'GOODLETTSVILLE', 'MISSISSIPPI, MISSISSIPPI', 'LA, LA, LA', 'BERWICK, LA', 'CHICAGO, FLORIDA', 'BONITA SPRINGS', 'ALEXANDRIA, SHENANDOAH, VA', 'PALM HARBOR', 'VOLUSIA COUNTY', 'FRANKLIN, LA, LA', 'TAMPA, TAMPA BAY', 'TAMPA', 'LA, MORGAN CITY', 'FLORIDA, NYC', 'GREENSBORO', 'DULAC, DULAC, LOUISIANA, LOUISIANA', 'SOWELA', 'FLORIDA, PORT RICHEY', 'FLORIDA, SINGAPORE', 'FL, FL, FLORIDA', 'TENN.', 'DFW', 'KANSAS CITY', 'FORT MYERS BEACH, LEE COUNTY', 'CHATHAM COUNTY, SAVANNAH', 'PORT CANAVERAL, PORT CANAVERAL', 'VALDOSTA', 'ST. MARY, ST. MARY PARISH', 'BROWARD COUNTY', 'MECKLENBURG COUNTY', 'GA, LIBERTY COUNTY', 'ASHEVILLE, NC, NC', 'BLOWING ROCK', 'NOLA, NOLA', 'BRADENTON, FL', 'FLORIDA, HILLSBOROUGH COUNTY', 'BRADENTON, FLORIDA', 'FLORIDA, FORT MYERS BEACH, US', 'FLORIDA, PERRY, US', 'ACADIANA', 'FLORIDA, MADISON', 'DEKLE BEACH, FLORIDA', 'FLORIDA, LOUISIANA', 'ALABAMA, GEORGIA', 'LARGO FL', 'LOUISIANA, US, US', 'FORTMYERS', 'TPA, TAMPA', 'GEORGIA, SAVANNAH', 'HOUMA, LOUISIANA, HOUMA', 'CAROLINAS, GEORGIA', 'JASPER CO, SC, SC', 'GONZALES, LA', 'CHARLOTTE-MECKLENBURG', 'ALBANY, FLORIDA, GA', 'FLORIDA, UNITED STATES', 'FLORIDA, NORTH CAROLINA', 'FLORIDA, PERRY', 'FL, GAINESVILLE', 'CRAWFORDVILLE, TALLAHASSEE', 'SARASOTA COUNTY', 'ST. PETE, ST. PETERSBURG', 'FRANKLIN, LOUISIANA', 'GA, GEORGIA', 'FLORIDA, MANATEE COUNTY', 'FL, FL, FLORIDA, TAMPA', 'BERWICK LA', 'FL, FL, FLORIDA, GA', 'FLORIDA, FORT LAUDERDALE', 'CLEMSON, SOUTH CAROLINA', 'FRANKLIN, LOUISIANNA', 'FL, FL, ST. PETERSBURG', 'CAMERON PARISH', 'GEORGIA, LOUISIANA', 'BEAUFORT COUNTY', 'BATON ROUGE, LA', 'HAMMOND, LA', 'HARTSELLE', 'LA, NEW ORLEANS', 'JEFFERSON PARISH', 'FL, ST. MARKS', 'KENTUCKY, LOUISIANA', 'CLEMSON', 'COCODRIE, LA', 'CUT OFF, LA., LOUISIANA', 'LOUISIANA, MORGAN CITY', 'FL, PASCO, PASCO COUNTY', 'HOUMA, LA, LOUISIANA, LA', 'TAMPA FLORIDA', 'FLORIDA, GEORGIA, USA', 'ALEXANDRIA, LOUISIANA, VA.', 'FLORIDA, US, USA, US', 'LOUISIANA, NEW ORLEANS', 'LOUISIANA, MORGAN CITY, SAINT MARY PARISH', 'HOUMA, TERREBONNE PARISH', 'HAMMOND', 'FLORIDA, GULFPORT', 'GADSDEN CO.', 'NOLA', 'HOUMA, LA, LA, LAFAYETTE', 'NEW ORLEANS', 'SALUDA COUNTY, SOUTH CAROLINA', 'FLORIDA, TAYLOR COUNTY, KEATON BEACH', 'LAPLACE, LOUISIANA', 'CHICAGO, LOUISIANA', 'AUGUSTA, GEORGIA', 'MECKLENBURG CO', 'FLORIDA, PORT CHARLOTTE', 'KEATON BEACH', 'BRADENTON', 'DUBLIN, GA', 'S.C., SPARTANBURG', 'GEORGIA, GLYNN COUNTY', 'AL, ORANGE BEACH', 'FLORIDA, WALTON COUNTY', 'GEORGIA, ATLANTA', 'SAINT PETERSBURG, ST. PETE BEACH', 'JENSEN BEACH', 'FLA', 'ATLANTA, GEORGIA', 'FLORIDA, FORT MYERS, FLORIDA', 'JAX, TALLAHASSEE', 'SCOTT COUNTY', 'LOUISIANA, MANDEVILLE', 'LA, NORCO', 'HOUMA, LA, LOUISIANA, TERREBONNE PARISH, THERIOT', 'FL, ORLANDO', 'ASHEVILLE, NC', 'SUMTER COUNTY', 'FLORIDA, FORT WALTON BEACH', 'FLORIDA, SOUTHAMPTON', 'TARPON SPRINGS', 'DORCHESTER CO, SC, SC', 'CRAWFORDVILLE, FLORIDA', 'ASHEVILLE, BILTMORE, BILTMORE, BILTMORE VILLAGE, NC', 'SC, SOUTH CAROLINA, SC', 'HOUMA, LOUISIANA, TERREBONNE', 'FLORIDA, US', 'FLORIDA, TORONTO', 'MEMPHIS', 'ST. MARY PARISH', 'LOUISIANA, MEMPHIS', 'ALLIGATOR POINT, FLORIDA', 'FLORIDA, OKLAHOMA', 'FLORIDA, VENICE', 'TERREBONNE PARISH', 'MYRTLE BEACH', 'ATLANTA, GA, FLORIDA', 'US_LOUISIANA', 'ASHEVILLE NC, FLORIDA', 'COLUMBUS, GEORGIA', 'CROSS CITY, FLORIDA', 'MULBERRY', 'PICKENS COUNTY', 'LOUISIANA, NATCHITOCHES', 'FLORIDA, FORT MYERS BEACH', 'MISSISSIPPI, NEW ORLEANS', 'ST. MARY', 'FLORIDA, FLORIDA, TAMPA, TAMPA', 'METAIRIE', 'FULTON COUNTY, GEORGIA', 'UNIVERSITY CITY', 'ATLANTA, NC, TENNESSEE', 'APALACHICOLA, FL', 'KENTUCKY, OHIO', 'CRYSTAL RIVER, FL, FL', 'LOUISIANA, SLIDELL', 'BROWARD COUNTY, FLORIDA', 'LA., LAPLACE', 'COCODRIE, LA, LA', 'ST. MARY, VERMILION', 'GEORGIA, U.S.', 'MEMPHIS, MISS', \"FLORIDA, ST. JOHNS COUNTY'S\", 'DULAC, LOUISIANA, TERREBONNE PARISH', 'FLORIDA, ST PETE BEACH', 'CHARLESTON, FLORIDA', 'FLORIDA, MIAMI FL', 'JACKSON, MS, NEW ORLEANS', 'FLA., PERRY', 'TEXAS, TX', 'CHACAHOULA, LOUISIANA', 'FLORIDA, PERRY, FLORIDA, PERRY', 'ARKANSAS, LOUISIANA', 'FLORIDA, THE BIG BEND', 'NEW ORLEANS, US', 'LOUISIANA, MISSISSIPPI, NEW ORLEANS', 'PANACEA', 'WAKULLA COUNTY', 'FL, GA, SC', 'KENNER, LOUISIANA', 'ASHEVILLE, BUNCOMBE COUNTY', '--LOUISIANA, TEXAS', 'BATON ROUGE, LOUISIANA, NEW ORLEANS', 'FLORIDA, GEORGIA, US', 'GA, GEORGIA, JORDAN, WHEELER COUNTY', 'LOUISIANA, LOUISIANA', 'GA, TX', 'ATLANTA, GEORGIA, ATLANTA', 'GEORGIA, VALDOSTA', 'FLORIDA, SARASOTA', 'ST. CHARLES PARISH', 'D.C., FLORIDA', 'LA, LA, TERREBONNE PARISH', 'LOUISIANA, UNITED STATES', 'HAMMOND, LA, US', 'LAFOURCHE PARISH, THIBODAUX', 'FLORIDA, LEE COUNTY', 'FLORIDA, KENTUCKY', 'LA., MORGAN CITY', 'FLORIDA, GA', 'IL, IL', 'ESCAMBIA, FLORIDA, SANTA ROSA', 'GULFPORT, PINELLAS COUNTY', 'BUNCOMBE, HENDERSON', 'LOUISIANA, PLATTENVILLE', 'BOCA RATON, FL', 'PEACHTREE CITY', 'GRAND ISLE, LOUISIANA', 'DANIA BEACH', 'FLORIDA, TARPON SPRINGS', 'FLORIDA, LAKELAND', 'SCHRIEVER', 'FLORIDA, THE SUNSHINE STATE'}\n",
      "\n",
      "Matching Results:\n",
      "  States matched: 19\n",
      "  Counties matched: 32\n",
      "  Cities matched: 105\n",
      "  Potential cities (not state/county): 655\n",
      "  Cities found in shapefile: 105\n",
      "  City matching rate: 16.0%\n",
      "\n",
      "Sample successful city matches:\n",
      "  - ATLANTA: Polygon\n",
      "  - DULAC: Polygon\n",
      "  - HARTSELLE: Polygon\n",
      "  - RALEIGH: Polygon\n",
      "  - NORTH SARASOTA: Polygon\n",
      "  - LOUISVILLE: Polygon\n",
      "  - CLEMSON: Polygon\n",
      "  - PENSACOLA: Polygon\n",
      "  - HOUSTON: MultiPolygon\n",
      "  - LAFAYETTE: Polygon\n",
      "\n",
      "Unmatched potential cities (first 20):\n",
      "  - --LOUISIANA, TEXAS\n",
      "  - -LAFAYETTE, LA, LA\n",
      "  - ., FL\n",
      "  - /TENNESSEE\n",
      "  - ACADIANA\n",
      "  - ACADIANA, LOUISIANA\n",
      "  - AIKEN COUNTY\n",
      "  - AL, ORANGE BEACH\n",
      "  - ALABAMA, ANDALUSIA\n",
      "  - ALABAMA, ATLANTA\n",
      "  - ALABAMA, CT, LOUISIANA\n",
      "  - ALABAMA, FLORIDA\n",
      "  - ALABAMA, FLORIDA, LOUISIANA\n",
      "  - ALABAMA, GEORGIA\n",
      "  - ALABAMA, LOUISIANA\n",
      "  - ALBANY, FLORIDA, GA\n",
      "  - ALEXANDRIA, LOUISIANA, VA.\n",
      "  - ALEXANDRIA, SHENANDOAH, VA\n",
      "  - ALGIERS, LOUISIANA, NEW ORLEANS\n",
      "  - ALLIGATOR POINT, FL\n",
      "  ... and 559 more\n",
      "\n",
      "Sample city names from shapefile (first 20):\n",
      "  - AARONSBURG\n",
      "  - ABANDA\n",
      "  - ABBEVILLE\n",
      "  - ABBOTSFORD\n",
      "  - ABBOTT\n",
      "  - ABBOTTSTOWN\n",
      "  - ABBS VALLEY\n",
      "  - ABBYVILLE\n",
      "  - ABERCROMBIE\n",
      "  - ABERDEEN\n",
      "  - ABERDEEN GARDENS\n",
      "  - ABERDEEN PROVING GROUND\n",
      "  - ABERNATHY\n",
      "  - ABEYTAS\n",
      "  - ABIE\n",
      "  - ABILENE\n",
      "  - ABINGDON\n",
      "  - ABINGTON\n",
      "  - ABIQUIU\n",
      "  - ABITA SPRINGS\n",
      "\n",
      "============================================================\n",
      "VALIDATION COMPLETE\n",
      "============================================================\n",
      "Lookup dictionaries updated with projected geometries ✓\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T18:52:37.535405Z",
     "start_time": "2025-09-22T18:52:03.111455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.features import geometry_mask\n",
    "# ==============================================================================\n",
    "# STEP 2: MAIN RASTERIZATION LOOP - TIME ITERATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Create output directories\n",
    "rasters_dir = r\"\\rasters_output\"\n",
    "output_dir = f\"{local_path}{rasters_dir}\"\n",
    "# output_dir = os.path.join(local_path, 'rasters_output')\n",
    "# output_dir = r\"C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def process_hurricane(hurricane_name, gdf_proj, interval_counts, time_bins):\n",
    "    \"\"\"\n",
    "    Process a single hurricane through all time bins\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"PROCESSING: {hurricane_name.upper()}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    # Create hurricane-specific output directory\n",
    "    hurricane_dir = os.path.join(output_dir, hurricane_name.lower())\n",
    "    os.makedirs(hurricane_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize cumulative grid (persists across time bins)\n",
    "    cumulative_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Loop through each time bin chronologically\n",
    "    for idx, time_bin in enumerate(time_bins):\n",
    "        print(f\"\\n--- Time Bin {idx+1}/{len(time_bins)}: {time_bin} ---\")\n",
    "\n",
    "        # Filter data for current time bin\n",
    "        current_data = interval_counts[interval_counts['unix_timestamp'] == time_bin]\n",
    "        tweet_count = len(current_data)\n",
    "        print(f\"  Tweets in this bin: {tweet_count}\")\n",
    "\n",
    "        # Initialize incremental grid for this time bin\n",
    "        incremental_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "        # === PLACEHOLDER FUNCTIONS ===\n",
    "\n",
    "        # 1. Create State Raster\n",
    "        state_raster = create_state_raster(current_data, grid_params)\n",
    "        incremental_grid += state_raster\n",
    "\n",
    "        # 2. Create County Raster\n",
    "        county_raster = create_county_raster(current_data, grid_params)\n",
    "        incremental_grid += county_raster\n",
    "\n",
    "        # 3. Create City/Point Raster\n",
    "        city_raster = create_city_raster(current_data, grid_params)\n",
    "        incremental_grid += city_raster\n",
    "\n",
    "        # 4. Create Facility/KDE Raster\n",
    "        facility_raster = create_facility_raster(current_data, grid_params)\n",
    "        incremental_grid += facility_raster\n",
    "\n",
    "        # === END PLACEHOLDERS ===\n",
    "\n",
    "        # Update cumulative grid\n",
    "        cumulative_grid += incremental_grid\n",
    "\n",
    "        # Save rasters\n",
    "        save_raster(incremental_grid, hurricane_dir, hurricane_name, time_bin, 'increment')\n",
    "        save_raster(cumulative_grid, hurricane_dir, hurricane_name, time_bin, 'cumulative')\n",
    "\n",
    "        print(f\"  Incremental max value: {np.max(incremental_grid):.2f}\")\n",
    "        print(f\"  Cumulative max value: {np.max(cumulative_grid):.2f}\")\n",
    "\n",
    "    print(f\"\\n{hurricane_name.upper()} processing complete!\")\n",
    "    print(f\"Output saved to: {hurricane_dir}\")\n",
    "    return\n",
    "\n",
    "# ==============================================================================\n",
    "# PLACEHOLDER FUNCTIONS (TO BE IMPLEMENTED)\n",
    "# ==============================================================================\n",
    "\n",
    "def create_state_raster(data, grid_params):\n",
    "    \"\"\"Rasterize state-level tweets\"\"\"\n",
    "    print(\"    [STATE] Creating state raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    state_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for STATE-level tweets only\n",
    "    state_data = data[data['scale_level'] == 'STATE']\n",
    "\n",
    "    if len(state_data) == 0:\n",
    "        print(\"      No state-level tweets in this time bin\")\n",
    "        return state_grid\n",
    "\n",
    "    # Group by state name and sum counts\n",
    "    state_counts = state_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(state_counts)} unique states\")\n",
    "\n",
    "    # Process each state\n",
    "    for state_name, tweet_count in state_counts.items():\n",
    "        if state_name in state_lookup_proj:\n",
    "            # Get the state geometry\n",
    "            state_geom = state_lookup_proj[state_name]\n",
    "\n",
    "            # Rasterize the polygon\n",
    "            # Create a list of (geometry, value) tuples\n",
    "            shapes = [(state_geom, 1)]\n",
    "\n",
    "            # Rasterize to temporary grid\n",
    "            temp_grid = rasterio.features.rasterize(\n",
    "                shapes=shapes,\n",
    "                out_shape=(grid_params['height'], grid_params['width']),\n",
    "                transform=grid_params['transform'],\n",
    "                fill=0,\n",
    "                dtype=np.float32,\n",
    "                all_touched=True  # Include all pixels touched by polygon\n",
    "            )\n",
    "\n",
    "            # Multiply by tweet count and add to state grid\n",
    "            state_grid += temp_grid * tweet_count\n",
    "\n",
    "            print(f\"      - {state_name}: {tweet_count} tweets, {np.sum(temp_grid)} pixels\")\n",
    "        else:\n",
    "            print(f\"      WARNING: State '{state_name}' not found in lookup\")\n",
    "\n",
    "    total_value = np.sum(state_grid)\n",
    "    max_value = np.max(state_grid)\n",
    "    print(f\"      Total state grid value: {total_value:.0f}, Max pixel: {max_value:.0f}\")\n",
    "\n",
    "    return state_grid\n",
    "\n",
    "def create_county_raster(data, grid_params):\n",
    "    \"\"\"Rasterize county-level tweets with hotspot multiplier\"\"\"\n",
    "    print(\"    [COUNTY] Creating county raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    county_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for COUNTY-level tweets only\n",
    "    county_data = data[data['scale_level'] == 'COUNTY']\n",
    "\n",
    "    if len(county_data) == 0:\n",
    "        print(\"      No county-level tweets in this time bin\")\n",
    "        return county_grid\n",
    "\n",
    "    # Group by county name and sum counts\n",
    "    county_counts = county_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(county_counts)} unique counties\")\n",
    "\n",
    "    # HOTSPOT MULTIPLIER for counties\n",
    "    county_multiplier = 3  # Make counties 3x more prominent\n",
    "\n",
    "    # Process each county\n",
    "    for county_name, tweet_count in county_counts.items():\n",
    "        if county_name in county_lookup_proj:\n",
    "            # Get the county geometry\n",
    "            county_geom = county_lookup_proj[county_name]\n",
    "\n",
    "            # Rasterize the polygon\n",
    "            shapes = [(county_geom, 1)]\n",
    "\n",
    "            # Rasterize to temporary grid\n",
    "            temp_grid = rasterize(\n",
    "                shapes=shapes,\n",
    "                out_shape=(grid_params['height'], grid_params['width']),\n",
    "                transform=grid_params['transform'],\n",
    "                fill=0,\n",
    "                dtype=np.float32,\n",
    "                all_touched=True  # Include all pixels touched by polygon\n",
    "            )\n",
    "\n",
    "            # Multiply by tweet count AND multiplier for hotspot effect\n",
    "            county_grid += temp_grid * tweet_count * county_multiplier\n",
    "\n",
    "            print(f\"      - {county_name}: {tweet_count} tweets × {county_multiplier} = {tweet_count * county_multiplier}, {np.sum(temp_grid)} pixels\")\n",
    "        else:\n",
    "            print(f\"      WARNING: County '{county_name}' not found in lookup\")\n",
    "\n",
    "    total_value = np.sum(county_grid)\n",
    "    max_value = np.max(county_grid)\n",
    "    print(f\"      Total county grid value: {total_value:.0f}, Max pixel: {max_value:.0f}\")\n",
    "\n",
    "    return county_grid\n",
    "\n",
    "def create_city_raster(data, grid_params):\n",
    "    \"\"\"Rasterize city-level tweets using city polygon geometries with hotspot multiplier\"\"\"\n",
    "    print(\"    [CITY] Creating city raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    city_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for CITY-level tweets only\n",
    "    city_data = data[data['scale_level'] == 'CITY']\n",
    "\n",
    "    if len(city_data) == 0:\n",
    "        print(\"      No city-level tweets in this time bin\")\n",
    "        return city_grid\n",
    "\n",
    "    # Group by city name and sum counts\n",
    "    city_counts = city_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(city_counts)} unique cities\")\n",
    "\n",
    "    # HOTSPOT MULTIPLIER for cities\n",
    "    city_multiplier = 5     # Make cities 5x more prominent\n",
    "\n",
    "    # Process each city\n",
    "    for city_name, tweet_count in city_counts.items():\n",
    "        if city_name in cities_lookup_proj:\n",
    "            # Get the city polygon geometry (already projected to grid CRS)\n",
    "            city_geom_proj = cities_lookup_proj[city_name]\n",
    "\n",
    "            # Rasterize the city polygon directly\n",
    "            shapes = [(city_geom_proj, 1)]\n",
    "\n",
    "            # Rasterize to temporary grid\n",
    "            temp_grid = rasterize(\n",
    "                shapes=shapes,\n",
    "                out_shape=(grid_params['height'], grid_params['width']),\n",
    "                transform=grid_params['transform'],\n",
    "                fill=0,\n",
    "                dtype=np.float32,\n",
    "                all_touched=True  # Include all pixels touched by city boundary\n",
    "            )\n",
    "\n",
    "            # Multiply by tweet count AND multiplier for hotspot effect\n",
    "            city_grid += temp_grid * tweet_count * city_multiplier\n",
    "\n",
    "            print(f\"      - {city_name}: {tweet_count} tweets × {city_multiplier} = {tweet_count * city_multiplier}, {np.sum(temp_grid)} pixels\")\n",
    "        else:\n",
    "            print(f\"      WARNING: City '{city_name}' not found in projected lookup\")\n",
    "\n",
    "    total_value = np.sum(city_grid)\n",
    "    max_value = np.max(city_grid)\n",
    "    # print(f\"      Total city grid value: {total_value:.0f}, Max pixel: {max_value:.0f}\")\n",
    "\n",
    "    return city_grid\n",
    "\n",
    "def create_facility_raster(data, grid_params):\n",
    "    \"\"\"Create KDE raster for facility points with strong hotspot multiplier\"\"\"\n",
    "    print(\"    [FACILITY] Creating facility raster...\")\n",
    "\n",
    "    # Initialize empty raster\n",
    "    facility_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "\n",
    "    # Filter for FACILITY-level tweets only\n",
    "    facility_data = data[data['scale_level'] == 'FACILITY']\n",
    "\n",
    "    if len(facility_data) == 0:\n",
    "        print(\"      No facility-level tweets in this time bin\")\n",
    "        return facility_grid\n",
    "\n",
    "    # Group by facility coordinates (using matched_name as proxy) and sum counts\n",
    "    facility_counts = facility_data.groupby('matched_name')['count'].sum()\n",
    "\n",
    "    print(f\"      Processing {len(facility_counts)} unique facilities\")\n",
    "\n",
    "    # HOTSPOT PARAMETERS for facilities\n",
    "    sigma_meters = 2 * grid_params['cell_size']  # 10 km for 5km cells\n",
    "    sigma_pixels = sigma_meters / grid_params['cell_size']  # Convert to pixel units\n",
    "    facility_multiplier = 10  # Make facilities 10x more prominent (strongest hotspots)\n",
    "\n",
    "    # Process each facility\n",
    "    facilities_processed = 0\n",
    "    for facility_name, tweet_count in facility_counts.items():\n",
    "        # Get facility data to extract geometry\n",
    "        facility_rows = facility_data[facility_data['matched_name'] == facility_name]\n",
    "\n",
    "        if len(facility_rows) > 0:\n",
    "            # Get the point geometry (should be from the tweet's geocoded location)\n",
    "            facility_point = facility_rows.iloc[0]['matched_geom']\n",
    "\n",
    "            # Project point to grid CRS if needed\n",
    "            if hasattr(facility_point, 'x') and hasattr(facility_point, 'y'):\n",
    "                # Create GeoSeries to handle projection\n",
    "                point_geoseries = gpd.GeoSeries([facility_point], crs='EPSG:4326')\n",
    "                point_proj = point_geoseries.to_crs(grid_params['crs']).iloc[0]\n",
    "\n",
    "                # Convert point coordinates to pixel indices\n",
    "                px = (point_proj.x - grid_params['bounds'][0]) / grid_params['cell_size']\n",
    "                py = (grid_params['bounds'][3] - point_proj.y) / grid_params['cell_size']\n",
    "\n",
    "                # Check if point is within grid bounds\n",
    "                if 0 <= px < grid_params['width'] and 0 <= py < grid_params['height']:\n",
    "                    # Create point raster with tweet count at location\n",
    "                    point_grid = np.zeros((grid_params['height'], grid_params['width']), dtype=np.float32)\n",
    "                    point_grid[int(py), int(px)] = tweet_count\n",
    "\n",
    "                    # Apply Gaussian filter to create kernel density\n",
    "                    kernel_grid = gaussian_filter(point_grid, sigma=sigma_pixels, mode='constant', cval=0)\n",
    "\n",
    "                    # FIXED: Only add once with proper multiplier\n",
    "                    facility_grid += kernel_grid * facility_multiplier\n",
    "\n",
    "                    facilities_processed += 1\n",
    "                    effective_value = tweet_count * facility_multiplier\n",
    "                    print(f\"      - {facility_name}: {tweet_count} tweets × {facility_multiplier} = {effective_value}, KDE at ({point_proj.x:.0f}, {point_proj.y:.0f})\")\n",
    "                else:\n",
    "                    print(f\"      WARNING: Facility '{facility_name}' outside grid bounds\")\n",
    "            else:\n",
    "                print(f\"      WARNING: Invalid geometry for facility '{facility_name}'\")\n",
    "\n",
    "    print(f\"      Processed {facilities_processed} facilities with sigma={sigma_pixels:.2f} pixels\")\n",
    "\n",
    "    total_value = np.sum(facility_grid)\n",
    "    max_value = np.max(facility_grid)\n",
    "    # print(f\"      Total facility grid value: {total_value:.2f}, Max pixel: {max_value:.2f}\")\n",
    "\n",
    "    return facility_grid\n",
    "\n",
    "def save_raster(grid, output_dir, hurricane_name, time_bin, raster_type):\n",
    "    \"\"\"Save raster as GeoTIFF\"\"\"\n",
    "    # Convert unix timestamp to readable format for filename\n",
    "    # time_str = pd.Timestamp(time_bin, unit='ns').strftime('%Y%m%d_%H%M')\n",
    "    filename = f\"{hurricane_name}_{raster_type}_{time_bin}.tif\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    with rasterio.open(\n",
    "        filepath, 'w',\n",
    "        driver='GTiff',\n",
    "        height=grid_params['height'],\n",
    "        width=grid_params['width'],\n",
    "        count=1,\n",
    "        dtype=grid.dtype,\n",
    "        crs=grid_params['crs'],\n",
    "        transform=grid_params['transform'],\n",
    "        compress='lzw'\n",
    "    ) as dst:\n",
    "        dst.write(grid, 1)\n",
    "\n",
    "    print(f\"    Saved: {filename}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECUTE PROCESSING FOR BOTH HURRICANES\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STARTING RASTERIZATION PROCESS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process Francine\n",
    "# process_hurricane('francine', francine_proj, francine_interval_counts, francine_time_bins)\n",
    "\n",
    "# Process Helene\n",
    "process_hurricane('helene', helene_proj, helene_interval_counts, helene_time_bins)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL PROCESSING COMPLETE! ✓\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "2e1bc16e47f51e00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING RASTERIZATION PROCESS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING: HELENE\n",
      "============================================================\n",
      "\n",
      "--- Time Bin 1/11: 1727308800 ---\n",
      "  Tweets in this bin: 44\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 7 unique states\n",
      "      - ALABAMA: 1 tweets, 191407.0 pixels\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 51 tweets, 195469.0 pixels\n",
      "      - GEORGIA: 4 tweets, 217442.0 pixels\n",
      "      - KANSAS: 1 tweets, 349904.0 pixels\n",
      "      WARNING: State 'NC' not found in lookup\n",
      "      - TENNESSEE: 1 tweets, 167994.0 pixels\n",
      "      Total state grid value: 11547992, Max pixel: 56\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 13 unique counties\n",
      "      - ABBEVILLE: 1 tweets × 3 = 3, 2066.0 pixels\n",
      "      - ARKANSAS: 1 tweets × 3 = 3, 4230.0 pixels\n",
      "      - ATLANTIC: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - BUNCOMBE: 2 tweets × 3 = 6, 2771.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 3 = 3, 2118.0 pixels\n",
      "      - CORTLAND: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - FLORIDA: 51 tweets × 3 = 153, 0.0 pixels\n",
      "      - GENESEE: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - GEORGE: 4 tweets × 3 = 12, 1825.0 pixels\n",
      "      - HENDERSON: 1 tweets × 3 = 3, 2135.0 pixels\n",
      "      - LAWRENCE: 1 tweets × 3 = 3, 2038.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 2611.0 pixels\n",
      "      - SPARTANBURG: 1 tweets × 3 = 3, 3292.0 pixels\n",
      "      Total county grid value: 93996, Max pixel: 12\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 22 unique cities\n",
      "      - ASHEVILLE: 1 tweets × 5 = 5, 293.0 pixels\n",
      "      - ATLANTA: 2 tweets × 5 = 10, 71.0 pixels\n",
      "      - BLOWING ROCK: 1 tweets × 5 = 5, 26.0 pixels\n",
      "      - BUNCOMBE: 2 tweets × 5 = 10, 11.0 pixels\n",
      "      - CAPE CANAVERAL: 2 tweets × 5 = 10, 15.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - FLORIDA: 51 tweets × 5 = 255, 6.0 pixels\n",
      "      - GEORGIANA: 4 tweets × 5 = 20, 36.0 pixels\n",
      "      - HENDERSON: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - KALAMA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - KANSAS: 1 tweets × 5 = 5, 24.0 pixels\n",
      "      - LARGO: 1 tweets × 5 = 5, 23.0 pixels\n",
      "      - LAWRENCEVILLE: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - OCALA: 1 tweets × 5 = 5, 235.0 pixels\n",
      "      - ORLANDO: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - PANACEA: 1 tweets × 5 = 5, 14.0 pixels\n",
      "      - RALEIGH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - SOUTHCHASE: 1 tweets × 5 = 5, 41.0 pixels\n",
      "      - SPARTANBURG: 1 tweets × 5 = 5, 123.0 pixels\n",
      "      - TALLAHASSEE: 4 tweets × 5 = 20, 518.0 pixels\n",
      "      - TENNESSEE: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - WHITMORE VILLAGE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      - PORT CANAVERAL, Port Canaveral: 2 tweets × 10 = 20, KDE at (-8975645, 3300402)\n",
      "      - River City Marketplace: 1 tweets × 10 = 10, KDE at (-9088220, 3565002)\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727308800.tif\n",
      "    Saved: helene_cumulative_1727308800.tif\n",
      "  Incremental max value: 255.00\n",
      "  Cumulative max value: 255.00\n",
      "\n",
      "--- Time Bin 2/11: 1727323200 ---\n",
      "  Tweets in this bin: 67\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 9 unique states\n",
      "      WARNING: State 'AL' not found in lookup\n",
      "      - ALABAMA: 1 tweets, 191407.0 pixels\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 97 tweets, 195469.0 pixels\n",
      "      - GEORGIA: 4 tweets, 217442.0 pixels\n",
      "      - NORTH CAROLINA: 1 tweets, 193420.0 pixels\n",
      "      - OHIO: 1 tweets, 185026.0 pixels\n",
      "      - TENNESSEE: 1 tweets, 167994.0 pixels\n",
      "      - VIRGINIA: 2 tweets, 163815.0 pixels\n",
      "      Total state grid value: 20895740, Max pixel: 102\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 19 unique counties\n",
      "      - ATLANTIC: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - BARTON: 1 tweets × 3 = 3, 2553.0 pixels\n",
      "      - BREVARD: 1 tweets × 3 = 3, 4578.0 pixels\n",
      "      - CABELL: 1 tweets × 3 = 3, 1323.0 pixels\n",
      "      - CAROLINA: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CORTLAND: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - ESCAMBIA: 1 tweets × 3 = 3, 2728.0 pixels\n",
      "      - FLORIDA: 97 tweets × 3 = 291, 0.0 pixels\n",
      "      - GENESEE: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - GEORGE: 4 tweets × 3 = 12, 1825.0 pixels\n",
      "      - OHIO: 1 tweets × 3 = 3, 2634.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 2611.0 pixels\n",
      "      WARNING: County 'SAINT MARY' not found in lookup\n",
      "      - SANTA ROSA: 1 tweets × 3 = 3, 4334.0 pixels\n",
      "      - SARASOTA: 1 tweets × 3 = 3, 2125.0 pixels\n",
      "      - SOUTHAMPTON: 1 tweets × 3 = 3, 2576.0 pixels\n",
      "      - TAMA: 2 tweets × 3 = 6, 106.0 pixels\n",
      "      - TULSA: 2 tweets × 3 = 6, 2513.0 pixels\n",
      "      - VIRGINIA BEACH: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      Total county grid value: 114000, Max pixel: 12\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 37 unique cities\n",
      "      - APALACHICOLA: 1 tweets × 5 = 5, 17.0 pixels\n",
      "      - ATHOL: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - ATLANTA: 2 tweets × 5 = 10, 71.0 pixels\n",
      "      - BAY CITY: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - BIG BEND: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - BOCA RATON: 1 tweets × 5 = 5, 126.0 pixels\n",
      "      - BREVARD: 1 tweets × 5 = 5, 47.0 pixels\n",
      "      - CAMBRIA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - CAROLINA: 1 tweets × 5 = 5, 10.0 pixels\n",
      "      - CARRABELLE: 1 tweets × 5 = 5, 39.0 pixels\n",
      "      - CINCINNATI: 1 tweets × 5 = 5, 475.0 pixels\n",
      "      - CRYSTAL RIVER: 1 tweets × 5 = 5, 49.0 pixels\n",
      "      - DEANS: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - DOTHAN: 1 tweets × 5 = 5, 415.0 pixels\n",
      "      - FAYETTEVILLE: 1 tweets × 5 = 5, 57.0 pixels\n",
      "      - FLORIDA: 97 tweets × 5 = 485, 6.0 pixels\n",
      "      - FORT MYERS: 1 tweets × 5 = 5, 195.0 pixels\n",
      "      - GEORGIANA: 4 tweets × 5 = 20, 36.0 pixels\n",
      "      - KALAMA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - MEMPHIS: 1 tweets × 5 = 5, 17.0 pixels\n",
      "      - NORTH COLLINS: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - OHIO: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - ORLANDO: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - PANACEA: 1 tweets × 5 = 5, 14.0 pixels\n",
      "      - PLANT CITY: 1 tweets × 5 = 5, 162.0 pixels\n",
      "      - RALEIGH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      WARNING: City 'SAINT MARKS' not found in projected lookup\n",
      "      - SAN ANTONIO: 4 tweets × 5 = 20, 2121.0 pixels\n",
      "      - SANTA ROSA: 1 tweets × 5 = 5, 2.0 pixels\n",
      "      - SARASOTA: 1 tweets × 5 = 5, 92.0 pixels\n",
      "      - SAVANNAH: 1 tweets × 5 = 5, 6.0 pixels\n",
      "      - SOUTHAMPTON: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - TALLAHASSEE: 6 tweets × 5 = 30, 518.0 pixels\n",
      "      - TAMPA: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - TENNESSEE: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - URSA: 2 tweets × 5 = 10, 12.0 pixels\n",
      "      - VIRGINIA: 2 tweets × 5 = 10, 3.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 2 unique facilities\n",
      "      - Blue Ridge Parkway: 1 tweets × 10 = 10, KDE at (-9096483, 4320972)\n",
      "      - Universal Volcano Bay: 1 tweets × 10 = 10, KDE at (-9069543, 3307271)\n",
      "      Processed 2 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727323200.tif\n",
      "    Saved: helene_cumulative_1727323200.tif\n",
      "  Incremental max value: 486.00\n",
      "  Cumulative max value: 741.00\n",
      "\n",
      "--- Time Bin 3/11: 1727337600 ---\n",
      "  Tweets in this bin: 56\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 10 unique states\n",
      "      WARNING: State 'DC' not found in lookup\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 139 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 7 tweets, 217442.0 pixels\n",
      "      - NORTH CAROLINA: 1 tweets, 193420.0 pixels\n",
      "      - OHIO: 3 tweets, 185026.0 pixels\n",
      "      - OKLAHOMA: 1 tweets, 275681.0 pixels\n",
      "      - TENNESSEE: 1 tweets, 167994.0 pixels\n",
      "      - VIRGINIA: 1 tweets, 163815.0 pixels\n",
      "      Total state grid value: 30048272, Max pixel: 146\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 16 unique counties\n",
      "      - ATLANTIC: 3 tweets × 3 = 9, 0.0 pixels\n",
      "      - BROWARD: 1 tweets × 3 = 3, 4089.0 pixels\n",
      "      - CHISAGO: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CORTLAND: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - CRAWFORD: 1 tweets × 3 = 3, 1414.0 pixels\n",
      "      - FLORIDA: 139 tweets × 3 = 417, 0.0 pixels\n",
      "      - GENESEE: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - GEORGE: 7 tweets × 3 = 21, 1825.0 pixels\n",
      "      - OAKLAND: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - OHIO: 3 tweets × 3 = 9, 2634.0 pixels\n",
      "      - OKLAHOMA: 1 tweets × 3 = 3, 2940.0 pixels\n",
      "      - PETERSBURG: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 2611.0 pixels\n",
      "      - SARASOTA: 2 tweets × 3 = 6, 2125.0 pixels\n",
      "      - TAMA: 3 tweets × 3 = 9, 106.0 pixels\n",
      "      - VIRGINIA BEACH: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      Total county grid value: 108897, Max pixel: 21\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 29 unique cities\n",
      "      - APALACHICOLA: 1 tweets × 5 = 5, 17.0 pixels\n",
      "      - ATLANTA: 3 tweets × 5 = 15, 71.0 pixels\n",
      "      - CHICAGO: 1 tweets × 5 = 5, 716.0 pixels\n",
      "      - CRAWFORDVILLE: 1 tweets × 5 = 5, 22.0 pixels\n",
      "      - FLORIDA: 139 tweets × 5 = 695, 6.0 pixels\n",
      "      - FORT MYERS BEACH: 2 tweets × 5 = 10, 30.0 pixels\n",
      "      - GAY: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - GEORGIANA: 7 tweets × 5 = 35, 36.0 pixels\n",
      "      - HOWARD: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - IVES ESTATES: 1 tweets × 5 = 5, 16.0 pixels\n",
      "      - LAKELAND: 1 tweets × 5 = 5, 123.0 pixels\n",
      "      - LEE MONT: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - MYRTLE BEACH: 1 tweets × 5 = 5, 141.0 pixels\n",
      "      - NASHVILLE: 1 tweets × 5 = 5, 2.0 pixels\n",
      "      - NORTH COLLINS: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - OHIO: 3 tweets × 5 = 15, 8.0 pixels\n",
      "      - OKLAHOMA: 1 tweets × 5 = 5, 9.0 pixels\n",
      "      - ORLANDO: 2 tweets × 5 = 10, 13.0 pixels\n",
      "      - PALM BAY: 1 tweets × 5 = 5, 366.0 pixels\n",
      "      - RALEIGH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      WARNING: City 'SAINT PETERSBURG' not found in projected lookup\n",
      "      - SAN ANTONIO: 1 tweets × 5 = 5, 2121.0 pixels\n",
      "      - SARASOTA: 2 tweets × 5 = 10, 92.0 pixels\n",
      "      - SOUTHEAST ARCADIA: 1 tweets × 5 = 5, 38.0 pixels\n",
      "      - TALLAHASSEE: 4 tweets × 5 = 20, 518.0 pixels\n",
      "      - TAMPA: 3 tweets × 5 = 15, 4.0 pixels\n",
      "      - TENNESSEE: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - TYNDALL: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - VIRGINIA: 1 tweets × 5 = 5, 3.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 1 unique facilities\n",
      "      - the Blue Ridge Parkway: 1 tweets × 10 = 10, KDE at (-9182381, 4240996)\n",
      "      Processed 1 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727337600.tif\n",
      "    Saved: helene_cumulative_1727337600.tif\n",
      "  Incremental max value: 698.00\n",
      "  Cumulative max value: 1439.00\n",
      "\n",
      "--- Time Bin 4/11: 1727352000 ---\n",
      "  Tweets in this bin: 92\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 14 unique states\n",
      "      WARNING: State 'AL' not found in lookup\n",
      "      - ALABAMA: 1 tweets, 191407.0 pixels\n",
      "      - ARIZONA: 1 tweets, 0.0 pixels\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 100 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 14 tweets, 217442.0 pixels\n",
      "      - KENTUCKY: 1 tweets, 168204.0 pixels\n",
      "      - NORTH CAROLINA: 3 tweets, 193420.0 pixels\n",
      "      - OHIO: 1 tweets, 185026.0 pixels\n",
      "      - SOUTH CAROLINA: 3 tweets, 118446.0 pixels\n",
      "      - TENNESSEE: 2 tweets, 167994.0 pixels\n",
      "      WARNING: State 'VA' not found in lookup\n",
      "      - VIRGINIA: 4 tweets, 163815.0 pixels\n",
      "      Total state grid value: 25062572, Max pixel: 115\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 27 unique counties\n",
      "      - ALACHUA: 1 tweets × 3 = 3, 3439.0 pixels\n",
      "      - ALEXANDRIA: 1 tweets × 3 = 3, 78.0 pixels\n",
      "      - ATLANTIC: 3 tweets × 3 = 9, 0.0 pixels\n",
      "      - BUNCOMBE: 1 tweets × 3 = 3, 2771.0 pixels\n",
      "      - CHARLESTON: 1 tweets × 3 = 3, 4174.0 pixels\n",
      "      - COLUMBUS: 1 tweets × 3 = 3, 3832.0 pixels\n",
      "      - CORTLAND: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - FLORIDA: 100 tweets × 3 = 300, 0.0 pixels\n",
      "      - GASTON: 1 tweets × 3 = 3, 1537.0 pixels\n",
      "      - GENESEE: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - GEORGE: 14 tweets × 3 = 42, 1825.0 pixels\n",
      "      - GRANVILLE: 1 tweets × 3 = 3, 2290.0 pixels\n",
      "      - GREENVILLE: 2 tweets × 3 = 6, 3265.0 pixels\n",
      "      - HASKELL: 1 tweets × 3 = 3, 3485.0 pixels\n",
      "      - HENDERSON: 1 tweets × 3 = 3, 2135.0 pixels\n",
      "      - MACON: 1 tweets × 3 = 3, 3674.0 pixels\n",
      "      - MARION: 1 tweets × 3 = 3, 2034.0 pixels\n",
      "      - MECKLENBURG: 2 tweets × 3 = 6, 2234.0 pixels\n",
      "      - MIAMI: 2 tweets × 3 = 6, 1908.0 pixels\n",
      "      - OHIO: 1 tweets × 3 = 3, 2634.0 pixels\n",
      "      - PASCO: 1 tweets × 3 = 3, 2754.0 pixels\n",
      "      - PERRY: 1 tweets × 3 = 3, 1577.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 2611.0 pixels\n",
      "      - SHENANDOAH: 1 tweets × 3 = 3, 2313.0 pixels\n",
      "      - SPARTANBURG: 1 tweets × 3 = 3, 3292.0 pixels\n",
      "      - TAMA: 6 tweets × 3 = 18, 106.0 pixels\n",
      "      - VIRGINIA BEACH: 4 tweets × 3 = 12, 0.0 pixels\n",
      "      Total county grid value: 256890, Max pixel: 42\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 45 unique cities\n",
      "      - ALEXANDRIA: 1 tweets × 5 = 5, 87.0 pixels\n",
      "      - APALACHICOLA: 1 tweets × 5 = 5, 17.0 pixels\n",
      "      - ARION: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - ATHOL: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - ATLANTA: 3 tweets × 5 = 15, 71.0 pixels\n",
      "      - BIG BEND: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - BUNCOMBE: 1 tweets × 5 = 5, 11.0 pixels\n",
      "      - BURKE CENTRE: 1 tweets × 5 = 5, 24.0 pixels\n",
      "      - CHARLESTON: 1 tweets × 5 = 5, 211.0 pixels\n",
      "      - COLUMBUS: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - EVA: 1 tweets × 5 = 5, 17.0 pixels\n",
      "      - FLORIDA: 100 tweets × 5 = 500, 6.0 pixels\n",
      "      - GAINESVILLE: 1 tweets × 5 = 5, 63.0 pixels\n",
      "      - GASTON: 1 tweets × 5 = 5, 45.0 pixels\n",
      "      - GAY: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - GEORGIANA: 14 tweets × 5 = 70, 36.0 pixels\n",
      "      - GREENVILLE: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - HARTSELLE: 1 tweets × 5 = 5, 109.0 pixels\n",
      "      - HENDERSON: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - KALAMA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - MACON: 1 tweets × 5 = 5, 6.0 pixels\n",
      "      WARNING: City 'MACONBIBB COUNTY' not found in projected lookup\n",
      "      - MATLACHA: 1 tweets × 5 = 5, 5.0 pixels\n",
      "      - MCKEANSBURG: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - MEMPHIS: 1 tweets × 5 = 5, 17.0 pixels\n",
      "      - MEXICO BEACH: 1 tweets × 5 = 5, 23.0 pixels\n",
      "      - MIAMI: 2 tweets × 5 = 10, 12.0 pixels\n",
      "      - NASHVILLE: 1 tweets × 5 = 5, 2.0 pixels\n",
      "      - NORTH COLLINS: 3 tweets × 5 = 15, 0.0 pixels\n",
      "      - OHIO: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - ORLANDO: 2 tweets × 5 = 10, 13.0 pixels\n",
      "      - PANACEA: 1 tweets × 5 = 5, 14.0 pixels\n",
      "      - PASCO: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - PENSACOLA: 1 tweets × 5 = 5, 5.0 pixels\n",
      "      - PERRY: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - RALEIGH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - SANDERSVILLE: 1 tweets × 5 = 5, 24.0 pixels\n",
      "      - SHELL POINT: 1 tweets × 5 = 5, 34.0 pixels\n",
      "      - SHENANDOAH: 1 tweets × 5 = 5, 18.0 pixels\n",
      "      - SOUTH CARROLLTON: 3 tweets × 5 = 15, 5.0 pixels\n",
      "      - SPARTANBURG: 1 tweets × 5 = 5, 123.0 pixels\n",
      "      - TALLAHASSEE: 19 tweets × 5 = 95, 518.0 pixels\n",
      "      - TAMPA: 6 tweets × 5 = 30, 4.0 pixels\n",
      "      - TENNESSEE: 2 tweets × 5 = 10, 8.0 pixels\n",
      "      - VIRGINIA: 4 tweets × 5 = 20, 3.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 6 unique facilities\n",
      "      - Camp Blanding Joint Training Center: 1 tweets × 10 = 10, KDE at (-9123764, 3493786)\n",
      "      - Capitol: 3 tweets × 10 = 30, KDE at (-9382157, 3559997)\n",
      "      - Disney World: 1 tweets × 10 = 10, KDE at (-9068478, 3315080)\n",
      "      - Dollywood Theme Park: 1 tweets × 10 = 10, KDE at (-9298731, 4272492)\n",
      "      - Hampton Springs Rd: 1 tweets × 10 = 10, KDE at (-9302606, 3517358)\n",
      "      - I-4: 13 tweets × 10 = 130, KDE at (-9066872, 3309543)\n",
      "      Processed 6 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727352000.tif\n",
      "    Saved: helene_cumulative_1727352000.tif\n",
      "  Incremental max value: 501.00\n",
      "  Cumulative max value: 1940.00\n",
      "\n",
      "--- Time Bin 5/11: 1727366400 ---\n",
      "  Tweets in this bin: 96\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 15 unique states\n",
      "      - ALABAMA: 1 tweets, 191407.0 pixels\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 175 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 13 tweets, 217442.0 pixels\n",
      "      - KENTUCKY: 1 tweets, 168204.0 pixels\n",
      "      WARNING: State 'NC' not found in lookup\n",
      "      - NORTH CAROLINA: 2 tweets, 193420.0 pixels\n",
      "      - NORTH DAKOTA: 1 tweets, 0.0 pixels\n",
      "      - OHIO: 1 tweets, 185026.0 pixels\n",
      "      - RHODE ISLAND: 1 tweets, 0.0 pixels\n",
      "      WARNING: State 'SC' not found in lookup\n",
      "      - SOUTH CAROLINA: 2 tweets, 118446.0 pixels\n",
      "      - VIRGINIA: 1 tweets, 163815.0 pixels\n",
      "      - WEST VIRGINIA: 2 tweets, 104748.0 pixels\n",
      "      Total state grid value: 38575500, Max pixel: 189\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 25 unique counties\n",
      "      - ABBEVILLE: 3 tweets × 3 = 9, 2066.0 pixels\n",
      "      - ATLANTIC: 4 tweets × 3 = 12, 0.0 pixels\n",
      "      - BENTON: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CABELL: 2 tweets × 3 = 6, 1323.0 pixels\n",
      "      - CHARLES CITY: 1 tweets × 3 = 3, 946.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 3 = 3, 2118.0 pixels\n",
      "      - CORTLAND: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CRAWFORD: 1 tweets × 3 = 3, 1414.0 pixels\n",
      "      - FLORIDA: 175 tweets × 3 = 525, 0.0 pixels\n",
      "      - GADSDEN: 1 tweets × 3 = 3, 1968.0 pixels\n",
      "      - GEORGE: 13 tweets × 3 = 39, 1825.0 pixels\n",
      "      - MACON: 1 tweets × 3 = 3, 3674.0 pixels\n",
      "      - MANATEE: 1 tweets × 3 = 3, 2833.0 pixels\n",
      "      - MIAMI: 4 tweets × 3 = 12, 1908.0 pixels\n",
      "      WARNING: County 'MIAMIDADE' not found in lookup\n",
      "      - OHIO: 1 tweets × 3 = 3, 2634.0 pixels\n",
      "      - PASCO: 1 tweets × 3 = 3, 2754.0 pixels\n",
      "      - PINELLAS: 4 tweets × 3 = 12, 1513.0 pixels\n",
      "      - ROCK ISLAND: 1 tweets × 3 = 3, 2220.0 pixels\n",
      "      - SAC: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      WARNING: County 'SAINT MARY' not found in lookup\n",
      "      - SARASOTA: 3 tweets × 3 = 9, 2125.0 pixels\n",
      "      - TAMA: 10 tweets × 3 = 30, 106.0 pixels\n",
      "      - TULSA: 1 tweets × 3 = 3, 2513.0 pixels\n",
      "      - VIRGINIA BEACH: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      Total county grid value: 230286, Max pixel: 39\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 53 unique cities\n",
      "      - ALLIGATOR: 2 tweets × 5 = 10, 9.0 pixels\n",
      "      - APALACHICOLA: 3 tweets × 5 = 15, 17.0 pixels\n",
      "      - ASHEVILLE: 3 tweets × 5 = 15, 293.0 pixels\n",
      "      - ATLANTA: 4 tweets × 5 = 20, 71.0 pixels\n",
      "      - BRADENTON: 1 tweets × 5 = 5, 104.0 pixels\n",
      "      - CARRABELLE: 2 tweets × 5 = 10, 39.0 pixels\n",
      "      - CHARLES CITY: 1 tweets × 5 = 5, 22.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - COOKE CITY: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - COOPER CITY: 1 tweets × 5 = 5, 42.0 pixels\n",
      "      - CRAWFORDVILLE: 1 tweets × 5 = 5, 22.0 pixels\n",
      "      - DEFUNIAK SPRINGS: 1 tweets × 5 = 5, 79.0 pixels\n",
      "      - FLORIDA: 175 tweets × 5 = 875, 6.0 pixels\n",
      "      - FLORIDA CITY: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - FORT WALTON BEACH: 1 tweets × 5 = 5, 56.0 pixels\n",
      "      - GADSDEN: 1 tweets × 5 = 5, 12.0 pixels\n",
      "      - GAY: 2 tweets × 5 = 10, 8.0 pixels\n",
      "      - GEORGIANA: 13 tweets × 5 = 65, 36.0 pixels\n",
      "      WARNING: City 'HINELLA' not found in projected lookup\n",
      "      - IVES ESTATES: 1 tweets × 5 = 5, 16.0 pixels\n",
      "      - KALAMA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - LAKE VILLAGE: 1 tweets × 5 = 5, 25.0 pixels\n",
      "      - LIBERTY CITY: 1 tweets × 5 = 5, 38.0 pixels\n",
      "      - MACON: 1 tweets × 5 = 5, 6.0 pixels\n",
      "      WARNING: City 'MACONBIBB COUNTY' not found in projected lookup\n",
      "      - MAGGIE VALLEY: 1 tweets × 5 = 5, 52.0 pixels\n",
      "      - MANTEE: 1 tweets × 5 = 5, 30.0 pixels\n",
      "      - MARCO ISLAND: 1 tweets × 5 = 5, 81.0 pixels\n",
      "      - MEMPHIS: 1 tweets × 5 = 5, 17.0 pixels\n",
      "      - MIAMI: 4 tweets × 5 = 20, 12.0 pixels\n",
      "      - MULBERRY: 1 tweets × 5 = 5, 14.0 pixels\n",
      "      - MYRTLE BEACH: 1 tweets × 5 = 5, 141.0 pixels\n",
      "      - NEW VIRGINIA: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - NORTH COLLINS: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - NORTH SARASOTA: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - OHIO: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - ORLANDO: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - PANACEA: 1 tweets × 5 = 5, 14.0 pixels\n",
      "      - PANAMA CITY: 1 tweets × 5 = 5, 221.0 pixels\n",
      "      - PASCO: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - PEACHTREE CITY: 1 tweets × 5 = 5, 129.0 pixels\n",
      "      - PORT RICHEY: 1 tweets × 5 = 5, 19.0 pixels\n",
      "      WARNING: City 'SAINT MARKS' not found in projected lookup\n",
      "      WARNING: City 'SAINT PETE BEACH' not found in projected lookup\n",
      "      - SALTON CITY: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - SARASOTA: 3 tweets × 5 = 15, 92.0 pixels\n",
      "      - SAVANNAH: 1 tweets × 5 = 5, 6.0 pixels\n",
      "      - SOUTH CARROLLTON: 2 tweets × 5 = 10, 5.0 pixels\n",
      "      - SURFSIDE: 1 tweets × 5 = 5, 6.0 pixels\n",
      "      - TALLAHASSEE: 20 tweets × 5 = 100, 518.0 pixels\n",
      "      - TAMPA: 10 tweets × 5 = 50, 4.0 pixels\n",
      "      - URSA: 1 tweets × 5 = 5, 12.0 pixels\n",
      "      - VIRGINIA: 1 tweets × 5 = 5, 3.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 3 unique facilities\n",
      "      - Bayshore Boulevard: 2 tweets × 10 = 20, KDE at (-9180541, 3240507)\n",
      "      - Volusia Mall: 1 tweets × 10 = 10, KDE at (-9023994, 3400729)\n",
      "      - the Don CeSar: 1 tweets × 10 = 10, KDE at (-9210272, 3212369)\n",
      "      Processed 3 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727366400.tif\n",
      "    Saved: helene_cumulative_1727366400.tif\n",
      "  Incremental max value: 876.00\n",
      "  Cumulative max value: 2816.00\n",
      "\n",
      "--- Time Bin 6/11: 1727380800 ---\n",
      "  Tweets in this bin: 100\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 12 unique states\n",
      "      WARNING: State 'AL' not found in lookup\n",
      "      - ALABAMA: 9 tweets, 191407.0 pixels\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 266 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 19 tweets, 217442.0 pixels\n",
      "      - KENTUCKY: 2 tweets, 168204.0 pixels\n",
      "      WARNING: State 'LA' not found in lookup\n",
      "      - MASSACHUSETTS: 1 tweets, 0.0 pixels\n",
      "      WARNING: State 'NC' not found in lookup\n",
      "      - NORTH CAROLINA: 3 tweets, 193420.0 pixels\n",
      "      - OHIO: 1 tweets, 185026.0 pixels\n",
      "      Total state grid value: 58950512, Max pixel: 294\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 26 unique counties\n",
      "      - ABBEVILLE: 2 tweets × 3 = 6, 2066.0 pixels\n",
      "      - ATLANTIC: 10 tweets × 3 = 30, 0.0 pixels\n",
      "      - BALTIMORE: 2 tweets × 3 = 6, 3011.0 pixels\n",
      "      - CHARLOTTE: 3 tweets × 3 = 9, 2118.0 pixels\n",
      "      - CLEARWATER: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CORTLAND: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CRAWFORD: 5 tweets × 3 = 15, 1414.0 pixels\n",
      "      - EVANS: 1 tweets × 3 = 3, 718.0 pixels\n",
      "      - FLORIDA: 266 tweets × 3 = 798, 0.0 pixels\n",
      "      - FRANKLIN: 1 tweets × 3 = 3, 53.0 pixels\n",
      "      - GEORGE: 19 tweets × 3 = 57, 1825.0 pixels\n",
      "      - GUILFORD: 1 tweets × 3 = 3, 2729.0 pixels\n",
      "      - HOT SPRINGS: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - LEXINGTON: 1 tweets × 3 = 3, 3026.0 pixels\n",
      "      - MIAMI: 5 tweets × 3 = 15, 1908.0 pixels\n",
      "      - OHIO: 1 tweets × 3 = 3, 2634.0 pixels\n",
      "      - OTTAWA: 1 tweets × 3 = 3, 2044.0 pixels\n",
      "      - PASCO: 1 tweets × 3 = 3, 2754.0 pixels\n",
      "      - PERRY: 2 tweets × 3 = 6, 1577.0 pixels\n",
      "      - PETERSBURG: 7 tweets × 3 = 21, 0.0 pixels\n",
      "      - PINELLAS: 6 tweets × 3 = 18, 1513.0 pixels\n",
      "      - RALEIGH: 2 tweets × 3 = 6, 2611.0 pixels\n",
      "      - SARASOTA: 2 tweets × 3 = 6, 2125.0 pixels\n",
      "      - SPARTANBURG: 2 tweets × 3 = 6, 3292.0 pixels\n",
      "      - TAMA: 32 tweets × 3 = 96, 106.0 pixels\n",
      "      - WAKULLA: 1 tweets × 3 = 3, 2365.0 pixels\n",
      "      Total county grid value: 347388, Max pixel: 96\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 52 unique cities\n",
      "      - ALLIGATOR: 1 tweets × 5 = 5, 9.0 pixels\n",
      "      - ALPHARETTA: 1 tweets × 5 = 5, 147.0 pixels\n",
      "      - ASHEVILLE: 4 tweets × 5 = 20, 293.0 pixels\n",
      "      - ATHOL: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - ATLANTA: 10 tweets × 5 = 50, 71.0 pixels\n",
      "      - BIG BEND: 4 tweets × 5 = 20, 0.0 pixels\n",
      "      - BILTMORE: 2 tweets × 5 = 10, 20.0 pixels\n",
      "      - CHARLOTTE: 2 tweets × 5 = 10, 13.0 pixels\n",
      "      - CLEARWATER: 1 tweets × 5 = 5, 28.0 pixels\n",
      "      - CRAWFORDVILLE: 5 tweets × 5 = 25, 22.0 pixels\n",
      "      - EVANS: 1 tweets × 5 = 5, 140.0 pixels\n",
      "      - FLAT: 4 tweets × 5 = 20, 12.0 pixels\n",
      "      - FLORIDA: 266 tweets × 5 = 1330, 6.0 pixels\n",
      "      - FORT MYERS BEACH: 1 tweets × 5 = 5, 30.0 pixels\n",
      "      - FRANKLIN CENTER: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - GAY: 5 tweets × 5 = 25, 8.0 pixels\n",
      "      - GEORGIANA: 19 tweets × 5 = 95, 36.0 pixels\n",
      "      - GREENSBORO: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - GULFPORT: 1 tweets × 5 = 5, 250.0 pixels\n",
      "      - HIGH SPRINGS: 2 tweets × 5 = 10, 122.0 pixels\n",
      "      - JACKSONVILLE: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - JENA: 5 tweets × 5 = 25, 35.0 pixels\n",
      "      - JENSEN BEACH: 1 tweets × 5 = 5, 42.0 pixels\n",
      "      - KALAMA: 9 tweets × 5 = 45, 0.0 pixels\n",
      "      - LAKE CITY: 1 tweets × 5 = 5, 11.0 pixels\n",
      "      - LEXINGTON: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - MADEIRA BEACH: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - MIAMI: 5 tweets × 5 = 25, 12.0 pixels\n",
      "      - MULBERRY: 1 tweets × 5 = 5, 14.0 pixels\n",
      "      - MYRTLE BEACH: 1 tweets × 5 = 5, 141.0 pixels\n",
      "      - NORTH COLLINS: 3 tweets × 5 = 15, 0.0 pixels\n",
      "      - NORTH PORT: 1 tweets × 5 = 5, 423.0 pixels\n",
      "      - OCALA: 2 tweets × 5 = 10, 235.0 pixels\n",
      "      - OHIO: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - ORLANDO: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - OTTAWA: 1 tweets × 5 = 5, 47.0 pixels\n",
      "      - PASCO: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - PERRY: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - PLANT CITY: 5 tweets × 5 = 25, 162.0 pixels\n",
      "      - PORT CHARLOTTE: 1 tweets × 5 = 5, 131.0 pixels\n",
      "      - PORT RICHEY: 2 tweets × 5 = 10, 19.0 pixels\n",
      "      - RALEIGH: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      WARNING: City 'SAINT PETERSBURG' not found in projected lookup\n",
      "      - SANDY SPRINGS: 1 tweets × 5 = 5, 24.0 pixels\n",
      "      - SARASOTA: 2 tweets × 5 = 10, 92.0 pixels\n",
      "      - SPARTANBURG: 2 tweets × 5 = 10, 123.0 pixels\n",
      "      - TALLAHASSEE: 30 tweets × 5 = 150, 518.0 pixels\n",
      "      - TAMPA: 32 tweets × 5 = 160, 4.0 pixels\n",
      "      - VERO BEACH: 2 tweets × 5 = 10, 68.0 pixels\n",
      "      - WAKULLA: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - WEBSTER COUNTY: 1 tweets × 5 = 5, 828.0 pixels\n",
      "      - WHITMORE VILLAGE: 2 tweets × 5 = 10, 0.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 10 unique facilities\n",
      "      - Bayshore Boulevard: 1 tweets × 10 = 10, KDE at (-9180541, 3240507)\n",
      "      - Bronson High School: 1 tweets × 10 = 10, KDE at (-9198240, 3435062)\n",
      "      - Buoy 42036: 2 tweets × 10 = 20, KDE at (-9804933, 4361859)\n",
      "      - DuPont State Recreational Forest: 1 tweets × 10 = 10, KDE at (-9195700, 4190827)\n",
      "      - Jacksonville International Airport: 1 tweets × 10 = 10, KDE at (-9094027, 3567176)\n",
      "      - Lido Key: 1 tweets × 10 = 10, KDE at (-9192929, 3163132)\n",
      "      - Matlacha Bridge: 1 tweets × 10 = 10, KDE at (-9135754, 3077645)\n",
      "      - Naples Botanical Garden: 1 tweets × 10 = 10, KDE at (-9102767, 3012202)\n",
      "      - Port Canaveral: 1 tweets × 10 = 10, KDE at (-8973278, 3300894)\n",
      "      - Yankee Clippers: 1 tweets × 10 = 10, KDE at (-9132236, 3957949)\n",
      "      Processed 10 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727380800.tif\n",
      "    Saved: helene_cumulative_1727380800.tif\n",
      "  Incremental max value: 1331.00\n",
      "  Cumulative max value: 4147.00\n",
      "\n",
      "--- Time Bin 7/11: 1727395200 ---\n",
      "  Tweets in this bin: 85\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 10 unique states\n",
      "      - ALABAMA: 2 tweets, 191407.0 pixels\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 301 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 18 tweets, 217442.0 pixels\n",
      "      WARNING: State 'LA' not found in lookup\n",
      "      WARNING: State 'NC' not found in lookup\n",
      "      - SOUTH CAROLINA: 4 tweets, 118446.0 pixels\n",
      "      - TENNESSEE: 2 tweets, 167994.0 pixels\n",
      "      - VIRGINIA: 1 tweets, 163815.0 pixels\n",
      "      Total state grid value: 64106528, Max pixel: 321\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 21 unique counties\n",
      "      - ABBEVILLE: 1 tweets × 3 = 3, 2066.0 pixels\n",
      "      - ATLANTIC: 5 tweets × 3 = 15, 0.0 pixels\n",
      "      - CABELL: 1 tweets × 3 = 3, 1323.0 pixels\n",
      "      - CARSON CITY: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CHARLESTON: 2 tweets × 3 = 6, 4174.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 3 = 3, 2118.0 pixels\n",
      "      - CLERMONT: 2 tweets × 3 = 6, 2107.0 pixels\n",
      "      - FLORIDA: 301 tweets × 3 = 903, 0.0 pixels\n",
      "      - GENESEE: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - GEORGE: 18 tweets × 3 = 54, 1825.0 pixels\n",
      "      - GIBSON: 1 tweets × 3 = 3, 2512.0 pixels\n",
      "      - HOT SPRINGS: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - JACKSON: 1 tweets × 3 = 3, 2988.0 pixels\n",
      "      - MIAMI: 5 tweets × 3 = 15, 1908.0 pixels\n",
      "      - MILWAUKEE: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - PERRY: 38 tweets × 3 = 114, 1577.0 pixels\n",
      "      - PETERSBURG: 4 tweets × 3 = 12, 0.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 2611.0 pixels\n",
      "      - SARASOTA: 1 tweets × 3 = 3, 2125.0 pixels\n",
      "      - TAMA: 14 tweets × 3 = 42, 106.0 pixels\n",
      "      - VIRGINIA BEACH: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      Total county grid value: 396315, Max pixel: 114\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 49 unique cities\n",
      "      - ALPHARETTA: 2 tweets × 5 = 10, 147.0 pixels\n",
      "      - APALACHICOLA: 2 tweets × 5 = 10, 17.0 pixels\n",
      "      - ASHEVILLE: 1 tweets × 5 = 5, 293.0 pixels\n",
      "      - ATLANTA: 5 tweets × 5 = 25, 71.0 pixels\n",
      "      - BONITA SPRINGS: 1 tweets × 5 = 5, 194.0 pixels\n",
      "      - BURKE CENTRE: 1 tweets × 5 = 5, 24.0 pixels\n",
      "      - CARRABELLE: 1 tweets × 5 = 5, 39.0 pixels\n",
      "      - CHARLESTON: 2 tweets × 5 = 10, 211.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - CLEMSON: 2 tweets × 5 = 10, 55.0 pixels\n",
      "      - CROSS CITY: 1 tweets × 5 = 5, 16.0 pixels\n",
      "      - DAYTONA BEACH: 6 tweets × 5 = 30, 303.0 pixels\n",
      "      - DEWEY BEACH: 4 tweets × 5 = 20, 0.0 pixels\n",
      "      - DORAL: 2 tweets × 5 = 10, 64.0 pixels\n",
      "      - FLAT: 1 tweets × 5 = 5, 12.0 pixels\n",
      "      - FLORIDA: 301 tweets × 5 = 1505, 6.0 pixels\n",
      "      - FORT MYERS: 2 tweets × 5 = 10, 195.0 pixels\n",
      "      - FORT MYERS BEACH: 8 tweets × 5 = 40, 30.0 pixels\n",
      "      - GAY: 4 tweets × 5 = 20, 8.0 pixels\n",
      "      - GEORGIANA: 18 tweets × 5 = 90, 36.0 pixels\n",
      "      - GIBSONTON: 1 tweets × 5 = 5, 67.0 pixels\n",
      "      - JACKSONVILLE: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - KALAMA: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - LAKE CITY: 1 tweets × 5 = 5, 11.0 pixels\n",
      "      - LEE MONT: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - MADEIRA BEACH: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - MIAMI: 5 tweets × 5 = 25, 12.0 pixels\n",
      "      - MILWAUKEE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - NASHVILLE: 1 tweets × 5 = 5, 2.0 pixels\n",
      "      - PANAMA CITY BEACH: 1 tweets × 5 = 5, 115.0 pixels\n",
      "      - PERRY: 38 tweets × 5 = 190, 0.0 pixels\n",
      "      - RALEIGH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      WARNING: City 'SAINT PETE BEACH' not found in projected lookup\n",
      "      WARNING: City 'SAINT PETERSBURG' not found in projected lookup\n",
      "      - SANDY SPRINGS: 1 tweets × 5 = 5, 24.0 pixels\n",
      "      - SARASOTA: 1 tweets × 5 = 5, 92.0 pixels\n",
      "      - SAVANNAH: 3 tweets × 5 = 15, 6.0 pixels\n",
      "      - SIESTA KEY: 1 tweets × 5 = 5, 20.0 pixels\n",
      "      - SOUTH CARROLLTON: 4 tweets × 5 = 20, 5.0 pixels\n",
      "      - STEINHATCHEE: 2 tweets × 5 = 10, 22.0 pixels\n",
      "      - TALLAHASSEE: 24 tweets × 5 = 120, 518.0 pixels\n",
      "      - TAMPA: 14 tweets × 5 = 70, 4.0 pixels\n",
      "      - TARPON SPRINGS: 1 tweets × 5 = 5, 62.0 pixels\n",
      "      - TENNESSEE: 2 tweets × 5 = 10, 8.0 pixels\n",
      "      - TITUSVILLE: 1 tweets × 5 = 5, 26.0 pixels\n",
      "      - VENICE: 2 tweets × 5 = 10, 8.0 pixels\n",
      "      - VIRGINIA: 1 tweets × 5 = 5, 3.0 pixels\n",
      "      - WEBSTER COUNTY: 1 tweets × 5 = 5, 828.0 pixels\n",
      "      - WOODVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 5 unique facilities\n",
      "      - 242A, 247: 1 tweets × 10 = 10, KDE at (-9202420, 3526538)\n",
      "      - Dean Park: 1 tweets × 10 = 10, KDE at (-9112455, 3079728)\n",
      "      - Doak Campbell Stadium: 2 tweets × 10 = 20, KDE at (-9384722, 3559995)\n",
      "      - Howard Frankland Bridge: 1 tweets × 10 = 10, KDE at (-9193573, 3239927)\n",
      "      - I-4: 5 tweets × 10 = 50, KDE at (-9164827, 3289065)\n",
      "      Processed 5 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727395200.tif\n",
      "    Saved: helene_cumulative_1727395200.tif\n",
      "  Incremental max value: 1505.00\n",
      "  Cumulative max value: 5652.00\n",
      "\n",
      "--- Time Bin 8/11: 1727409600 ---\n",
      "  Tweets in this bin: 107\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 12 unique states\n",
      "      - ARIZONA: 1 tweets, 0.0 pixels\n",
      "      - CALIFORNIA: 2 tweets, 0.0 pixels\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 319 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 62 tweets, 217442.0 pixels\n",
      "      - KENTUCKY: 1 tweets, 168204.0 pixels\n",
      "      WARNING: State 'LA' not found in lookup\n",
      "      - OHIO: 1 tweets, 185026.0 pixels\n",
      "      WARNING: State 'SC' not found in lookup\n",
      "      - SOUTH CAROLINA: 3 tweets, 118446.0 pixels\n",
      "      - TENNESSEE: 1 tweets, 167994.0 pixels\n",
      "      Total state grid value: 76712576, Max pixel: 381\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 27 unique counties\n",
      "      - ATLANTIC: 5 tweets × 3 = 15, 0.0 pixels\n",
      "      - AUGUSTA: 2 tweets × 3 = 6, 4305.0 pixels\n",
      "      - BEAUFORT: 2 tweets × 3 = 6, 3939.0 pixels\n",
      "      - BENTON: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CLEARWATER: 5 tweets × 3 = 15, 0.0 pixels\n",
      "      - DORCHESTER: 2 tweets × 3 = 6, 2293.0 pixels\n",
      "      - DUPLIN: 1 tweets × 3 = 3, 3271.0 pixels\n",
      "      - FLORIDA: 319 tweets × 3 = 957, 0.0 pixels\n",
      "      - GENESEE: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - GEORGE: 62 tweets × 3 = 186, 1825.0 pixels\n",
      "      - JACKSON: 1 tweets × 3 = 3, 2988.0 pixels\n",
      "      - JASPER: 4 tweets × 3 = 12, 3571.0 pixels\n",
      "      - MADISON: 3 tweets × 3 = 9, 2847.0 pixels\n",
      "      - MARION: 1 tweets × 3 = 3, 2034.0 pixels\n",
      "      - MIAMI: 2 tweets × 3 = 6, 1908.0 pixels\n",
      "      - MIDLAND: 4 tweets × 3 = 12, 3364.0 pixels\n",
      "      - OHIO: 1 tweets × 3 = 3, 2634.0 pixels\n",
      "      - PALM BEACH: 2 tweets × 3 = 6, 7383.0 pixels\n",
      "      - PERRY: 24 tweets × 3 = 72, 1577.0 pixels\n",
      "      - PETERSBURG: 4 tweets × 3 = 12, 0.0 pixels\n",
      "      - PINELLAS: 1 tweets × 3 = 3, 1513.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 2611.0 pixels\n",
      "      - SAC: 20 tweets × 3 = 60, 0.0 pixels\n",
      "      - SARASOTA: 2 tweets × 3 = 6, 2125.0 pixels\n",
      "      - SOUTHAMPTON: 1 tweets × 3 = 3, 2576.0 pixels\n",
      "      - TAMA: 22 tweets × 3 = 66, 106.0 pixels\n",
      "      - TULSA: 2 tweets × 3 = 6, 2513.0 pixels\n",
      "      Total county grid value: 768510, Max pixel: 186\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 53 unique cities\n",
      "      - ALMA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - APOLLO BEACH: 2 tweets × 5 = 10, 100.0 pixels\n",
      "      - ARION: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - ATLANTA: 5 tweets × 5 = 25, 71.0 pixels\n",
      "      - AUGUSTA: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - BEAUFORT: 2 tweets × 5 = 10, 205.0 pixels\n",
      "      - BIG BEND: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - BRADENTON: 1 tweets × 5 = 5, 104.0 pixels\n",
      "      - CALIFORNIA: 2 tweets × 5 = 10, 72.0 pixels\n",
      "      - CASTALIA: 1 tweets × 5 = 5, 9.0 pixels\n",
      "      - CLEARWATER: 5 tweets × 5 = 25, 28.0 pixels\n",
      "      - DANIA BEACH: 1 tweets × 5 = 5, 53.0 pixels\n",
      "      - DORCHESTER: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - DUBLIN: 1 tweets × 5 = 5, 15.0 pixels\n",
      "      - FLAT: 1 tweets × 5 = 5, 12.0 pixels\n",
      "      - FLORIDA: 319 tweets × 5 = 1595, 6.0 pixels\n",
      "      - FORT MYERS: 4 tweets × 5 = 20, 195.0 pixels\n",
      "      - FORT MYERS BEACH: 2 tweets × 5 = 10, 30.0 pixels\n",
      "      - GAY: 4 tweets × 5 = 20, 8.0 pixels\n",
      "      - GEORGIANA: 62 tweets × 5 = 310, 36.0 pixels\n",
      "      - IVES ESTATES: 2 tweets × 5 = 10, 16.0 pixels\n",
      "      - JACKSONVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - JASPER: 4 tweets × 5 = 20, 61.0 pixels\n",
      "      - JORDAN: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - LEE MONT: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - MADISON: 3 tweets × 5 = 15, 0.0 pixels\n",
      "      - MIAMI: 2 tweets × 5 = 10, 12.0 pixels\n",
      "      - OHIO: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - PALM HARBOR: 1 tweets × 5 = 5, 87.0 pixels\n",
      "      - PANACEA: 1 tweets × 5 = 5, 14.0 pixels\n",
      "      - PERRY: 24 tweets × 5 = 120, 0.0 pixels\n",
      "      - PETERSBURG: 1 tweets × 5 = 5, 19.0 pixels\n",
      "      - PORT RICHEY: 2 tweets × 5 = 10, 19.0 pixels\n",
      "      - RALEIGH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - RIDGELAND: 4 tweets × 5 = 20, 0.0 pixels\n",
      "      - ROCK HILL: 1 tweets × 5 = 5, 258.0 pixels\n",
      "      WARNING: City 'SAINT PETE BEACH' not found in projected lookup\n",
      "      WARNING: City 'SAINT PETERSBURG' not found in projected lookup\n",
      "      - SARASOTA: 2 tweets × 5 = 10, 92.0 pixels\n",
      "      - SAVANNAH: 1 tweets × 5 = 5, 6.0 pixels\n",
      "      - SOUTH CARROLLTON: 3 tweets × 5 = 15, 5.0 pixels\n",
      "      - SOUTHAMPTON: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - STEINHATCHEE: 1 tweets × 5 = 5, 22.0 pixels\n",
      "      - STONECREST: 1 tweets × 5 = 5, 186.0 pixels\n",
      "      - TABOR CITY: 1 tweets × 5 = 5, 30.0 pixels\n",
      "      - TALLAHASSEE: 11 tweets × 5 = 55, 518.0 pixels\n",
      "      - TAMPA: 21 tweets × 5 = 105, 4.0 pixels\n",
      "      - TENNESSEE: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - URSA: 2 tweets × 5 = 10, 12.0 pixels\n",
      "      - VALDOSTA: 8 tweets × 5 = 40, 201.0 pixels\n",
      "      - WALTERBORO: 2 tweets × 5 = 10, 61.0 pixels\n",
      "      - WEBSTER COUNTY: 2 tweets × 5 = 10, 828.0 pixels\n",
      "      - WILKESON: 1 tweets × 5 = 5, 0.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 15 unique facilities\n",
      "      - 10739 Bells Highway: 2 tweets × 10 = 20, KDE at (-8981612, 3885315)\n",
      "      - Byron Butler Pkwy: 1 tweets × 10 = 10, KDE at (-9303717, 3515353)\n",
      "      - Calf Pen Bay Road: 2 tweets × 10 = 20, KDE at (-9033572, 3842579)\n",
      "      - Carters Mill Road: 2 tweets × 10 = 20, KDE at (-9016686, 3826049)\n",
      "      - Deerfield Road: 2 tweets × 10 = 20, KDE at (-8881541, 4074355)\n",
      "      - Fort Moore/Columbus: 1 tweets × 10 = 10, KDE at (-9450569, 3817899)\n",
      "      - Freedom Parkway: 4 tweets × 10 = 40, KDE at (-9024535, 3791434)\n",
      "      - Georgia Aquarium: 1 tweets × 10 = 10, KDE at (-9394821, 3997059)\n",
      "      - I-4: 5 tweets × 10 = 50, KDE at (-9176064, 3244613)\n",
      "      - Sisters Ferry Road: 2 tweets × 10 = 20, KDE at (-9015044, 3826712)\n",
      "      - Smiths Xing: 2 tweets × 10 = 20, KDE at (-9013555, 3825200)\n",
      "      - US-21: 2 tweets × 10 = 20, KDE at (-8979369, 3815535)\n",
      "      - US15: 2 tweets × 10 = 20, KDE at (-8904239, 3875360)\n",
      "      - Venetian Isles: 1 tweets × 10 = 10, KDE at (-9194159, 3225907)\n",
      "      - the Blue Ridge Parkway: 1 tweets × 10 = 10, KDE at (-9182381, 4240996)\n",
      "      Processed 15 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727409600.tif\n",
      "    Saved: helene_cumulative_1727409600.tif\n",
      "  Incremental max value: 1596.00\n",
      "  Cumulative max value: 7248.00\n",
      "\n",
      "--- Time Bin 9/11: 1727424000 ---\n",
      "  Tweets in this bin: 88\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 12 unique states\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 260 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 114 tweets, 217442.0 pixels\n",
      "      - KENTUCKY: 1 tweets, 168204.0 pixels\n",
      "      WARNING: State 'NC' not found in lookup\n",
      "      - NORTH CAROLINA: 7 tweets, 193420.0 pixels\n",
      "      - OHIO: 2 tweets, 185026.0 pixels\n",
      "      WARNING: State 'SC' not found in lookup\n",
      "      - SOUTH CAROLINA: 3 tweets, 118446.0 pixels\n",
      "      - TENNESSEE: 1 tweets, 167994.0 pixels\n",
      "      - VIRGINIA: 3 tweets, 163815.0 pixels\n",
      "      Total state grid value: 78517296, Max pixel: 374\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 26 unique counties\n",
      "      - ABBEVILLE: 2 tweets × 3 = 6, 2066.0 pixels\n",
      "      - AMELIA: 1 tweets × 3 = 3, 1580.0 pixels\n",
      "      - ATLANTIC: 18 tweets × 3 = 54, 0.0 pixels\n",
      "      - AUGUSTA: 1 tweets × 3 = 3, 4305.0 pixels\n",
      "      - CHARLES CITY: 1 tweets × 3 = 3, 946.0 pixels\n",
      "      - CHARLESTON: 1 tweets × 3 = 3, 4174.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 3 = 3, 2118.0 pixels\n",
      "      - CLEARWATER: 3 tweets × 3 = 9, 0.0 pixels\n",
      "      - COLUMBIA: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CRAWFORD: 1 tweets × 3 = 3, 1414.0 pixels\n",
      "      - FLORIDA: 260 tweets × 3 = 780, 0.0 pixels\n",
      "      - GENESEE: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - GEORGE: 114 tweets × 3 = 342, 1825.0 pixels\n",
      "      - GREENVILLE: 1 tweets × 3 = 3, 3265.0 pixels\n",
      "      - HILLSBOROUGH: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - JACKSON: 1 tweets × 3 = 3, 2988.0 pixels\n",
      "      - MACON: 4 tweets × 3 = 12, 3674.0 pixels\n",
      "      - OCONTO: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - OHIO: 2 tweets × 3 = 6, 2634.0 pixels\n",
      "      - OVERTON: 1 tweets × 3 = 3, 1817.0 pixels\n",
      "      - PERRY: 7 tweets × 3 = 21, 1577.0 pixels\n",
      "      - PETERSBURG: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - SAC: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - TAMA: 12 tweets × 3 = 36, 106.0 pixels\n",
      "      - TULSA: 1 tweets × 3 = 3, 2513.0 pixels\n",
      "      - VIRGINIA BEACH: 3 tweets × 3 = 9, 0.0 pixels\n",
      "      Total county grid value: 808731, Max pixel: 342\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 43 unique cities\n",
      "      - AMERICUS: 1 tweets × 5 = 5, 9.0 pixels\n",
      "      - ASHEVILLE: 2 tweets × 5 = 10, 293.0 pixels\n",
      "      - ATLANTA: 18 tweets × 5 = 90, 71.0 pixels\n",
      "      - AUGUSTA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - BIG BEND: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - CHARLES CITY: 1 tweets × 5 = 5, 22.0 pixels\n",
      "      - CHARLESTON: 1 tweets × 5 = 5, 211.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - CLEARWATER: 3 tweets × 5 = 15, 28.0 pixels\n",
      "      - COLUMBIA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - CRAWFORDVILLE: 1 tweets × 5 = 5, 22.0 pixels\n",
      "      - DANIA BEACH: 1 tweets × 5 = 5, 53.0 pixels\n",
      "      - FLORIDA: 260 tweets × 5 = 1300, 6.0 pixels\n",
      "      - FORT MYERS: 2 tweets × 5 = 10, 195.0 pixels\n",
      "      - FORT MYERS BEACH: 2 tweets × 5 = 10, 30.0 pixels\n",
      "      - GAY: 3 tweets × 5 = 15, 8.0 pixels\n",
      "      - GEORGIANA: 114 tweets × 5 = 570, 36.0 pixels\n",
      "      - GREENVILLE: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - HILLSBOROUGH: 1 tweets × 5 = 5, 52.0 pixels\n",
      "      - JACKSONVILLE: 3 tweets × 5 = 15, 0.0 pixels\n",
      "      - LOUISVILLE: 2 tweets × 5 = 10, 101.0 pixels\n",
      "      - MACON: 4 tweets × 5 = 20, 6.0 pixels\n",
      "      - MADEIRA BEACH: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - NORTH COLLINS: 7 tweets × 5 = 35, 0.0 pixels\n",
      "      - OHIO: 2 tweets × 5 = 10, 8.0 pixels\n",
      "      - PALM BAY: 1 tweets × 5 = 5, 366.0 pixels\n",
      "      - PERRY: 7 tweets × 5 = 35, 0.0 pixels\n",
      "      - PORT RICHEY: 2 tweets × 5 = 10, 19.0 pixels\n",
      "      - ROCK HILL: 1 tweets × 5 = 5, 258.0 pixels\n",
      "      - RUSSELLS POINT: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      WARNING: City 'SAINT PETE BEACH' not found in projected lookup\n",
      "      WARNING: City 'SAINT PETERSBURG' not found in projected lookup\n",
      "      - SAVANNAH: 1 tweets × 5 = 5, 6.0 pixels\n",
      "      - SOPERTON: 1 tweets × 5 = 5, 35.0 pixels\n",
      "      - SOUTH CARROLLTON: 3 tweets × 5 = 15, 5.0 pixels\n",
      "      - STEINHATCHEE: 1 tweets × 5 = 5, 22.0 pixels\n",
      "      - TALLAHASSEE: 5 tweets × 5 = 25, 518.0 pixels\n",
      "      - TAMPA: 12 tweets × 5 = 60, 4.0 pixels\n",
      "      - TENNESSEE: 1 tweets × 5 = 5, 8.0 pixels\n",
      "      - TORONTO: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - URSA: 1 tweets × 5 = 5, 12.0 pixels\n",
      "      - VALDOSTA: 2 tweets × 5 = 10, 201.0 pixels\n",
      "      - VIRGINIA: 3 tweets × 5 = 15, 3.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 7 unique facilities\n",
      "      - Bayshore Boulevard: 1 tweets × 10 = 10, KDE at (-9180541, 3240507)\n",
      "      - Capitol: 1 tweets × 10 = 10, KDE at (-9394048, 3995156)\n",
      "      - Dean Park: 1 tweets × 10 = 10, KDE at (-9112455, 3079728)\n",
      "      - Hartsfield-Jackson: 1 tweets × 10 = 10, KDE at (-9398684, 3980217)\n",
      "      - I-10: 1 tweets × 10 = 10, KDE at (-9112368, 3543247)\n",
      "      - I-4: 2 tweets × 10 = 20, KDE at (-9179232, 3242389)\n",
      "      - Town & Country: 1 tweets × 10 = 10, KDE at (-9193177, 3251041)\n",
      "      Processed 7 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727424000.tif\n",
      "    Saved: helene_cumulative_1727424000.tif\n",
      "  Incremental max value: 1302.00\n",
      "  Cumulative max value: 8550.00\n",
      "\n",
      "--- Time Bin 10/11: 1727438400 ---\n",
      "  Tweets in this bin: 111\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 15 unique states\n",
      "      - ALABAMA: 2 tweets, 191407.0 pixels\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 201 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 36 tweets, 217442.0 pixels\n",
      "      - KENTUCKY: 3 tweets, 168204.0 pixels\n",
      "      WARNING: State 'KY' not found in lookup\n",
      "      WARNING: State 'NC' not found in lookup\n",
      "      - NORTH CAROLINA: 13 tweets, 193420.0 pixels\n",
      "      WARNING: State 'NY' not found in lookup\n",
      "      - OHIO: 3 tweets, 185026.0 pixels\n",
      "      WARNING: State 'SC' not found in lookup\n",
      "      - SOUTH CAROLINA: 1 tweets, 118446.0 pixels\n",
      "      WARNING: State 'TN' not found in lookup\n",
      "      - VIRGINIA: 2 tweets, 163815.0 pixels\n",
      "      Total state grid value: 51520224, Max pixel: 239\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 30 unique counties\n",
      "      - ALBANY: 1 tweets × 3 = 3, 13365.0 pixels\n",
      "      - ATLANTIC: 17 tweets × 3 = 51, 0.0 pixels\n",
      "      - AUGUSTA: 2 tweets × 3 = 6, 4305.0 pixels\n",
      "      - BENTON: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CLERMONT: 1 tweets × 3 = 3, 2107.0 pixels\n",
      "      - CLEVELAND: 1 tweets × 3 = 3, 2237.0 pixels\n",
      "      - COLUMBIA: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - CORTLAND: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - FALL RIVER: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - FLORIDA: 201 tweets × 3 = 603, 0.0 pixels\n",
      "      - GEORGE: 36 tweets × 3 = 108, 1825.0 pixels\n",
      "      - GEORGETOWN: 1 tweets × 3 = 3, 3421.0 pixels\n",
      "      - HASKELL: 1 tweets × 3 = 3, 3485.0 pixels\n",
      "      - HILLSBOROUGH: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - KAY: 1 tweets × 3 = 3, 3969.0 pixels\n",
      "      - MADISON: 2 tweets × 3 = 6, 2847.0 pixels\n",
      "      - MANATEE: 1 tweets × 3 = 3, 2833.0 pixels\n",
      "      - MECKLENBURG: 1 tweets × 3 = 3, 2234.0 pixels\n",
      "      - MIAMI: 4 tweets × 3 = 12, 1908.0 pixels\n",
      "      - OAKLAND: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - OHIO: 3 tweets × 3 = 9, 2634.0 pixels\n",
      "      - PERRY: 13 tweets × 3 = 39, 1577.0 pixels\n",
      "      - PETERSBURG: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - PINELLAS: 1 tweets × 3 = 3, 1513.0 pixels\n",
      "      - RUTHERFORD: 1 tweets × 3 = 3, 2608.0 pixels\n",
      "      - SAC: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - SANPETE: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - SARASOTA: 2 tweets × 3 = 6, 2125.0 pixels\n",
      "      - TAMA: 11 tweets × 3 = 33, 106.0 pixels\n",
      "      - VIRGINIA BEACH: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      Total county grid value: 477681, Max pixel: 108\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 54 unique cities\n",
      "      - ALBANY: 1 tweets × 5 = 5, 71.0 pixels\n",
      "      - APPALACHIA: 1 tweets × 5 = 5, 20.0 pixels\n",
      "      - ATLANTA: 17 tweets × 5 = 85, 71.0 pixels\n",
      "      - AUGUSTA: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - BIG BEND: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - BRADENTON: 1 tweets × 5 = 5, 104.0 pixels\n",
      "      - CLEMSON: 1 tweets × 5 = 5, 55.0 pixels\n",
      "      - COLUMBIA: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - FLORIDA: 201 tweets × 5 = 1005, 6.0 pixels\n",
      "      - FORT MYERS: 2 tweets × 5 = 10, 195.0 pixels\n",
      "      - GAY: 3 tweets × 5 = 15, 8.0 pixels\n",
      "      - GEORGETOWN: 1 tweets × 5 = 5, 359.0 pixels\n",
      "      - GEORGIANA: 36 tweets × 5 = 180, 36.0 pixels\n",
      "      - GUNTERSVILLE: 1 tweets × 5 = 5, 268.0 pixels\n",
      "      - HARTSELLE: 1 tweets × 5 = 5, 109.0 pixels\n",
      "      - HELEN: 2 tweets × 5 = 10, 6.0 pixels\n",
      "      - HILLSBOROUGH: 1 tweets × 5 = 5, 52.0 pixels\n",
      "      - HILTON HEAD ISLAND: 2 tweets × 5 = 10, 197.0 pixels\n",
      "      - JACKSONVILLE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - KALAMA: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - LAKELAND: 1 tweets × 5 = 5, 123.0 pixels\n",
      "      - LECANTO: 1 tweets × 5 = 5, 128.0 pixels\n",
      "      - LELAND: 1 tweets × 5 = 5, 146.0 pixels\n",
      "      - LINGANORE: 1 tweets × 5 = 5, 63.0 pixels\n",
      "      - LOUISVILLE: 1 tweets × 5 = 5, 101.0 pixels\n",
      "      - MADISON: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - MANTEE: 1 tweets × 5 = 5, 30.0 pixels\n",
      "      - MARSHALLTON: 1 tweets × 5 = 5, 11.0 pixels\n",
      "      - MIAMI: 4 tweets × 5 = 20, 12.0 pixels\n",
      "      - MILLS RIVER: 1 tweets × 5 = 5, 129.0 pixels\n",
      "      - MYRTLE BEACH: 1 tweets × 5 = 5, 141.0 pixels\n",
      "      - NASHVILLE: 1 tweets × 5 = 5, 2.0 pixels\n",
      "      - NORTH COLLINS: 13 tweets × 5 = 65, 0.0 pixels\n",
      "      - NYACK: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - OHIO: 3 tweets × 5 = 15, 8.0 pixels\n",
      "      - ORLANDO: 2 tweets × 5 = 10, 13.0 pixels\n",
      "      - PALM BAY: 1 tweets × 5 = 5, 366.0 pixels\n",
      "      - PASADENA: 1 tweets × 5 = 5, 244.0 pixels\n",
      "      - PERRY: 13 tweets × 5 = 65, 0.0 pixels\n",
      "      - RUTHERFORDTON: 1 tweets × 5 = 5, 40.0 pixels\n",
      "      WARNING: City 'SAINT PETE BEACH' not found in projected lookup\n",
      "      WARNING: City 'SAINT PETER' not found in projected lookup\n",
      "      WARNING: City 'SAINT PETERSBURG' not found in projected lookup\n",
      "      - SALTON CITY: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - SARASOTA: 2 tweets × 5 = 10, 92.0 pixels\n",
      "      - SAVANNAH: 1 tweets × 5 = 5, 6.0 pixels\n",
      "      - SHELL POINT: 1 tweets × 5 = 5, 34.0 pixels\n",
      "      - SOUTH CARROLLTON: 1 tweets × 5 = 5, 5.0 pixels\n",
      "      - STEINHATCHEE: 1 tweets × 5 = 5, 22.0 pixels\n",
      "      - TALLAHASSEE: 6 tweets × 5 = 30, 518.0 pixels\n",
      "      - TAMPA: 11 tweets × 5 = 55, 4.0 pixels\n",
      "      - TARPON SPRINGS: 1 tweets × 5 = 5, 62.0 pixels\n",
      "      - VALDOSTA: 1 tweets × 5 = 5, 201.0 pixels\n",
      "      - VIRGINIA: 2 tweets × 5 = 10, 3.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 12 unique facilities\n",
      "      - Abraham Lincoln Birthplace National Historical Park: 1 tweets × 10 = 10, KDE at (-9533710, 4524728)\n",
      "      - Amalie Arena: 3 tweets × 10 = 30, KDE at (-9178502, 3241752)\n",
      "      - Bayshore Drive: 1 tweets × 10 = 10, KDE at (-9182939, 3232957)\n",
      "      - Busch Gardens: 1 tweets × 10 = 10, KDE at (-9175093, 3253650)\n",
      "      - Greenbrier Resort: 1 tweets × 10 = 10, KDE at (-9301588, 4278100)\n",
      "      - I-4: 1 tweets × 10 = 10, KDE at (-9176064, 3244613)\n",
      "      - Midnight Pass: 1 tweets × 10 = 10, KDE at (-9185159, 3149466)\n",
      "      - ST. PETE BEACH: 1 tweets × 10 = 10, KDE at (-9210710, 3214385)\n",
      "      - Steeple Club: 1 tweets × 10 = 10, KDE at (-9381305, 3564197)\n",
      "      - Tradition Hall: 1 tweets × 10 = 10, KDE at (-8796000, 4002137)\n",
      "      - US 431: 1 tweets × 10 = 10, KDE at (-9601747, 4068260)\n",
      "      - the Memphis International Airport: 1 tweets × 10 = 10, KDE at (-10016182, 4170169)\n",
      "      Processed 12 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727438400.tif\n",
      "    Saved: helene_cumulative_1727438400.tif\n",
      "  Incremental max value: 1008.00\n",
      "  Cumulative max value: 9558.00\n",
      "\n",
      "--- Time Bin 11/11: 1727452800 ---\n",
      "  Tweets in this bin: 115\n",
      "    [STATE] Creating state raster...\n",
      "      Processing 14 unique states\n",
      "      WARNING: State 'AL' not found in lookup\n",
      "      WARNING: State 'FL' not found in lookup\n",
      "      - FLORIDA: 109 tweets, 195469.0 pixels\n",
      "      WARNING: State 'GA' not found in lookup\n",
      "      - GEORGIA: 50 tweets, 217442.0 pixels\n",
      "      WARNING: State 'NC' not found in lookup\n",
      "      - NORTH CAROLINA: 20 tweets, 193420.0 pixels\n",
      "      - OHIO: 5 tweets, 185026.0 pixels\n",
      "      WARNING: State 'PA' not found in lookup\n",
      "      WARNING: State 'SC' not found in lookup\n",
      "      - SOUTH CAROLINA: 14 tweets, 118446.0 pixels\n",
      "      - TENNESSEE: 7 tweets, 167994.0 pixels\n",
      "      WARNING: State 'TN' not found in lookup\n",
      "      - VIRGINIA: 2 tweets, 163815.0 pixels\n",
      "      Total state grid value: 40133584, Max pixel: 159\n",
      "    [COUNTY] Creating county raster...\n",
      "      Processing 36 unique counties\n",
      "      - ABBEVILLE: 4 tweets × 3 = 12, 2066.0 pixels\n",
      "      - ATHENS: 1 tweets × 3 = 3, 2286.0 pixels\n",
      "      - ATLANTIC: 10 tweets × 3 = 30, 0.0 pixels\n",
      "      - AUGUSTA: 1 tweets × 3 = 3, 4305.0 pixels\n",
      "      - CAROLINA: 8 tweets × 3 = 24, 0.0 pixels\n",
      "      - CHARLOTTE: 1 tweets × 3 = 3, 2118.0 pixels\n",
      "      - CHRISTIAN: 1 tweets × 3 = 3, 2363.0 pixels\n",
      "      - CLEARWATER: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      - CLEVELAND: 1 tweets × 3 = 3, 2237.0 pixels\n",
      "      - COLUMBUS: 1 tweets × 3 = 3, 3832.0 pixels\n",
      "      - CORTLAND: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - DUNDY: 1 tweets × 3 = 3, 4235.0 pixels\n",
      "      - FLORIDA: 109 tweets × 3 = 327, 0.0 pixels\n",
      "      - GENESEE: 7 tweets × 3 = 21, 0.0 pixels\n",
      "      - GEORGE: 50 tweets × 3 = 150, 1825.0 pixels\n",
      "      - GREENVILLE: 2 tweets × 3 = 6, 3265.0 pixels\n",
      "      - GUILFORD: 1 tweets × 3 = 3, 2729.0 pixels\n",
      "      - HAMBLEN: 1 tweets × 3 = 3, 828.0 pixels\n",
      "      - HILLSBOROUGH: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - HOT SPRINGS: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - IRWIN: 2 tweets × 3 = 6, 1333.0 pixels\n",
      "      - LAUDERDALE: 1 tweets × 3 = 3, 2961.0 pixels\n",
      "      - LEE: 1 tweets × 3 = 3, 1822.0 pixels\n",
      "      - MECKLENBURG: 1 tweets × 3 = 3, 2234.0 pixels\n",
      "      - NEWPORT: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - NEWPORT NEWS: 1 tweets × 3 = 3, 545.0 pixels\n",
      "      - OHIO: 5 tweets × 3 = 15, 2634.0 pixels\n",
      "      - PERRY: 1 tweets × 3 = 3, 1577.0 pixels\n",
      "      - PETERSBURG: 3 tweets × 3 = 9, 0.0 pixels\n",
      "      - PINELLAS: 1 tweets × 3 = 3, 1513.0 pixels\n",
      "      - RALEIGH: 1 tweets × 3 = 3, 2611.0 pixels\n",
      "      - SAC: 1 tweets × 3 = 3, 0.0 pixels\n",
      "      - SARASOTA: 2 tweets × 3 = 6, 2125.0 pixels\n",
      "      - SUWANNEE: 1 tweets × 3 = 3, 2559.0 pixels\n",
      "      - TAMA: 9 tweets × 3 = 27, 106.0 pixels\n",
      "      - VIRGINIA BEACH: 2 tweets × 3 = 6, 0.0 pixels\n",
      "      Total county grid value: 503517, Max pixel: 150\n",
      "    [CITY] Creating city raster...\n",
      "      Processing 57 unique cities\n",
      "      - ASHEVILLE: 4 tweets × 5 = 20, 293.0 pixels\n",
      "      - ATHENS: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - ATHOL: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - ATLANTA: 10 tweets × 5 = 50, 71.0 pixels\n",
      "      - AUGUSTA: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - BLACKSBURG: 1 tweets × 5 = 5, 113.0 pixels\n",
      "      - BLACKSHEAR: 1 tweets × 5 = 5, 56.0 pixels\n",
      "      - BLUFFTON: 1 tweets × 5 = 5, 278.0 pixels\n",
      "      - BONITA SPRINGS: 1 tweets × 5 = 5, 194.0 pixels\n",
      "      - BUCKHEAD: 2 tweets × 5 = 10, 8.0 pixels\n",
      "      - CAROLINA: 8 tweets × 5 = 40, 10.0 pixels\n",
      "      - CHAMBLEE: 1 tweets × 5 = 5, 47.0 pixels\n",
      "      - CHRISTIANSBURG: 1 tweets × 5 = 5, 90.0 pixels\n",
      "      - CINCINNATI: 1 tweets × 5 = 5, 475.0 pixels\n",
      "      - CLEARWATER: 2 tweets × 5 = 10, 28.0 pixels\n",
      "      - CLEVELAND: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - COLUMBUS: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - DAYTONA BEACH: 4 tweets × 5 = 20, 303.0 pixels\n",
      "      - DUNWOODY: 1 tweets × 5 = 5, 65.0 pixels\n",
      "      - ERWIN: 2 tweets × 5 = 10, 35.0 pixels\n",
      "      - FLORIDA: 109 tweets × 5 = 545, 6.0 pixels\n",
      "      - FORT LAUDERDALE: 1 tweets × 5 = 5, 167.0 pixels\n",
      "      - GAY: 5 tweets × 5 = 25, 8.0 pixels\n",
      "      - GEORGIANA: 50 tweets × 5 = 250, 36.0 pixels\n",
      "      - GREENVILLE: 2 tweets × 5 = 10, 4.0 pixels\n",
      "      - GULFPORT: 1 tweets × 5 = 5, 250.0 pixels\n",
      "      - HILLSBOROUGH: 1 tweets × 5 = 5, 52.0 pixels\n",
      "      - HILTON HEAD ISLAND: 1 tweets × 5 = 5, 197.0 pixels\n",
      "      WARNING: City 'HINELLA' not found in projected lookup\n",
      "      - IVES ESTATES: 1 tweets × 5 = 5, 16.0 pixels\n",
      "      - JONESBOROUGH: 1 tweets × 5 = 5, 42.0 pixels\n",
      "      - LEE: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - METTER: 1 tweets × 5 = 5, 46.0 pixels\n",
      "      - NEWPORT: 2 tweets × 5 = 10, 0.0 pixels\n",
      "      - NORTH COLLINS: 20 tweets × 5 = 100, 0.0 pixels\n",
      "      - OHIO: 5 tweets × 5 = 25, 8.0 pixels\n",
      "      - ORLANDO: 1 tweets × 5 = 5, 13.0 pixels\n",
      "      - PALM BAY: 1 tweets × 5 = 5, 366.0 pixels\n",
      "      - PERRY: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - PORT CHARLOTTE: 1 tweets × 5 = 5, 131.0 pixels\n",
      "      - RALEIGH: 1 tweets × 5 = 5, 4.0 pixels\n",
      "      - RUTHERFORDTON: 2 tweets × 5 = 10, 40.0 pixels\n",
      "      WARNING: City 'SAINT PETE BEACH' not found in projected lookup\n",
      "      WARNING: City 'SAINT PETERSBURG' not found in projected lookup\n",
      "      - SARASOTA: 2 tweets × 5 = 10, 92.0 pixels\n",
      "      - SOUTH CARROLLTON: 13 tweets × 5 = 65, 5.0 pixels\n",
      "      - SOUTH PASADENA: 3 tweets × 5 = 15, 9.0 pixels\n",
      "      - STATESBORO: 1 tweets × 5 = 5, 94.0 pixels\n",
      "      - STEINHATCHEE: 2 tweets × 5 = 10, 22.0 pixels\n",
      "      - SUWANEE: 1 tweets × 5 = 5, 71.0 pixels\n",
      "      - TALLAHASSEE: 6 tweets × 5 = 30, 518.0 pixels\n",
      "      - TAMPA: 9 tweets × 5 = 45, 4.0 pixels\n",
      "      - TENINO: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - TENNESSEE: 7 tweets × 5 = 35, 8.0 pixels\n",
      "      - TOPAZ: 1 tweets × 5 = 5, 0.0 pixels\n",
      "      - VIRGINIA: 2 tweets × 5 = 10, 3.0 pixels\n",
      "      - WEBSTER COUNTY: 2 tweets × 5 = 10, 828.0 pixels\n",
      "    [FACILITY] Creating facility raster...\n",
      "      Processing 8 unique facilities\n",
      "      - Amalie Arena: 1 tweets × 10 = 10, KDE at (-9178502, 3241752)\n",
      "      - Bayshore Boulevard: 1 tweets × 10 = 10, KDE at (-9180541, 3240507)\n",
      "      - I-40: 1 tweets × 10 = 10, KDE at (-9678056, 4313198)\n",
      "      - Lake Lure Dam: 2 tweets × 10 = 20, KDE at (-9148680, 4221901)\n",
      "      - Midnight Pass: 1 tweets × 10 = 10, KDE at (-9185159, 3149466)\n",
      "      - Pass-A-Grille Beach: 1 tweets × 10 = 10, KDE at (-9210518, 3212923)\n",
      "      - Sarasota - Beach Road: 1 tweets × 10 = 10, KDE at (-9178151, 3133363)\n",
      "      - St. Armand’s Circle: 1 tweets × 10 = 10, KDE at (-9192451, 3163312)\n",
      "      Processed 8 facilities with sigma=2.00 pixels\n",
      "    Saved: helene_increment_1727452800.tif\n",
      "    Saved: helene_cumulative_1727452800.tif\n",
      "  Incremental max value: 550.00\n",
      "  Cumulative max value: 10108.00\n",
      "\n",
      "HELENE processing complete!\n",
      "Output saved to: C:\\Users\\clgoodr2\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\n",
      "\n",
      "============================================================\n",
      "ALL PROCESSING COMPLETE! ✓\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T18:52:38.238718Z",
     "start_time": "2025-09-22T18:52:37.569978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# STEP 5: POST-PROCESSING & ASSEMBLY\n",
    "# ==============================================================================\n",
    "\n",
    "def create_metadata_index(hurricane_name, hurricane_dir):\n",
    "    \"\"\"Create CSV index of all rasters with metadata\"\"\"\n",
    "    print(f\"\\nCreating metadata index for {hurricane_name}...\")\n",
    "\n",
    "    # Get all increment and cumulative TIFFs\n",
    "    increment_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\")))\n",
    "    cumulative_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_cumulative_*.tif\")))\n",
    "\n",
    "    metadata_rows = []\n",
    "\n",
    "    for tif_path in increment_files + cumulative_files:\n",
    "        filename = os.path.basename(tif_path)\n",
    "\n",
    "        # Extract time and type from filename\n",
    "        parts = filename.replace('.tif', '').split('_')\n",
    "        raster_type = parts[-2]  # 'increment' or 'cumulative'\n",
    "        time_str = parts[-1]     # e.g., '20240910_0000'\n",
    "\n",
    "        # Open raster to get stats\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            data = src.read(1)\n",
    "\n",
    "            metadata_rows.append({\n",
    "                'filename': filename,\n",
    "                'type': raster_type,\n",
    "                'time_str': time_str,\n",
    "                'min_value': np.min(data),\n",
    "                'max_value': np.max(data),\n",
    "                'mean_value': np.mean(data),\n",
    "                'total_value': np.sum(data),\n",
    "                'non_zero_pixels': np.count_nonzero(data)\n",
    "            })\n",
    "\n",
    "    # Create DataFrame and save\n",
    "    metadata_df = pd.DataFrame(metadata_rows)\n",
    "    index_path = os.path.join(hurricane_dir, f\"{hurricane_name}_index.csv\")\n",
    "    metadata_df.to_csv(index_path, index=False)\n",
    "\n",
    "    print(f\"  Index saved: {index_path}\")\n",
    "    print(f\"  Total rasters cataloged: {len(metadata_rows)}\")\n",
    "\n",
    "    return metadata_df\n",
    "\n",
    "\n",
    "def create_vrt_stacks(hurricane_name, hurricane_dir):\n",
    "    \"\"\"Create VRT files using rasterio (no GDAL needed)\"\"\"\n",
    "    print(f\"\\nCreating VRT stacks for {hurricane_name}...\")\n",
    "\n",
    "    # Simply skip VRT creation or create a text-based reference file\n",
    "    increment_files = sorted(glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\")))\n",
    "\n",
    "    # Create a simple text list file instead\n",
    "    list_file = os.path.join(hurricane_dir, f\"{hurricane_name}_increment_files.txt\")\n",
    "    with open(list_file, 'w') as f:\n",
    "        for file in increment_files:\n",
    "            f.write(file + '\\n')\n",
    "\n",
    "    print(f\"  Created file list: {hurricane_name}_increment_files.txt\")\n",
    "    print(f\"  Import these files directly in ArcGIS Pro\")\n",
    "\n",
    "def print_summary_stats(hurricane_name, hurricane_dir):\n",
    "    \"\"\"Print summary statistics for the hurricane dataset\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUMMARY: {hurricane_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    increment_files = glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_increment_*.tif\"))\n",
    "    cumulative_files = glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_cumulative_*.tif\"))\n",
    "\n",
    "    print(f\"  Total time slices: {len(increment_files)}\")\n",
    "    print(f\"  Increment rasters: {len(increment_files)}\")\n",
    "    print(f\"  Cumulative rasters: {len(cumulative_files)}\")\n",
    "    print(f\"  Output directory: {hurricane_dir}\")\n",
    "\n",
    "    # Get final cumulative stats\n",
    "    if cumulative_files:\n",
    "        final_cumulative = sorted(cumulative_files)[-1]\n",
    "        with rasterio.open(final_cumulative) as src:\n",
    "            final_data = src.read(1)\n",
    "            print(f\"\\n  Final Cumulative Statistics:\")\n",
    "            print(f\"    Total value: {np.sum(final_data):,.0f}\")\n",
    "            print(f\"    Max pixel value: {np.max(final_data):,.2f}\")\n",
    "            print(f\"    Active pixels: {np.count_nonzero(final_data):,}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# RUN POST-PROCESSING\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: POST-PROCESSING & ASSEMBLY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Process Francine\n",
    "francine_dir = os.path.join(output_dir, 'francine')\n",
    "if os.path.exists(francine_dir):\n",
    "    francine_metadata = create_metadata_index('francine', francine_dir)\n",
    "    create_vrt_stacks('francine', francine_dir)\n",
    "    print_summary_stats('francine', francine_dir)\n",
    "\n",
    "# Process Helene\n",
    "helene_dir = os.path.join(output_dir, 'helene')\n",
    "if os.path.exists(helene_dir):\n",
    "    helene_metadata = create_metadata_index('helene', helene_dir)\n",
    "    create_vrt_stacks('helene', helene_dir)\n",
    "    print_summary_stats('helene', helene_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POST-PROCESSING COMPLETE! ✓\")\n"
   ],
   "id": "20a24d59822d8736",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 5: POST-PROCESSING & ASSEMBLY\n",
      "============================================================\n",
      "\n",
      "Creating metadata index for francine...\n",
      "  Index saved: C:\\Users\\clgoodr2\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\\francine_index.csv\n",
      "  Total rasters cataloged: 0\n",
      "\n",
      "Creating VRT stacks for francine...\n",
      "  Created file list: francine_increment_files.txt\n",
      "  Import these files directly in ArcGIS Pro\n",
      "\n",
      "============================================================\n",
      "SUMMARY: FRANCINE\n",
      "============================================================\n",
      "  Total time slices: 0\n",
      "  Increment rasters: 0\n",
      "  Cumulative rasters: 0\n",
      "  Output directory: C:\\Users\\clgoodr2\\Documents\\GitHub\\Tweet_project\\rasters_output\\francine\n",
      "\n",
      "Creating metadata index for helene...\n",
      "  Index saved: C:\\Users\\clgoodr2\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\\helene_index.csv\n",
      "  Total rasters cataloged: 22\n",
      "\n",
      "Creating VRT stacks for helene...\n",
      "  Created file list: helene_increment_files.txt\n",
      "  Import these files directly in ArcGIS Pro\n",
      "\n",
      "============================================================\n",
      "SUMMARY: HELENE\n",
      "============================================================\n",
      "  Total time slices: 11\n",
      "  Increment rasters: 11\n",
      "  Cumulative rasters: 11\n",
      "  Output directory: C:\\Users\\clgoodr2\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\n",
      "\n",
      "  Final Cumulative Statistics:\n",
      "    Total value: 500,936,832\n",
      "    Max pixel value: 10,108.00\n",
      "    Active pixels: 2,383,114\n",
      "\n",
      "============================================================\n",
      "POST-PROCESSING COMPLETE! ✓\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T18:52:38.254056Z",
     "start_time": "2025-09-22T18:52:38.243431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PLACE THIS CODE AFTER YOUR RASTER GENERATION IS COMPLETE\n",
    "# =============================================================================\n",
    "# HEATMAP POST-PROCESSING AND STYLING\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from rasterio.plot import show\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def apply_heatmap_smoothing(input_raster_path, output_raster_path, sigma_multiplier=2.0):\n",
    "    \"\"\"\n",
    "    Apply gaussian smoothing to create heatmap effect\n",
    "\n",
    "    Parameters:\n",
    "    - sigma_multiplier: Controls smoothing intensity (higher = more blur)\n",
    "    \"\"\"\n",
    "    with rasterio.open(input_raster_path) as src:\n",
    "        data = src.read(1).astype(np.float32)\n",
    "        profile = src.profile.copy()\n",
    "\n",
    "        # Apply gaussian filter for heatmap smoothing\n",
    "        # Sigma is relative to cell size for consistent smoothing\n",
    "        sigma = sigma_multiplier  # pixels\n",
    "        smoothed_data = gaussian_filter(data, sigma=sigma, mode='constant', cval=0)\n",
    "\n",
    "        # Ensure no negative values\n",
    "        smoothed_data = np.maximum(smoothed_data, 0)\n",
    "\n",
    "        # Update profile for output\n",
    "        profile.update(dtype=rasterio.float32, compress='lzw')\n",
    "\n",
    "        # Write smoothed raster\n",
    "        with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "            dst.write(smoothed_data, 1)\n",
    "\n",
    "    print(f\"  Smoothed: {os.path.basename(output_raster_path)}\")\n",
    "\n",
    "    # Return stats\n",
    "    original_max = np.max(data)\n",
    "    smoothed_max = np.max(smoothed_data)\n",
    "    return original_max, smoothed_max\n",
    "\n",
    "def create_heatmap_versions(hurricane_dir, hurricane_name, sigma=2.0):\n",
    "    \"\"\"Create smoothed heatmap versions of all rasters\"\"\"\n",
    "    print(f\"\\nCreating heatmap versions for {hurricane_name}...\")\n",
    "\n",
    "    # Create heatmap subdirectory\n",
    "    heatmap_dir = os.path.join(hurricane_dir, 'heatmap')\n",
    "    os.makedirs(heatmap_dir, exist_ok=True)\n",
    "\n",
    "    # Process all cumulative rasters (these are usually more interesting for heatmaps)\n",
    "    cumulative_files = glob.glob(os.path.join(hurricane_dir, f\"{hurricane_name}_cumulative_*.tif\"))\n",
    "\n",
    "    stats = []\n",
    "    for tif_path in sorted(cumulative_files):\n",
    "        filename = os.path.basename(tif_path)\n",
    "        heatmap_filename = filename.replace('.tif', '_heatmap.tif')\n",
    "        heatmap_path = os.path.join(heatmap_dir, heatmap_filename)\n",
    "\n",
    "        orig_max, smooth_max = apply_heatmap_smoothing(tif_path, heatmap_path, sigma)\n",
    "        stats.append((filename, orig_max, smooth_max))\n",
    "\n",
    "    print(f\"  Created {len(cumulative_files)} heatmap rasters in: {heatmap_dir}\")\n",
    "\n",
    "    # Print smoothing statistics\n",
    "    print(f\"  Smoothing statistics:\")\n",
    "    for filename, orig_max, smooth_max in stats[:3]:  # Show first 3\n",
    "        print(f\"    {filename}: {orig_max:.1f} → {smooth_max:.1f} (max value)\")\n",
    "\n",
    "    return heatmap_dir\n",
    "\n",
    "def create_heatmap_colormap():\n",
    "    \"\"\"Create a heatmap-style colormap like the example image\"\"\"\n",
    "    # Define colors similar to your example image\n",
    "    colors = [\n",
    "        '#00000000',  # Transparent (for 0 values)\n",
    "        '#2E8B57FF',  # Sea Green (low values)\n",
    "        '#32CD32FF',  # Lime Green\n",
    "        '#ADFF2FFF',  # Green Yellow\n",
    "        '#FFFF00FF',  # Yellow\n",
    "        '#FFD700FF',  # Gold\n",
    "        '#FFA500FF',  # Orange\n",
    "        '#FF6347FF',  # Tomato\n",
    "        '#FF4500FF',  # Orange Red\n",
    "        '#FF0000FF',  # Red (high values)\n",
    "        '#8B0000FF',  # Dark Red (highest values)\n",
    "    ]\n",
    "\n",
    "    # Create colormap\n",
    "    n_bins = 256\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list('heatmap', colors, N=n_bins)\n",
    "\n",
    "    return cmap\n",
    "\n",
    "def preview_heatmap(raster_path, title=\"Heatmap Preview\"):\n",
    "    \"\"\"Create a preview of the heatmap with proper styling\"\"\"\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        data = src.read(1)\n",
    "\n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        # Get custom colormap\n",
    "        cmap = create_heatmap_colormap()\n",
    "\n",
    "        # Set up visualization\n",
    "        # Use 95th percentile for max to avoid outliers dominating the scale\n",
    "        vmax = np.percentile(data[data > 0], 95) if np.any(data > 0) else np.max(data)\n",
    "        vmin = 0\n",
    "\n",
    "        # Display raster\n",
    "        show(src, ax=ax, cmap=cmap, vmin=vmin, vmax=vmax, alpha=0.8)\n",
    "\n",
    "        # Styling\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        # Add colorbar\n",
    "        im = ax.images[0]\n",
    "        cbar = plt.colorbar(im, ax=ax, shrink=0.8, aspect=20)\n",
    "        cbar.set_label('Tweet Density', rotation=270, labelpad=20)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Print statistics\n",
    "        print(f\"  Data range: {np.min(data):.1f} - {np.max(data):.1f}\")\n",
    "        print(f\"  95th percentile: {vmax:.1f}\")\n",
    "        print(f\"  Non-zero pixels: {np.count_nonzero(data):,}\")\n",
    "\n",
    "def export_styled_geotiff(input_path, output_path, apply_colormap=True):\n",
    "    \"\"\"Export a styled GeoTIFF with embedded colormap for direct use in web maps\"\"\"\n",
    "\n",
    "    with rasterio.open(input_path) as src:\n",
    "        data = src.read(1)\n",
    "        profile = src.profile.copy()\n",
    "\n",
    "        if apply_colormap:\n",
    "            # Convert to 8-bit for colormap application\n",
    "            vmax = np.percentile(data[data > 0], 95) if np.any(data > 0) else np.max(data)\n",
    "            data_normalized = np.clip((data / vmax) * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "            # Update profile for 8-bit output\n",
    "            profile.update(\n",
    "                dtype=rasterio.uint8,\n",
    "                count=1,\n",
    "                compress='lzw'\n",
    "            )\n",
    "\n",
    "            # Write the normalized data\n",
    "            with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "                dst.write(data_normalized, 1)\n",
    "\n",
    "                # Create and write colormap\n",
    "                cmap = create_heatmap_colormap()\n",
    "                colormap = {}\n",
    "                for i in range(256):\n",
    "                    rgba = cmap(i / 255.0)\n",
    "                    # Convert to 0-255 range\n",
    "                    colormap[i] = tuple(int(c * 255) for c in rgba)\n",
    "\n",
    "                dst.write_colormap(1, colormap)\n",
    "        else:\n",
    "            # Keep as float32\n",
    "            with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "                dst.write(data, 1)\n",
    "\n",
    "    print(f\"  Exported styled raster: {os.path.basename(output_path)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXECUTE HEATMAP PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "def process_hurricane_heatmaps(hurricane_name, hurricane_dir, preview_latest=True):\n",
    "    \"\"\"Complete heatmap processing pipeline for a hurricane\"\"\"\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"HEATMAP PROCESSING: {hurricane_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Step 1: Create smoothed heatmap versions\n",
    "    heatmap_dir = create_heatmap_versions(hurricane_dir, hurricane_name, sigma=2.5)\n",
    "\n",
    "    # Step 2: Create web-ready styled versions\n",
    "    styled_dir = os.path.join(hurricane_dir, 'styled')\n",
    "    os.makedirs(styled_dir, exist_ok=True)\n",
    "\n",
    "    heatmap_files = glob.glob(os.path.join(heatmap_dir, \"*.tif\"))\n",
    "\n",
    "    for heatmap_file in sorted(heatmap_files):\n",
    "        filename = os.path.basename(heatmap_file)\n",
    "        styled_filename = filename.replace('_heatmap.tif', '_styled.tif')\n",
    "        styled_path = os.path.join(styled_dir, styled_filename)\n",
    "\n",
    "        export_styled_geotiff(heatmap_file, styled_path, apply_colormap=True)\n",
    "\n",
    "    # Step 3: Preview the latest heatmap\n",
    "    if preview_latest and heatmap_files:\n",
    "        latest_heatmap = sorted(heatmap_files)[-1]\n",
    "        preview_heatmap(latest_heatmap, f\"{hurricane_name.title()} - Latest Cumulative Heatmap\")\n",
    "\n",
    "    print(f\"\\n✓ {hurricane_name.upper()} heatmap processing complete!\")\n",
    "    print(f\"  Smoothed rasters: {heatmap_dir}\")\n",
    "    print(f\"  Styled rasters: {styled_dir}\")\n",
    "\n",
    "    return heatmap_dir, styled_dir\n",
    "\n",
    "# Run processing for your hurricanes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HEATMAP POST-PROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Process both hurricanes\n",
    "francine_dir = os.path.join(output_dir, 'francine')\n",
    "helene_dir = os.path.join(output_dir, 'helene')\n",
    "#\n",
    "# if os.path.exists(francine_dir):\n",
    "#     francine_heatmap_dir, francine_styled_dir = process_hurricane_heatmaps('francine', francine_dir)\n",
    "#\n",
    "# if os.path.exists(helene_dir):\n",
    "#     helene_heatmap_dir, helene_styled_dir = process_hurricane_heatmaps('helene', helene_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL HEATMAP PROCESSING COMPLETE! 🔥\")\n"
   ],
   "id": "530b3a7a47b1f7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HEATMAP POST-PROCESSING\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ALL HEATMAP PROCESSING COMPLETE! 🔥\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T18:52:38.263853Z",
     "start_time": "2025-09-22T18:52:38.262688Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "80b96b516fb40db0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
