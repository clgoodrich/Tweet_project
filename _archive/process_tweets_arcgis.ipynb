{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Processing with ArcPy - ArcGIS Pro Native\n",
    "\n",
    "This notebook processes hurricane tweet data using **ArcPy only** - no external dependencies.\n",
    "\n",
    "**Features:**\n",
    "- Spatial operations using arcpy.da, arcpy.management, arcpy.analysis\n",
    "- All data stored in project geodatabase (tw_project.gdb)\n",
    "- Time-binned aggregation (4-hour intervals)\n",
    "- Hierarchical geographic cascade (city → county → state)\n",
    "- Raster creation for heat mapping\n",
    "- Time-enabled outputs for ArcGIS Pro visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace set to: C:\\Users\\colto\\Documents\\tw_project\\tw_project\\data\\tw_project.gdb\n",
      "ArcGIS Pro Version: 3.5\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SETUP: Import ArcPy and Configure Environment\n",
    "# ==============================================================================\n",
    "\n",
    "import arcpy\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Set workspace to project geodatabase\n",
    "project_root = os.getcwd()\n",
    "gdb_path = os.path.join(project_root, 'data', 'tw_project.gdb')\n",
    "\n",
    "# Create geodatabase if it doesn't exist\n",
    "if not arcpy.Exists(gdb_path):\n",
    "    gdb_folder = os.path.dirname(gdb_path)\n",
    "    gdb_name = os.path.basename(gdb_path)\n",
    "    arcpy.management.CreateFileGDB(gdb_folder, gdb_name)\n",
    "    print(f\"Created geodatabase: {gdb_path}\")\n",
    "\n",
    "arcpy.env.workspace = gdb_path\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "print(f\"Workspace set to: {arcpy.env.workspace}\")\n",
    "print(f\"ArcGIS Pro Version: {arcpy.GetInstallInfo()['Version']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported tweets_helene: 0 features\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# IMPORT DATA: Load GeoJSON into Geodatabase\n",
    "# ==============================================================================\n",
    "\n",
    "def import_geojson_to_gdb(geojson_path, output_fc_name):\n",
    "    \"\"\"\n",
    "    Import GeoJSON to geodatabase feature class.\n",
    "    \"\"\"\n",
    "    output_fc = os.path.join(gdb_path, output_fc_name)\n",
    "    \n",
    "    # Convert JSON to Features\n",
    "    arcpy.conversion.JSONToFeatures(geojson_path, output_fc)\n",
    "    \n",
    "    print(f\"Imported {output_fc_name}: {arcpy.management.GetCount(output_fc)[0]} features\")\n",
    "    return output_fc\n",
    "\n",
    "# Import hurricane tweet data\n",
    "helene_geojson = os.path.join(project_root, 'data', 'geojson', 'helene.geojson')\n",
    "francine_geojson = os.path.join(project_root, 'data', 'geojson', 'francine.geojson')\n",
    "\n",
    "tweets_helene_fc = import_geojson_to_gdb(helene_geojson, 'tweets_helene')\n",
    "# tweets_francine_fc = import_geojson_to_gdb(francine_geojson, 'tweets_francine')\n",
    "\n",
    "# Use Helene data as primary\n",
    "tweets_fc = tweets_helene_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported US States: 52 features\n",
      "Imported US Counties: 3222 features\n",
      "Imported US Cities: 17244 features\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# LOAD REFERENCE GEOGRAPHY\n",
    "# ==============================================================================\n",
    "\n",
    "# Import US States\n",
    "states_shp = os.path.join(project_root, 'data', 'shape_files', 'cb_2023_us_state_20m.shp')\n",
    "states_fc = os.path.join(gdb_path, 'us_states')\n",
    "arcpy.conversion.FeatureClassToFeatureClass(states_shp, gdb_path, 'us_states')\n",
    "print(f\"Imported US States: {arcpy.management.GetCount(states_fc)[0]} features\")\n",
    "\n",
    "# Import US Counties\n",
    "counties_shp = os.path.join(project_root, 'data', 'shape_files', 'cb_2023_us_county_20m.shp')\n",
    "counties_fc = os.path.join(gdb_path, 'us_counties')\n",
    "arcpy.conversion.FeatureClassToFeatureClass(counties_shp, gdb_path, 'us_counties')\n",
    "print(f\"Imported US Counties: {arcpy.management.GetCount(counties_fc)[0]} features\")\n",
    "\n",
    "# Import US Cities (from CSV - create feature class)\n",
    "cities_csv = os.path.join(project_root, 'data', 'tables', 'cities1000.csv')\n",
    "cities_fc = os.path.join(gdb_path, 'us_cities')\n",
    "\n",
    "# Create point feature class from XY data\n",
    "arcpy.management.XYTableToPoint(\n",
    "    cities_csv,\n",
    "    cities_fc,\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    coordinate_system=arcpy.SpatialReference(4326)\n",
    ")\n",
    "\n",
    "# Filter to US cities only\n",
    "arcpy.analysis.Select(\n",
    "    cities_fc,\n",
    "    os.path.join(gdb_path, 'us_cities_filtered'),\n",
    "    \"country_code = 'US'\"\n",
    ")\n",
    "cities_fc = os.path.join(gdb_path, 'us_cities_filtered')\n",
    "print(f\"Imported US Cities: {arcpy.management.GetCount(cities_fc)[0]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added time_bin field to tweets_helene\n",
      "\n",
      "Found 0 time bins\n"
     ]
    },
    {
     "ename": "<class 'IndexError'>",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m time_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(time_bins))\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(time_bins)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m time bins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_bins[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_bins[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# TIME BINNING: Create 4-hour time bins\n",
    "# ==============================================================================\n",
    "\n",
    "def add_time_bin_field(feature_class, time_field='time', bin_hours=4):\n",
    "    \"\"\"\n",
    "    Add a time_bin field that groups times into N-hour intervals.\n",
    "    \"\"\"\n",
    "    # Add time_bin field\n",
    "    arcpy.management.AddField(feature_class, 'time_bin', 'DATE')\n",
    "    arcpy.management.AddField(feature_class, 'time_bin_str', 'TEXT', field_length=50)\n",
    "    \n",
    "    # Calculate time bins using Python expression\n",
    "    expression = f\"\"\"\n",
    "def floor_to_hours(dt, hours):\n",
    "    if dt is None:\n",
    "        return None\n",
    "    hour = (dt.hour // hours) * hours\n",
    "    return dt.replace(hour=hour, minute=0, second=0, microsecond=0)\n",
    "    \n",
    "floor_to_hours(!{time_field}!, {bin_hours})\n",
    "\"\"\"\n",
    "    \n",
    "    arcpy.management.CalculateField(\n",
    "        feature_class,\n",
    "        'time_bin',\n",
    "        expression,\n",
    "        'PYTHON3'\n",
    "    )\n",
    "    \n",
    "    # Also create string version for labeling\n",
    "    arcpy.management.CalculateField(\n",
    "        feature_class,\n",
    "        'time_bin_str',\n",
    "        \"!time_bin!.strftime('%Y-%m-%d %H:%M:%S') if !time_bin! else None\",\n",
    "        'PYTHON3'\n",
    "    )\n",
    "    \n",
    "    print(f\"Added time_bin field to {os.path.basename(feature_class)}\")\n",
    "\n",
    "# Add time bins to tweets\n",
    "add_time_bin_field(tweets_fc, 'time', 4)\n",
    "\n",
    "# Get unique time bins\n",
    "time_bins = set()\n",
    "with arcpy.da.SearchCursor(tweets_fc, ['time_bin']) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0]:\n",
    "            time_bins.add(row[0])\n",
    "\n",
    "time_bins = sorted(list(time_bins))\n",
    "print(f\"\\nFound {len(time_bins)} time bins\")\n",
    "print(f\"Range: {time_bins[0].strftime('%Y-%m-%d %H:%M')} to {time_bins[-1].strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SPATIAL JOIN: Cascade counts from tweet points to geography\n",
    "# ==============================================================================\n",
    "\n",
    "def spatial_join_and_count(tweet_fc, target_fc, output_name, time_bin=None):\n",
    "    \"\"\"\n",
    "    Perform spatial join to count tweets in each geographic unit.\n",
    "    If time_bin specified, filter tweets to that time period.\n",
    "    \"\"\"\n",
    "    # Filter tweets by time bin if specified\n",
    "    if time_bin:\n",
    "        bin_str = time_bin.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        where_clause = f\"time_bin_str = '{bin_str}'\"\n",
    "        tweet_layer = arcpy.management.MakeFeatureLayer(tweet_fc, 'tweet_temp', where_clause)\n",
    "    else:\n",
    "        tweet_layer = tweet_fc\n",
    "    \n",
    "    # Spatial join (one-to-many, then summarize)\n",
    "    output_fc = os.path.join(gdb_path, output_name)\n",
    "    \n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_fc,\n",
    "        tweet_layer,\n",
    "        output_fc,\n",
    "        'JOIN_ONE_TO_ONE',\n",
    "        'KEEP_ALL',\n",
    "        match_option='CONTAINS'\n",
    "    )\n",
    "    \n",
    "    # Rename Join_Count to tweet_count\n",
    "    arcpy.management.AddField(output_fc, 'tweet_count', 'LONG')\n",
    "    arcpy.management.CalculateField(output_fc, 'tweet_count', '!Join_Count!', 'PYTHON3')\n",
    "    \n",
    "    return output_fc\n",
    "\n",
    "print(\"Creating spatial aggregations...\")\n",
    "\n",
    "# Aggregate for all time (no time filter)\n",
    "states_all = spatial_join_and_count(tweets_fc, states_fc, 'states_all_time')\n",
    "counties_all = spatial_join_and_count(tweets_fc, counties_fc, 'counties_all_time')\n",
    "\n",
    "print(f\"\\nCreated aggregations:\")\n",
    "print(f\"  States: {states_all}\")\n",
    "print(f\"  Counties: {counties_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEMPORAL AGGREGATION: Create feature classes for each time bin\n",
    "# ==============================================================================\n",
    "\n",
    "def create_temporal_aggregations(tweet_fc, geography_fc, geography_name, time_bins):\n",
    "    \"\"\"\n",
    "    Create separate feature classes for each time bin (incremental).\n",
    "    Also create cumulative versions.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing {geography_name} temporal aggregations...\")\n",
    "    \n",
    "    incremental_fcs = []\n",
    "    cumulative_fcs = []\n",
    "    cumulative_counts = {}  # Track cumulative by entity ID\n",
    "    \n",
    "    for idx, time_bin in enumerate(time_bins):\n",
    "        bin_str = time_bin.strftime('%Y%m%d_%H%M')\n",
    "        print(f\"  Processing bin {idx+1}/{len(time_bins)}: {time_bin.strftime('%Y-%m-%d %H:%M')}\")\n",
    "        \n",
    "        # INCREMENTAL\n",
    "        inc_name = f\"{geography_name}_inc_{bin_str}\"\n",
    "        inc_fc = spatial_join_and_count(tweet_fc, geography_fc, inc_name, time_bin)\n",
    "        \n",
    "        # Add time bin field\n",
    "        arcpy.management.AddField(inc_fc, 'time_bin', 'DATE')\n",
    "        arcpy.management.AddField(inc_fc, 'time_bin_str', 'TEXT', field_length=50)\n",
    "        arcpy.management.CalculateField(\n",
    "            inc_fc, 'time_bin', \n",
    "            f\"datetime.datetime({time_bin.year}, {time_bin.month}, {time_bin.day}, {time_bin.hour}, {time_bin.minute})\",\n",
    "            'PYTHON3'\n",
    "        )\n",
    "        arcpy.management.CalculateField(\n",
    "            inc_fc, 'time_bin_str',\n",
    "            f\"'{time_bin.strftime('%Y-%m-%d %H:%M:%S')}'\",\n",
    "            'PYTHON3'\n",
    "        )\n",
    "        \n",
    "        incremental_fcs.append(inc_fc)\n",
    "        \n",
    "        # CUMULATIVE - update running totals\n",
    "        # Read current counts and add to cumulative\n",
    "        id_field = get_id_field(geography_name)\n",
    "        with arcpy.da.SearchCursor(inc_fc, [id_field, 'tweet_count']) as cursor:\n",
    "            for row in cursor:\n",
    "                entity_id = row[0]\n",
    "                count = row[1] if row[1] else 0\n",
    "                cumulative_counts[entity_id] = cumulative_counts.get(entity_id, 0) + count\n",
    "        \n",
    "        # Create cumulative feature class\n",
    "        cum_name = f\"{geography_name}_cum_{bin_str}\"\n",
    "        cum_fc = os.path.join(gdb_path, cum_name)\n",
    "        arcpy.management.Copy(geography_fc, cum_fc)\n",
    "        \n",
    "        # Add cumulative count field\n",
    "        arcpy.management.AddField(cum_fc, 'cumul_cnt', 'LONG')\n",
    "        arcpy.management.AddField(cum_fc, 'time_bin', 'DATE')\n",
    "        arcpy.management.AddField(cum_fc, 'time_bin_str', 'TEXT', field_length=50)\n",
    "        \n",
    "        # Update cumulative counts\n",
    "        with arcpy.da.UpdateCursor(cum_fc, [id_field, 'cumul_cnt']) as cursor:\n",
    "            for row in cursor:\n",
    "                entity_id = row[0]\n",
    "                row[1] = cumulative_counts.get(entity_id, 0)\n",
    "                cursor.updateRow(row)\n",
    "        \n",
    "        # Set time bin\n",
    "        arcpy.management.CalculateField(\n",
    "            cum_fc, 'time_bin',\n",
    "            f\"datetime.datetime({time_bin.year}, {time_bin.month}, {time_bin.day}, {time_bin.hour}, {time_bin.minute})\",\n",
    "            'PYTHON3'\n",
    "        )\n",
    "        arcpy.management.CalculateField(\n",
    "            cum_fc, 'time_bin_str',\n",
    "            f\"'{time_bin.strftime('%Y-%m-%d %H:%M:%S')}'\",\n",
    "            'PYTHON3'\n",
    "        )\n",
    "        \n",
    "        cumulative_fcs.append(cum_fc)\n",
    "    \n",
    "    return incremental_fcs, cumulative_fcs\n",
    "\n",
    "def get_id_field(geography_name):\n",
    "    \"\"\"Get the unique ID field for each geography type.\"\"\"\n",
    "    if 'state' in geography_name.lower():\n",
    "        return 'STUSPS'\n",
    "    elif 'count' in geography_name.lower():\n",
    "        return 'GEOID'\n",
    "    elif 'cit' in geography_name.lower():\n",
    "        return 'geonameid'\n",
    "    return 'OBJECTID'\n",
    "\n",
    "# Create temporal aggregations\n",
    "states_inc, states_cum = create_temporal_aggregations(tweets_fc, states_fc, 'states', time_bins)\n",
    "counties_inc, counties_cum = create_temporal_aggregations(tweets_fc, counties_fc, 'counties', time_bins)\n",
    "\n",
    "print(f\"\\nCreated {len(states_inc)} incremental state feature classes\")\n",
    "print(f\"Created {len(states_cum)} cumulative state feature classes\")\n",
    "print(f\"Created {len(counties_inc)} incremental county feature classes\")\n",
    "print(f\"Created {len(counties_cum)} cumulative county feature classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MERGE TEMPORAL DATA: Create master feature classes\n",
    "# ==============================================================================\n",
    "\n",
    "def merge_temporal_fcs(fc_list, output_name):\n",
    "    \"\"\"\n",
    "    Merge all temporal feature classes into one master feature class.\n",
    "    \"\"\"\n",
    "    output_fc = os.path.join(gdb_path, output_name)\n",
    "    arcpy.management.Merge(fc_list, output_fc)\n",
    "    count = arcpy.management.GetCount(output_fc)[0]\n",
    "    print(f\"Merged {len(fc_list)} feature classes into {output_name}: {count} features\")\n",
    "    return output_fc\n",
    "\n",
    "print(\"\\nMerging temporal feature classes...\")\n",
    "\n",
    "# Merge incremental\n",
    "states_inc_all = merge_temporal_fcs(states_inc, 'states_INCREMENTAL_ALL')\n",
    "counties_inc_all = merge_temporal_fcs(counties_inc, 'counties_INCREMENTAL_ALL')\n",
    "\n",
    "# Merge cumulative\n",
    "states_cum_all = merge_temporal_fcs(states_cum, 'states_CUMULATIVE_ALL')\n",
    "counties_cum_all = merge_temporal_fcs(counties_cum, 'counties_CUMULATIVE_ALL')\n",
    "\n",
    "print(\"\\n✓ Master feature classes created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# RASTER CREATION: Convert tweet density to rasters\n",
    "# ==============================================================================\n",
    "\n",
    "def create_kernel_density_raster(point_fc, output_raster, cell_size=0.1, search_radius=1.0):\n",
    "    \"\"\"\n",
    "    Create kernel density raster from tweet points.\n",
    "    \"\"\"\n",
    "    arcpy.sa.KernelDensity(\n",
    "        point_fc,\n",
    "        'NONE',  # No population field\n",
    "        cell_size,\n",
    "        search_radius,\n",
    "        'SQUARE_KILOMETERS'\n",
    "    ).save(output_raster)\n",
    "    \n",
    "    print(f\"Created kernel density raster: {os.path.basename(output_raster)}\")\n",
    "    return output_raster\n",
    "\n",
    "def create_polygon_to_raster(polygon_fc, value_field, output_raster, cell_size=0.1):\n",
    "    \"\"\"\n",
    "    Convert polygon feature class to raster using a value field.\n",
    "    \"\"\"\n",
    "    arcpy.conversion.PolygonToRaster(\n",
    "        polygon_fc,\n",
    "        value_field,\n",
    "        output_raster,\n",
    "        'CELL_CENTER',\n",
    "        'NONE',\n",
    "        cell_size\n",
    "    )\n",
    "    \n",
    "    print(f\"Created polygon raster: {os.path.basename(output_raster)}\")\n",
    "    return output_raster\n",
    "\n",
    "print(\"\\nCreating rasters...\")\n",
    "\n",
    "# Create overall density raster\n",
    "density_raster = os.path.join(gdb_path, 'tweet_density_all')\n",
    "create_kernel_density_raster(tweets_fc, density_raster, cell_size=0.05, search_radius=0.5)\n",
    "\n",
    "# Create state count raster\n",
    "states_raster = os.path.join(gdb_path, 'states_count_raster')\n",
    "create_polygon_to_raster(states_all, 'tweet_count', states_raster, cell_size=0.1)\n",
    "\n",
    "# Create county count raster\n",
    "counties_raster = os.path.join(gdb_path, 'counties_count_raster')\n",
    "create_polygon_to_raster(counties_all, 'tweet_count', counties_raster, cell_size=0.05)\n",
    "\n",
    "print(\"\\n✓ Rasters created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEMPORAL RASTERS: Create rasters for each time bin\n",
    "# ==============================================================================\n",
    "\n",
    "def create_temporal_rasters(fc_list, value_field, output_prefix, cell_size=0.05):\n",
    "    \"\"\"\n",
    "    Create rasters for each temporal feature class.\n",
    "    \"\"\"\n",
    "    rasters = []\n",
    "    \n",
    "    for idx, fc in enumerate(fc_list):\n",
    "        fc_name = os.path.basename(fc)\n",
    "        raster_name = f\"{output_prefix}_{fc_name}\"\n",
    "        output_raster = os.path.join(gdb_path, raster_name)\n",
    "        \n",
    "        try:\n",
    "            arcpy.conversion.PolygonToRaster(\n",
    "                fc,\n",
    "                value_field,\n",
    "                output_raster,\n",
    "                'CELL_CENTER',\n",
    "                'NONE',\n",
    "                cell_size\n",
    "            )\n",
    "            rasters.append(output_raster)\n",
    "            print(f\"  Created raster {idx+1}/{len(fc_list)}: {raster_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error creating {raster_name}: {e}\")\n",
    "    \n",
    "    return rasters\n",
    "\n",
    "print(\"\\nCreating temporal rasters...\")\n",
    "\n",
    "# Create incremental rasters\n",
    "print(\"  Incremental state rasters...\")\n",
    "states_inc_rasters = create_temporal_rasters(states_inc, 'tweet_count', 'raster_states_inc')\n",
    "\n",
    "print(\"  Cumulative state rasters...\")\n",
    "states_cum_rasters = create_temporal_rasters(states_cum, 'cumul_cnt', 'raster_states_cum')\n",
    "\n",
    "print(f\"\\n✓ Created {len(states_inc_rasters)} incremental rasters\")\n",
    "print(f\"✓ Created {len(states_cum_rasters)} cumulative rasters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SUMMARY & VALIDATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nGEODATABASE CONTENTS:\")\n",
    "arcpy.env.workspace = gdb_path\n",
    "\n",
    "# List feature classes\n",
    "feature_classes = arcpy.ListFeatureClasses()\n",
    "print(f\"\\nFeature Classes: {len(feature_classes)}\")\n",
    "for fc in sorted(feature_classes)[:20]:  # Show first 20\n",
    "    count = arcpy.management.GetCount(fc)[0]\n",
    "    print(f\"  {fc}: {count} features\")\n",
    "if len(feature_classes) > 20:\n",
    "    print(f\"  ... and {len(feature_classes) - 20} more\")\n",
    "\n",
    "# List rasters\n",
    "rasters = arcpy.ListRasters()\n",
    "print(f\"\\nRasters: {len(rasters)}\")\n",
    "for raster in sorted(rasters)[:10]:  # Show first 10\n",
    "    print(f\"  {raster}\")\n",
    "if len(rasters) > 10:\n",
    "    print(f\"  ... and {len(rasters) - 10} more\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY OUTPUTS FOR ARCGIS PRO VISUALIZATION:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTemporal Feature Classes (time-enabled):\")\n",
    "print(\"  - states_INCREMENTAL_ALL\")\n",
    "print(\"  - states_CUMULATIVE_ALL\")\n",
    "print(\"  - counties_INCREMENTAL_ALL\")\n",
    "print(\"  - counties_CUMULATIVE_ALL\")\n",
    "print(\"\\nTo enable time:\")\n",
    "print(\"  1. Add layer to map\")\n",
    "print(\"  2. Right-click → Properties → Time tab\")\n",
    "print(\"  3. Enable time using 'time_bin' field\")\n",
    "print(\"  4. Set time step to 4 hours\")\n",
    "print(\"\\nRasters:\")\n",
    "print(\"  - tweet_density_all (kernel density)\")\n",
    "print(\"  - states_count_raster\")\n",
    "print(\"  - counties_count_raster\")\n",
    "print(\"  - raster_states_inc_* (temporal)\")\n",
    "print(\"  - raster_states_cum_* (temporal)\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EXPORT TO SHAPEFILE (Optional - for external use)\n",
    "# ==============================================================================\n",
    "\n",
    "def export_to_shapefile(input_fc, output_folder):\n",
    "    \"\"\"\n",
    "    Export feature class to shapefile for external use.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    fc_name = os.path.basename(input_fc)\n",
    "    output_shp = os.path.join(output_folder, f\"{fc_name}.shp\")\n",
    "    \n",
    "    arcpy.conversion.FeatureClassToShapefile([input_fc], output_folder)\n",
    "    print(f\"Exported: {output_shp}\")\n",
    "    return output_shp\n",
    "\n",
    "# Export key outputs\n",
    "output_folder = os.path.join(project_root, 'arcgis_outputs', 'shapefiles')\n",
    "\n",
    "print(\"\\nExporting to shapefiles...\")\n",
    "export_to_shapefile(states_inc_all, output_folder)\n",
    "export_to_shapefile(states_cum_all, output_folder)\n",
    "export_to_shapefile(counties_inc_all, output_folder)\n",
    "export_to_shapefile(counties_cum_all, output_folder)\n",
    "\n",
    "print(f\"\\n✓ Shapefiles exported to: {output_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
