{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Hurricane Raster Fusion Analysis\n\n**PLAN:** Load tweets → Create grid → Temporal bins → Fuse signals → Export rasters\n\n**DO:** Execute pipeline\n\n**VERIFY:** Check outputs"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:08:15.925875Z",
     "start_time": "2025-10-30T00:08:15.921666Z"
    }
   },
   "source": "CONFIG = {\n    'event': 'helene',\n    'cell_size_km': 5,\n    'time_bin_hours': 2,\n    'weights': {'coordinates': 0.50, 'city': 0.30, 'county': 0.15, 'state': 0.05},\n    'crs': 'EPSG:5070',\n    'export_slices': True\n}\nassert abs(sum(CONFIG['weights'].values()) - 1.0) < 0.001\nprint(f\"Config: {CONFIG['event']}, {CONFIG['cell_size_km']}km\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: helene, 5km\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:08:16.759067Z",
     "start_time": "2025-10-30T00:08:15.949828Z"
    }
   },
   "source": "import geopandas as gpd\nimport pandas as pd\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_bounds\nfrom pathlib import Path\nfrom datetime import datetime\nimport warnings, json\nwarnings.filterwarnings('ignore')\nprint('Imports ready')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:08:16.822760Z",
     "start_time": "2025-10-30T00:08:16.819558Z"
    }
   },
   "source": "DATA = Path(r'C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\data')\nOUT = Path(r'C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output')\nOUT.mkdir(exist_ok=True)\nEVENT_DIR = OUT / CONFIG['event']\nEVENT_DIR.mkdir(exist_ok=True)\nprint(f'Output: {EVENT_DIR}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:08:16.990828Z",
     "start_time": "2025-10-30T00:08:16.830427Z"
    }
   },
   "source": "print('Loading tweets...')\ntweets = gpd.read_file(DATA / 'geojson' / f\"{CONFIG['event']}.geojson\")\ntweets['time'] = pd.to_datetime(tweets['time'])\nif tweets.crs is None:\n    tweets.set_crs('EPSG:4326', inplace=True)\ntweets = tweets.to_crs(CONFIG['crs'])\nprint(f'{len(tweets)} tweets, {tweets[\"time\"].min()} to {tweets[\"time\"].max()}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tweets...\n",
      "3007 tweets, 2024-09-26 02:29:25+00:00 to 2024-09-27 19:59:41+00:00\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:08:17.003972Z",
     "start_time": "2025-10-30T00:08:16.995774Z"
    }
   },
   "source": "buffer_m = 100000\ncell_m = CONFIG['cell_size_km'] * 1000\nbounds = tweets.total_bounds\nminx = bounds[0]-buffer_m\nminy = bounds[1]-buffer_m\nmaxx = bounds[2]+buffer_m\nmaxy = bounds[3]+buffer_m\nwidth = int(np.ceil((maxx-minx)/cell_m))\nheight = int(np.ceil((maxy-miny)/cell_m))\ntransform = from_bounds(minx, miny, maxx, maxy, width, height)\nprint(f'Grid: {width}x{height} = {width*height:,} cells')\nx_coords = np.linspace(minx+cell_m/2, maxx-cell_m/2, width)\ny_coords = np.linspace(miny+cell_m/2, maxy-cell_m/2, height)\nX, Y = np.meshgrid(x_coords, y_coords)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid: 279x390 = 108,810 cells\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:08:17.017755Z",
     "start_time": "2025-10-30T00:08:17.012146Z"
    }
   },
   "source": "min_t = tweets['time'].min()\nmax_t = tweets['time'].max()\nstart_t = min_t.floor(f\"{CONFIG['time_bin_hours']}h\")\nend_t = max_t.ceil(f\"{CONFIG['time_bin_hours']}h\")\ntime_bins = pd.date_range(start_t, end_t, freq=f\"{CONFIG['time_bin_hours']}h\")\ntweets['bin'] = pd.cut(tweets['time'], bins=time_bins, labels=range(len(time_bins)-1), include_lowest=True)\nprint(f'{len(time_bins)-1} bins of {CONFIG[\"time_bin_hours\"]}h each')\nbin_meta = pd.DataFrame({'idx': range(len(time_bins)-1), 'start': time_bins[:-1], 'end': time_bins[1:]})",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 bins of 2h each\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:08:17.025147Z",
     "start_time": "2025-10-30T00:08:17.021862Z"
    }
   },
   "source": "def fuse_intensity(tweet_subset, grid_x, grid_y, sigma_m=3000):\n    intensity = np.zeros(grid_x.shape, dtype=np.float32)\n    for idx, row in tweet_subset.iterrows():\n        if row.geometry and row.geometry.is_valid:\n            px, py = row.geometry.x, row.geometry.y\n            dist_sq = (grid_x - px)**2 + (grid_y - py)**2\n            kernel = np.exp(-dist_sq / (2*sigma_m**2))\n            intensity += kernel\n    if intensity.max() > 0:\n        intensity = intensity / intensity.max()\n    return intensity\n\nprint('Fusion ready')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion ready\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:09:46.475802Z",
     "start_time": "2025-10-30T00:08:17.030812Z"
    }
   },
   "source": "print('Generating slices...')\nslices_iter = []\nslices_cum = []\nfor idx, row in bin_meta.iterrows():\n    tweets_in_bin = tweets[tweets['bin'] == idx]\n    tweets_cumulative = tweets[tweets['bin'] <= idx]\n    print(f'Bin {idx}: {len(tweets_in_bin)} tweets')\n    if len(tweets_in_bin) > 0:\n        intensity_i = fuse_intensity(tweets_in_bin, X, Y)\n    else:\n        intensity_i = np.zeros((height, width), dtype=np.float32)\n    if len(tweets_cumulative) > 0:\n        intensity_c = fuse_intensity(tweets_cumulative, X, Y)\n    else:\n        intensity_c = np.zeros((height, width), dtype=np.float32)\n    slices_iter.append(intensity_i)\n    slices_cum.append(intensity_c)\n    if CONFIG['export_slices']:\n        for name, data in [('iterative', intensity_i), ('cumulative', intensity_c)]:\n            path = EVENT_DIR / f'slice_{idx:03d}_{name}.tif'\n            with rasterio.open(path, 'w', driver='GTiff', height=height, width=width, count=1, dtype=np.float32, crs=CONFIG['crs'], transform=transform, compress='lzw') as dst:\n                dst.write(data, 1)\n                dst.update_tags(time_start=str(row['start']), time_end=str(row['end']))\nprint(f'{len(slices_iter)} slices generated')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating slices...\n",
      "Bin 0: 76 tweets\n",
      "Bin 1: 84 tweets\n",
      "Bin 2: 57 tweets\n",
      "Bin 3: 86 tweets\n",
      "Bin 4: 82 tweets\n",
      "Bin 5: 80 tweets\n",
      "Bin 6: 93 tweets\n",
      "Bin 7: 81 tweets\n",
      "Bin 8: 176 tweets\n",
      "Bin 9: 163 tweets\n",
      "Bin 10: 239 tweets\n",
      "Bin 11: 175 tweets\n",
      "Bin 12: 214 tweets\n",
      "Bin 13: 221 tweets\n",
      "Bin 14: 211 tweets\n",
      "Bin 15: 201 tweets\n",
      "Bin 16: 184 tweets\n",
      "Bin 17: 158 tweets\n",
      "Bin 18: 162 tweets\n",
      "Bin 19: 123 tweets\n",
      "Bin 20: 141 tweets\n",
      "21 slices generated\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:09:46.518066Z",
     "start_time": "2025-10-30T00:09:46.514641Z"
    }
   },
   "source": "meta = {\n    'pipeline': 'Raster Fusion',\n    'timestamp': datetime.now().isoformat(),\n    'config': CONFIG,\n    'grid': {'width': width, 'height': height},\n    'slices': len(slices_iter)\n}\nprint(json.dumps(meta, indent=2))\nwith open(EVENT_DIR / 'metadata.json', 'w') as f:\n    json.dump(meta, f, indent=2)\nprint(f'Metadata saved')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipeline\": \"Raster Fusion\",\n",
      "  \"timestamp\": \"2025-10-29T19:09:46.515896\",\n",
      "  \"config\": {\n",
      "    \"event\": \"helene\",\n",
      "    \"cell_size_km\": 5,\n",
      "    \"time_bin_hours\": 2,\n",
      "    \"weights\": {\n",
      "      \"coordinates\": 0.5,\n",
      "      \"city\": 0.3,\n",
      "      \"county\": 0.15,\n",
      "      \"state\": 0.05\n",
      "    },\n",
      "    \"crs\": \"EPSG:5070\",\n",
      "    \"export_slices\": true\n",
      "  },\n",
      "  \"grid\": {\n",
      "    \"width\": 279,\n",
      "    \"height\": 390\n",
      "  },\n",
      "  \"slices\": 21\n",
      "}\n",
      "Metadata saved\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T00:09:46.527074Z",
     "start_time": "2025-10-30T00:09:46.522934Z"
    }
   },
   "source": "print('VERIFICATION:')\nassert len(slices_iter) == len(bin_meta)\nprint('  ✓ Count OK')\nassert slices_iter[0].shape == (height, width)\nprint('  ✓ Shape OK')\nprint(f'  ✓ Slices: {sum(1 for s in slices_iter if s.max() > 0)}/{len(slices_iter)} non-empty')\nprint(f'\\nOUTPUTS: {EVENT_DIR}')\nprint('COMPLETE')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICATION:\n",
      "  ✓ Count OK\n",
      "  ✓ Shape OK\n",
      "  ✓ Slices: 21/21 non-empty\n",
      "\n",
      "OUTPUTS: C:\\Users\\colto\\Documents\\GitHub\\Tweet_project\\rasters_output\\helene\n",
      "COMPLETE\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## README\n\n### Fusion Strategy\nGaussian kernel density from tweet coordinates. Normalized intensity [0,1].\n\n### ArcGIS Pro\n1. Add GeoTIFF slices\n2. Enable time on layer\n3. Use time slider\n4. Symbology: Stretched, heat colors\n\n### Files\n- `slice_NNN_iterative.tif`\n- `slice_NNN_cumulative.tif`\n- `metadata.json`"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
